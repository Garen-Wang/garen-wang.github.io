<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic|Fira Code:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">


<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"garen-wang.top","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Today I spent nearly an afternoon to follow the tutorial on pytorch.org. So just recall what I have learnt here.  (all in PyTorch…)  from Scratch We first write our code without too many features of P">
<meta property="og:type" content="article">
<meta property="og:title" content="Learn MNIST in PyTorch from Scratch to CNN">
<meta property="og:url" content="http://garen-wang.top/2021/01/11/Learn-MNIST-in-PyTorch-from-Scratch-to-CNN/index.html">
<meta property="og:site_name" content="Garen Wang&#39;s Blog">
<meta property="og:description" content="Today I spent nearly an afternoon to follow the tutorial on pytorch.org. So just recall what I have learnt here.  (all in PyTorch…)  from Scratch We first write our code without too many features of P">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2021-01-11T11:33:08.000Z">
<meta property="article:modified_time" content="2022-03-04T22:44:26.856Z">
<meta property="article:author" content="Garen Wang">
<meta property="article:tag" content="Deep-Learning">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://garen-wang.top/2021/01/11/Learn-MNIST-in-PyTorch-from-Scratch-to-CNN/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Learn MNIST in PyTorch from Scratch to CNN | Garen Wang's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>


</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Garen Wang's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>


</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://garen-wang.top/2021/01/11/Learn-MNIST-in-PyTorch-from-Scratch-to-CNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Garen Wang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Garen Wang's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Learn MNIST in PyTorch from Scratch to CNN
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-11 19:33:08" itemprop="dateCreated datePublished" datetime="2021-01-11T19:33:08+08:00">2021-01-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-03-05 06:44:26" itemprop="dateModified" datetime="2022-03-05T06:44:26+08:00">2022-03-05</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Today I spent nearly an afternoon to follow the tutorial on <a href="pytorch.org">pytorch.org</a>. So just recall what I have learnt here.</p>
<p>(all in PyTorch…)</p>
<h2 id="from-Scratch"><a href="#from-Scratch" class="headerlink" title="from Scratch"></a>from Scratch</h2><p>We first write our code without too many features of PyTorch so that we can gradually see what can be simplified when using PyTorch.</p>
<a id="more"></a>
<h3 id="Download-MNIST-Data"><a href="#Download-MNIST-Data" class="headerlink" title="Download MNIST Data"></a>Download MNIST Data</h3><p>data download link: <a target="_blank" rel="noopener" href="https://github.com/pytorch/tutorials/raw/master/_static/mnist.pkl.gz">https://github.com/pytorch/tutorials/raw/master/_static/mnist.pkl.gz</a></p>
<p>After manually decompressing this file, we use <code>pickle</code> to read data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_data</span>():</span></span><br><span class="line">    path = Path(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> path.exists():</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            (XTrain, YTrain), (XTest, YTest), _ = pickle.load(f, encoding=<span class="string">&#x27;latin-1&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> XTrain, YTrain, XTest, YTest</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(FileNotFoundError)</span><br></pre></td></tr></table></figure>
<p>It’s worth mentioning that the second dimension of <code>XTrain</code> and <code>XTest</code> are 784, which is identical to 28 * 28.</p>
<p>Using <code>plt.imshow</code> and <code>plt.show</code> function, single data can be shown easily.</p>
<p>Here is the initial code implementing MNIST with few feature of PyTorch:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_data</span>():</span></span><br><span class="line">    path = Path(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> path.exists():</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            (XTrain, YTrain), (XTest, YTest), _ = pickle.load(f, encoding=<span class="string">&#x27;latin-1&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> XTrain, YTrain, XTest, YTest</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(FileNotFoundError)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw</span>(<span class="params">X</span>):</span></span><br><span class="line">    print(X.shape)</span><br><span class="line">    plt.imshow(X.reshape((<span class="number">28</span>, <span class="number">28</span>)), cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log_softmax</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x - x.exp().<span class="built_in">sum</span>(-<span class="number">1</span>).log().unsqueeze(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">X</span>):</span></span><br><span class="line">    <span class="keyword">return</span> log_softmax(X @ weights + bias)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nll</span>(<span class="params">batch_z, batch_y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> -batch_z[<span class="built_in">range</span>(batch_y.shape[<span class="number">0</span>]), batch_y].mean()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">loss_func = nll</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">batch_z, batch_y</span>):</span></span><br><span class="line">    temp = torch.argmax(batch_z, dim=<span class="number">1</span>)</span><br><span class="line">    r = (temp == batch_y)</span><br><span class="line">    <span class="keyword">return</span> r.<span class="built_in">float</span>().mean()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_batch_train_data</span>(<span class="params">batch_size, iteration</span>):</span></span><br><span class="line">    start = batch_size * iteration</span><br><span class="line">    end = start + iteration</span><br><span class="line">    <span class="keyword">return</span> XTrain[start:end], YTrain[start:end]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_batch_test_data</span>(<span class="params">batch_size, iteration</span>):</span></span><br><span class="line">    start = batch_size * iteration</span><br><span class="line">    end = start + iteration</span><br><span class="line">    <span class="keyword">return</span> XTest[start:end], YTest[start:end]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">XTrain, YTrain, XTest, YTest = read_data()  <span class="comment"># train: 50000, test: 10000</span></span><br><span class="line">XTrain, YTrain, XTest, YTest = <span class="built_in">map</span>(torch.tensor, (XTrain, YTrain, XTest, YTest))</span><br><span class="line"></span><br><span class="line">weights = torch.randn(<span class="number">784</span>, <span class="number">10</span>) / math.sqrt(<span class="number">784</span>)</span><br><span class="line">weights.requires_grad_()</span><br><span class="line">bias = torch.zeros(<span class="number">10</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">max_epoch, max_iteration, batch_size, lr</span>):</span></span><br><span class="line">    print(<span class="string">&#x27;training...&#x27;</span>)</span><br><span class="line">    <span class="keyword">global</span> weights, bias</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(max_epoch):</span><br><span class="line">        <span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(max_iteration):</span><br><span class="line">            start = iteration * batch_size</span><br><span class="line">            end = start + batch_size</span><br><span class="line">            batch_x, batch_y = get_batch_train_data(batch_size, iteration)</span><br><span class="line">            batch_z = forward(batch_x)</span><br><span class="line">            loss = loss_func(batch_z, batch_y)</span><br><span class="line"></span><br><span class="line">            loss.backward()</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                weights -= lr * weights.grad</span><br><span class="line">                bias -= lr * bias.grad</span><br><span class="line">                weights.grad.zero_()</span><br><span class="line">                bias.grad.zero_()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;training done.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    print(<span class="string">&#x27;testing...&#x27;</span>)</span><br><span class="line">    ZTest = forward(XTest)</span><br><span class="line">    print(<span class="string">&#x27;loss=%.4f, accuracy=%.4f&#x27;</span> % (loss_func(ZTest, YTest), accuracy(ZTest, YTest)))</span><br><span class="line">    print(<span class="string">&#x27;testing done.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    num_train = XTrain.shape[<span class="number">0</span>]</span><br><span class="line">    num_test = XTest.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># batch_x = XTrain[:batch_size]</span></span><br><span class="line">    <span class="comment"># batch_z = forward(batch_x)</span></span><br><span class="line">    <span class="comment"># print(batch_z[0], batch_z.shape)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># batch_y = YTrain[:batch_size]</span></span><br><span class="line">    <span class="comment"># print(loss_func(batch_z, batch_y))</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># print(accuracy(batch_z, batch_y))</span></span><br><span class="line"></span><br><span class="line">    batch_size = <span class="number">64</span></span><br><span class="line">    lr = <span class="number">0.05</span></span><br><span class="line">    max_epoch = <span class="number">20</span></span><br><span class="line">    max_iteration = math.ceil(num_train / batch_size)</span><br><span class="line">    train(max_epoch, max_iteration, batch_size, lr)</span><br><span class="line">    test()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>Most of the details can be answered if you have learnt about the basic knowledge of neural network, and most of the procedures are very similar to <a href="github.com/microsoft/ai-edu">the tutorial I learn</a>.</p>
<p>Now the magic just begins.</p>
<h2 id="Where-can-be-simplified-using-PyTorch-feature"><a href="#Where-can-be-simplified-using-PyTorch-feature" class="headerlink" title="Where can be simplified using PyTorch feature?"></a>Where can be simplified using PyTorch feature?</h2><h3 id="choosing-from-torch-nn-functional"><a href="#choosing-from-torch-nn-functional" class="headerlink" title="choosing from torch.nn.functional"></a>choosing from torch.nn.functional</h3><p>In previous code, we must manually define a function <code>nll</code> for calculating loss, which can be replaced by <code>torch.nn.functional</code>.</p>
<p>This stuff contains lots of functions, so that we needn’t implement each function we use, which is quite convenient.</p>
<h2 id="extending-torch-nn-Module"><a href="#extending-torch-nn-Module" class="headerlink" title="extending torch.nn.Module"></a>extending torch.nn.Module</h2><p>we can define our whole neural network as a class, whose super class is <code>torch.nn.Module</code>. In this way, parameters can be stored inside this object, which is friendly for us to program.</p>
<h2 id="using-layer-objects-from-torch-nn"><a href="#using-layer-objects-from-torch-nn" class="headerlink" title="using layer objects from torch.nn"></a>using layer objects from torch.nn</h2><p>The model previous code uses is exactly a linear layer, which can be replaced by <code>torch.nn.Linear</code>, which contains parameters within it.</p>
<p>What’s more, pooling layer, convolution layer are also available to use in <code>torch.nn</code>, which greatly reduces workflow.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">loss_func = F.cross_entropy</span><br><span class="line">model = NeuralNet() <span class="comment"># I am hanhan!</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">max_epoch, max_iteration, batch_size, lr</span>):</span></span><br><span class="line">    print(<span class="string">&#x27;training...&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(max_epoch):</span><br><span class="line">        <span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(max_iteration):</span><br><span class="line">            batch_x, batch_y = get_batch_train_data(batch_size, iteration)</span><br><span class="line">            batch_z = model(batch_x)</span><br><span class="line">            loss = loss_func(batch_z, batch_y)</span><br><span class="line"></span><br><span class="line">            loss.backward()</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters():</span><br><span class="line">                    p -= p.grad * lr</span><br><span class="line">                model.zero_grad()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;training done.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    print(<span class="string">&#x27;testing...&#x27;</span>)</span><br><span class="line">    ZTest = model(XTest)</span><br><span class="line">    print(<span class="string">&#x27;loss=%.4f, accuracy=%.4f&#x27;</span> % (loss_func(ZTest, YTest), accuracy(ZTest, YTest)))</span><br><span class="line">    print(<span class="string">&#x27;testing done.&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="modifying-parameters-by-torch-optim"><a href="#modifying-parameters-by-torch-optim" class="headerlink" title="modifying parameters by torch.optim"></a>modifying parameters by torch.optim</h2><p><code>torch.optim</code> includes many methods of optimization, including most commonly-used SGD. With this tool, we needn’t traverse all parameters and subtract its specific value from itself, but only write two lines of code:</p>
<p>Before:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters():</span><br><span class="line">        p -= p.grad * lr</span><br><span class="line">    model.zero_grad()</span><br></pre></td></tr></table></figure><br>After:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    optimizer.step()</span><br><span class="line">    optimizer.zero_grad()</span><br></pre></td></tr></table></figure><br>Remember to zero grad after each epoch is done, otherwise the gradients will become way too large and get unexpected results.</p>
<p>btw, why I comment that I am hanhan? Because I made mistake on <code>model</code>. Here <code>model</code> must be an instance of <code>NeuralNet</code> rather than a alias, for the values of weights are random. Otherwise, your loss value will always get above 2…</p>
<h3 id="loading-dataset-and-dataloader"><a href="#loading-dataset-and-dataloader" class="headerlink" title="loading dataset and dataloader"></a>loading dataset and dataloader</h3><p>How to import?</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> TensorDataset, DataLoader</span><br></pre></td></tr></table></figure>
<p>How to declare?<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_set = TensorDataset(XTrain, YTrain)</span><br><span class="line">train_loader = DataLoader(train_set, batch_size=bs, shuffle=<span class="literal">True</span>)</span><br><span class="line">valid_set = TensorDataset(XValid, YValid)</span><br><span class="line">valid_loader = DataLoader(valid_set, batch_size=bs * <span class="number">2</span>, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><br>Where is the validation set? I just generate the validation set by extracting one tenth of data of training set. This trick is learnt from “microsoft/ai-edu”.</p>
<p>Since we have things prepared, the whole training code is simple:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>():</span></span><br><span class="line">    print(<span class="string">&#x27;training...&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(max_epoch):</span><br><span class="line">        model.train() <span class="comment"># written before training</span></span><br><span class="line">        <span class="keyword">for</span> batch_x, batch_y <span class="keyword">in</span> train_loader: <span class="comment"># traversal simplified</span></span><br><span class="line">            batch_z = model(batch_x)</span><br><span class="line">            loss = loss_func(batch_z, batch_y)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">        model.<span class="built_in">eval</span>() <span class="comment"># written before validating</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            valid_loss = <span class="built_in">sum</span>(loss_func(model(batch_x), batch_y) <span class="keyword">for</span> batch_x, batch_y <span class="keyword">in</span> valid_loader) / num_valid</span><br><span class="line">        print(<span class="string">&quot;epoch %d, validation loss=%.4f&quot;</span> % (epoch, valid_loss))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;training done.&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Switch-to-CNN"><a href="#Switch-to-CNN" class="headerlink" title="Switch to CNN"></a>Switch to CNN</h2><p>CNN is widely used when data is images. Now let’s try to solve MNIST with CNN, just to feel how powerful CNN is.</p>
<p>In fact, most of the code remain the same. The only area we need to modify is in the definition of class, replacing linear layer with more complex layers.</p>
<p>Here is the code:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> TensorDataset, DataLoader</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># class MNIST(nn.Module):</span></span><br><span class="line"><span class="comment">#     def __init__(self):</span></span><br><span class="line"><span class="comment">#         super(MNIST, self).__init__()</span></span><br><span class="line"><span class="comment">#         self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)</span></span><br><span class="line"><span class="comment">#         self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)</span></span><br><span class="line"><span class="comment">#         self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     def forward(self, batch_x):</span></span><br><span class="line"><span class="comment">#         batch_x = batch_x.view(-1, 1, 28, 28)</span></span><br><span class="line"><span class="comment">#         batch_x = F.relu(self.conv1(batch_x))</span></span><br><span class="line"><span class="comment">#         batch_x = F.relu(self.conv2(batch_x))</span></span><br><span class="line"><span class="comment">#         batch_x = F.relu(self.conv3(batch_x))</span></span><br><span class="line"><span class="comment">#         batch_x = F.avg_pool2d(batch_x, 4)</span></span><br><span class="line"><span class="comment">#         return batch_x.view(-1, batch_x.size(1))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw</span>(<span class="params">X</span>):</span></span><br><span class="line">    print(X.shape)</span><br><span class="line">    plt.imshow(X.reshape((<span class="number">28</span>, <span class="number">28</span>)), cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_data</span>():</span></span><br><span class="line">    path = Path(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> path.exists():</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data/mnist/mnist.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            (XTrain, YTrain), (XTest, YTest), _ = pickle.load(f, encoding=<span class="string">&#x27;latin-1&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> XTrain, YTrain, XTest, YTest</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(FileNotFoundError)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_validation_set</span>(<span class="params">k=<span class="number">10</span></span>):</span></span><br><span class="line">    <span class="keyword">global</span> num_train, XTrain, YTrain</span><br><span class="line">    num_valid = num_train // k</span><br><span class="line">    num_train -= num_valid</span><br><span class="line">    XValid, YValid = XTrain[:num_valid], YTrain[:num_valid]</span><br><span class="line">    XTrain, YTrain = XTrain[num_valid:], YTrain[num_valid:]</span><br><span class="line">    <span class="keyword">return</span> XValid, YValid, num_valid</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">XTrain, YTrain, XTest, YTest = read_data()  <span class="comment"># train: 50000, test: 10000</span></span><br><span class="line">num_train = XTrain.shape[<span class="number">0</span>]</span><br><span class="line">num_test = XTest.shape[<span class="number">0</span>]</span><br><span class="line">XValid, YValid, num_valid = generate_validation_set(k=<span class="number">10</span>)</span><br><span class="line">XTrain, YTrain, XValid, YValid, XTest, YTest = <span class="built_in">map</span>(torch.tensor, (XTrain, YTrain, XValid, YValid, XTest, YTest))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">batch_z, batch_y</span>):</span></span><br><span class="line">    temp = torch.argmax(batch_z, dim=<span class="number">1</span>)</span><br><span class="line">    r = (temp == batch_y)</span><br><span class="line">    <span class="keyword">return</span> r.<span class="built_in">float</span>().mean()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Lambda</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, func</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Lambda, self).__init__()</span><br><span class="line">        self.func = func</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.func(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># hyper-parameter</span></span><br><span class="line">bs = <span class="number">64</span></span><br><span class="line">lr = <span class="number">0.1</span></span><br><span class="line">momentum = <span class="number">0.9</span></span><br><span class="line">max_epoch = <span class="number">20</span></span><br><span class="line"><span class="comment"># essential stuff</span></span><br><span class="line">loss_func = F.cross_entropy</span><br><span class="line"><span class="comment"># model = MNIST()</span></span><br><span class="line">model = nn.Sequential(</span><br><span class="line">    Lambda(<span class="keyword">lambda</span> x: x.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">    nn.Conv2d(<span class="number">1</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">16</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Conv2d(<span class="number">16</span>, <span class="number">10</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.AvgPool2d(<span class="number">4</span>),</span><br><span class="line">    Lambda(<span class="keyword">lambda</span> x: x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)),</span><br><span class="line">)</span><br><span class="line"><span class="comment"># <span class="doctag">NOTE:</span> relu is different in these two forms!(F.relu vs nn.ReLU)</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)</span><br><span class="line"><span class="comment"># datasets and dataloaders</span></span><br><span class="line">train_set = TensorDataset(XTrain, YTrain)</span><br><span class="line">train_loader = DataLoader(train_set, batch_size=bs, shuffle=<span class="literal">True</span>)</span><br><span class="line">valid_set = TensorDataset(XValid, YValid)</span><br><span class="line">valid_loader = DataLoader(valid_set, batch_size=bs * <span class="number">2</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>():</span></span><br><span class="line">    print(<span class="string">&#x27;training...&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(max_epoch):</span><br><span class="line">        model.train()</span><br><span class="line">        <span class="comment"># training: using training set</span></span><br><span class="line">        <span class="keyword">for</span> batch_x, batch_y <span class="keyword">in</span> train_loader:</span><br><span class="line">            <span class="comment"># forward</span></span><br><span class="line">            batch_z = model(batch_x)</span><br><span class="line">            <span class="comment"># backward</span></span><br><span class="line">            loss = loss_func(batch_z, batch_y)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="comment"># inference: using validation set</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            valid_loss = <span class="built_in">sum</span>(loss_func(model(batch_x), batch_y) <span class="keyword">for</span> batch_x, batch_y <span class="keyword">in</span> valid_loader) / num_valid</span><br><span class="line">        print(<span class="string">&quot;epoch %d, validation loss=%.4f&quot;</span> % (epoch, valid_loss))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;training done.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>():</span></span><br><span class="line">    print(<span class="string">&#x27;testing...&#x27;</span>)</span><br><span class="line">    ZTest = model(XTest)</span><br><span class="line">    print(<span class="string">&#x27;loss=%.4f, accuracy=%.4f&#x27;</span> % (loss_func(ZTest, YTest), accuracy(ZTest, YTest)))</span><br><span class="line">    print(<span class="string">&#x27;testing done.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train()</span><br><span class="line">test()</span><br></pre></td></tr></table></figure></p>
<h2 id="Result-Comparision"><a href="#Result-Comparision" class="headerlink" title="Result Comparision"></a>Result Comparision</h2><h3 id="Linear"><a href="#Linear" class="headerlink" title="Linear"></a>Linear</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">training...</span><br><span class="line">epoch 0, validation loss&#x3D;0.0032</span><br><span class="line">epoch 1, validation loss&#x3D;0.0028</span><br><span class="line">epoch 2, validation loss&#x3D;0.0026</span><br><span class="line">epoch 3, validation loss&#x3D;0.0025</span><br><span class="line">epoch 4, validation loss&#x3D;0.0024</span><br><span class="line">epoch 5, validation loss&#x3D;0.0024</span><br><span class="line">epoch 6, validation loss&#x3D;0.0023</span><br><span class="line">epoch 7, validation loss&#x3D;0.0023</span><br><span class="line">epoch 8, validation loss&#x3D;0.0023</span><br><span class="line">epoch 9, validation loss&#x3D;0.0022</span><br><span class="line">epoch 10, validation loss&#x3D;0.0022</span><br><span class="line">epoch 11, validation loss&#x3D;0.0022</span><br><span class="line">epoch 12, validation loss&#x3D;0.0022</span><br><span class="line">epoch 13, validation loss&#x3D;0.0022</span><br><span class="line">epoch 14, validation loss&#x3D;0.0022</span><br><span class="line">epoch 15, validation loss&#x3D;0.0022</span><br><span class="line">epoch 16, validation loss&#x3D;0.0022</span><br><span class="line">epoch 17, validation loss&#x3D;0.0021</span><br><span class="line">epoch 18, validation loss&#x3D;0.0022</span><br><span class="line">epoch 19, validation loss&#x3D;0.0021</span><br><span class="line">training done.</span><br><span class="line">testing...</span><br><span class="line">loss&#x3D;0.2707, accuracy&#x3D;0.9251</span><br><span class="line">testing done.</span><br></pre></td></tr></table></figure>
<h3 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">training...</span><br><span class="line">epoch 0, validation loss&#x3D;0.0042</span><br><span class="line">epoch 1, validation loss&#x3D;0.0020</span><br><span class="line">epoch 2, validation loss&#x3D;0.0018</span><br><span class="line">epoch 3, validation loss&#x3D;0.0017</span><br><span class="line">epoch 4, validation loss&#x3D;0.0015</span><br><span class="line">epoch 5, validation loss&#x3D;0.0012</span><br><span class="line">epoch 6, validation loss&#x3D;0.0015</span><br><span class="line">epoch 7, validation loss&#x3D;0.0013</span><br><span class="line">epoch 8, validation loss&#x3D;0.0012</span><br><span class="line">epoch 9, validation loss&#x3D;0.0011</span><br><span class="line">epoch 10, validation loss&#x3D;0.0011</span><br><span class="line">epoch 11, validation loss&#x3D;0.0012</span><br><span class="line">epoch 12, validation loss&#x3D;0.0011</span><br><span class="line">epoch 13, validation loss&#x3D;0.0013</span><br><span class="line">epoch 14, validation loss&#x3D;0.0010</span><br><span class="line">epoch 15, validation loss&#x3D;0.0010</span><br><span class="line">epoch 16, validation loss&#x3D;0.0010</span><br><span class="line">epoch 17, validation loss&#x3D;0.0010</span><br><span class="line">epoch 18, validation loss&#x3D;0.0010</span><br><span class="line">epoch 19, validation loss&#x3D;0.0009</span><br><span class="line">training done.</span><br><span class="line">testing...</span><br><span class="line">loss&#x3D;0.1135, accuracy&#x3D;0.9666</span><br><span class="line">testing done.</span><br></pre></td></tr></table></figure>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Life is short, I use PyTorch.</p>
<p>CNN, yyds!</p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:  </strong>Garen Wang
  </li>
  <li class="post-copyright-link">
    <strong>Post link: </strong>
    <a href="http://garen-wang.top/2021/01/11/Learn-MNIST-in-PyTorch-from-Scratch-to-CNN/" title="Learn MNIST in PyTorch from Scratch to CNN">http://garen-wang.top/2021/01/11/Learn-MNIST-in-PyTorch-from-Scratch-to-CNN/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Deep-Learning/" rel="tag"><i class="fa fa-tag"></i> Deep-Learning</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/01/08/My-Hexo-Blog-Configuration/" rel="prev" title="My Hexo Blog Configuration">
      <i class="fa fa-chevron-left"></i> My Hexo Blog Configuration
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/01/13/CSAPP-Bomb-Lab-Writeup/" rel="next" title="CSAPP Bomb Lab Writeup">
      CSAPP Bomb Lab Writeup <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#from-Scratch"><span class="nav-number">1.</span> <span class="nav-text">from Scratch</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Download-MNIST-Data"><span class="nav-number">1.1.</span> <span class="nav-text">Download MNIST Data</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Where-can-be-simplified-using-PyTorch-feature"><span class="nav-number">2.</span> <span class="nav-text">Where can be simplified using PyTorch feature?</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#choosing-from-torch-nn-functional"><span class="nav-number">2.1.</span> <span class="nav-text">choosing from torch.nn.functional</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#extending-torch-nn-Module"><span class="nav-number">3.</span> <span class="nav-text">extending torch.nn.Module</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#using-layer-objects-from-torch-nn"><span class="nav-number">4.</span> <span class="nav-text">using layer objects from torch.nn</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#modifying-parameters-by-torch-optim"><span class="nav-number">5.</span> <span class="nav-text">modifying parameters by torch.optim</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#loading-dataset-and-dataloader"><span class="nav-number">5.1.</span> <span class="nav-text">loading dataset and dataloader</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Switch-to-CNN"><span class="nav-number">6.</span> <span class="nav-text">Switch to CNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Result-Comparision"><span class="nav-number">7.</span> <span class="nav-text">Result Comparision</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Linear"><span class="nav-number">7.1.</span> <span class="nav-text">Linear</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CNN"><span class="nav-number">7.2.</span> <span class="nav-text">CNN</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Conclusion"><span class="nav-number">8.</span> <span class="nav-text">Conclusion</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Garen Wang"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Garen Wang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">35</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Garen-Wang" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Garen-Wang" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:g4r3nwang@gmail.com" title="E-Mail → mailto:g4r3nwang@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>



      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">粤ICP备2022012256号 </a>
      <img src="/images/beian.png" style="display: inline-block;">
  </div>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Garen Wang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : 'b42ce29f20441cf61284',
      clientSecret: 'b0d31bcee62d16ebbabf153616a692f84cba5e27',
      repo        : 'garen-wang.github.io',
      owner       : 'Garen-Wang',
      admin       : ['Garen-Wang'],
      id          : 'b5dc770c117fa3e4a740a8ca1864e672',
        language: 'zh-CN',
      distractionFreeMode: false
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>


  <!-- script src="https://cdn.jsdelivr.net/gh/Garen-Wang/live2d-moc3@vv0.2.2/js/live2dcubismcore.js"></script -->
  <!-- script src="https://cdn.jsdelivr.net/gh/Garen-Wang/live2d-moc3@vv0.2.2/js/bundle.js"></script -->

  <canvas id="live2d" width="400" height="400" style="position: fixed; opacity: 1; left: -110px; bottom: -135px; z-index: 99999;"></canvas>
  <script src="https://cdn.jsdelivr.net/gh/Garen-Wang/live2d-moc3@vv0.1.1/js/live2dcubismcore.js"></script>
  <script src="https://cdn.jsdelivr.net/gh/Garen-Wang/live2d-moc3@vv0.1.1/js/bundle.js"></script>
  <script>
    var resourcesPath = 'https://cdn.jsdelivr.net/gh/Garen-Wang/live2d-moc3@v0.1.0/';
    var backImageName = '';
    var modelDir = ['jiaran4'];
    initDefine(resourcesPath, backImageName, modelDir);
  </script>

</body>
</html>
